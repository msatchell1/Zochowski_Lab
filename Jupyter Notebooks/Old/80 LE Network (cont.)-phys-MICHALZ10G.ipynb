{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from \"80 LE Neuron Network\" on 4/21/2022\n",
    "\n",
    "## Goals\n",
    "\n",
    "\n",
    " - Keep improving on the 80 Le neuron network. I need to get REM to be more effective at orthogonalizing. \n",
    " \n",
    " \n",
    " \n",
    " - I need to change avg_quad_array so that it fits the new 80 LE neuron network. \n",
    "\n",
    "\n",
    " - Adjust LE_mult so that it does not apply to the LE-LE connections.\n",
    "\n",
    "## Changes\n",
    "\n",
    "\n",
    " - All figures now save a .pdf and .png version.\n",
    "\n",
    "\n",
    " - Completely redid plasticty vs time graph. Now calculates plasticity post-simulation.\n",
    " \n",
    " \n",
    " - Added conn_out_history attribute to neuron object\n",
    " \n",
    " \n",
    " - Adjusted LE_mult so that it only applies to LE->BB and LE->SST connections.\n",
    "\n",
    "\n",
    "## Notes\n",
    "\n",
    " - Michal likes the LE_mult = 0.8 value because this shows too much general potentiation after NREM and a correction to orthogonalization after REM.\n",
    " \n",
    " \n",
    " - IDEA: Make a new object called “params” to hold all simulation parameters! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import random as RD\n",
    "from matplotlib import colors\n",
    "import winsound\n",
    "import csv\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to leave numEquations and stepSize here, as they affect the integration.\n",
    "numEquations = 4\n",
    "stepSize = 0.1\n",
    "simLength = 42000\n",
    "tarray = np.arange(0,simLength,stepSize)\n",
    "Ntimes = len(tarray)\n",
    "\n",
    "spikeThreshold = 5 # Sets the voltage(mV) at which a spike is recorded. \n",
    "\n",
    "numnrn = 180 # Number of neurons in the model.\n",
    "\n",
    "numSST = 20 # Number of SST neurons to be forced into the model.\n",
    "percent_SST = 0 # Percent of neurons to be randomly assigned as SST interneurons.\n",
    "\n",
    "c_e, c_i = 0.1, 0.5 # Percent connectivity. Excitory, Inhibitory.  \n",
    "p_e, p_i = 0.8, 0 # Probabilty of an existing connection breaking and forming a new connection. Excitory, Inhibitory. \n",
    "local_conn = True # When true, new connections can be formed with local connections. When false, only non-local new\n",
    "# connections are formed.\n",
    "\n",
    "gks_E = 0 # ACh level of excitatory neurons. Type I is gks=0, Type II gks=1.5.\n",
    "gks_SST = 0 # ACh level for SST neurons. \n",
    "\n",
    "Idrive_min, Idrive_max = 0.5, 0.5 # Range for possible random Idrives. For excitory neurons.\n",
    "Idrive_SST = -0.1 #The Idrive for SST neurons. Should be low enough so that they do not fire without synaptic input. \n",
    "\n",
    "gsynH,gsynL = 3,0.5 #High and low gsyn values for recruitee neurons and backbone neurons respectively.\n",
    "\n",
    "w_max = 3 #Maximum positive synaptic plasticity multiplier allowed in network.\n",
    "\n",
    "NABP_boo = True # When true, non-active backbone has plasticity. When False, it does not. \n",
    "makeSound = True\n",
    "spike_skip_time = 200 # Time before spikes start being recorded (in ms) and plasticity begins.\n",
    "NREM_testphase = False # Currently not used anywhere. Needs code needs to be added to make the NREM testing phase optional.\n",
    "\n",
    "RD_seed = True # When true, a seed is used to generate connections\n",
    "seed = 1 # The seed for generating random numbers/list indices. NOTE: defining a seed before a sequence of random events will\n",
    "# not only define the outcome of the first random choice/event, but ALSO the following ones. So we only need one seed. \n",
    "\n",
    "bbs_toplot = [1,2] # list of backbones to plot by ID.\n",
    "\n",
    "directory = 'C:/Users/satchelm/OneDrive - Umich/Zochowski Lab/Saved Figures 4-25-22/Vary w_dep/w_dep = 20/' #The directory for all files to be saved to. \n",
    "\n",
    "osc_period = 300 # The amount of time each BB is active in the oscillations. Note that osc_period under 1000*plas_thr will\n",
    "    # likely cause large depotentiation problems.\n",
    "\n",
    "num_test_phases = 3 # Number of test phases in simulation. Right now we have 3: pre-learning test, post-NREM test, and post-learning test.\n",
    "BB_len_test = 3000 # Length of test phase for each BB (in ms). Total pre- and post- test phase length is then 2*BB_len_test.\n",
    "\n",
    "BB_len_NREM = int((simLength - 2*num_test_phases*BB_len_test)/4) # The length of NREM for each BB (in ms).\n",
    "BB_len_REM = int((simLength - 2*num_test_phases*BB_len_test)/4) # The length of REM for each BB (in ms).\n",
    "t_start_NREM = 2*BB_len_test # Time at which NREM begins.\n",
    "t_start_NREMtest = t_start_NREM + 2*BB_len_NREM # Time at which the test phase after NREM begins.\n",
    "t_start_REM = t_start_NREMtest + 2*BB_len_test # Time at which REM begins.\n",
    "t_start_posttest = t_start_REM + 2*BB_len_REM # Time at which the post-learning test phase begins.\n",
    "\n",
    "\n",
    "class neuron:\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.ID = 0\n",
    "        self.position = []\n",
    "        self.connections = [] #List of (1 or 0) connection strengths to other neurons. Is tuple like [[postsyn,conn],[postsyn,conn]...].\n",
    "        # DO NOT CHANGE self.connections from values of only 1 and 0 because many apects of the program rely on it.\n",
    "        self.connectionWeights = [] #Holds changes made from plasticity. For self as presynaptic nrn. Values are strengths of\n",
    "        # signal to other neurons from this neuron.\n",
    "        self.Input_syn = 0\n",
    "        self.Input_noise = 0\n",
    "        self.Input_external = 0\n",
    "        self.spikeTimes = [] # Set to record a spike when membrane voltage breaches variable spikeThreshold.\n",
    "        self.prevActivity = 0\n",
    "        self.neuronsInRange = [] #Tracks the # of neurons in range so as to minimize looping time during connection growth function\n",
    "        self.solutions = np.zeros(numEquations) #Why does nrn.solutions still function as a comment?\n",
    "        \n",
    "        #Things I have added in myself:\n",
    "        self.spike = False #Determines whether the neuron has already spiked or not. \n",
    "        self.Idrive = 0\n",
    "        self.color = '' #Color of neuron for graphing.\n",
    "        self.conn_in = [] #Connections coming in from other neurons. Sum is the in-degree of the neuron. Note, not tuple like self.connections.\n",
    "        # Format is 1D list of connection strengths, where list index is presynaptic neuron. \n",
    "        self.category = 'Excitatory' #Labels the neuron type. Default is excitatory, can be chanegd to inhibitory. \n",
    "        self.gsyn = 1 # Connection strength multiplier for I->E connections.\n",
    "        self.pair_spiketimes = np.zeros(numnrn) #Pair spike times for outgoing connections. Note that this only holds the most recent pair spiketime for each conn.\n",
    "        self.start_noise = 0 #Starting step time for noise when it occurs (mV/stepSize). \n",
    "        self.backbone_ID = 0 # backbone_ID=0 will be used to designate lower E neurons and -1 for inhibitory neurons.\n",
    "        self.spike_gaussian = [] #List of gaussian curves, each centered at the time a neuron spikes. Each index in list corresponds to a t_ind time.\n",
    "        self.plas_on = True #Boolean determining whether or not to change plasticity of connections TO and FROM this nrn. \n",
    "        self.cw_in_history = [] #Connection weight history. Holds plasticity connection weights coming IN (this nrn as postsyn).\n",
    "        # Set up as [[[weight from nrn 0, weight from nrn 1, ... ],time(ms)] ,...], one weight list for each milisecond.\n",
    "        # List set up to skip first 500 ms because we don't want plasticity due to transient behaviors. Note the default\n",
    "        # value for connections and non-existent connections is 1. \n",
    "        self.cw_out_history = [] # Same as cw_in_history, just with this nrn as the presynaptic neuron.\n",
    "        self.scatter_color = 'grey'\n",
    "        self.scatter_quad_color = 'grey'\n",
    "        self.i_current_hist = np.array([[0,time] for time in range(simLength)]) # Net inhibitory current to this neuron\n",
    "        # every ms. [ [net current, time(ms)] , ...]\n",
    "        \n",
    "        \n",
    "def equations(solns_, eqn, Isyn, Idrive,nrn):\n",
    "    # These equations are parameters are adjusted to fit fast-spiking interneurons.\n",
    "    \n",
    "    tempVal = 0\n",
    "    \n",
    "    category = nrn.category\n",
    "    Inoise = nrn.Input_noise #Noise from neuron. Maybe I should put Idrive, solns, etc here as well?\n",
    "    \n",
    "    if category == 'Excitatory':\n",
    "        gks = gks_E\n",
    "        C = 1 \n",
    "        gna = 24\n",
    "        gkdr = 3\n",
    "        gl = 0.02\n",
    "        Vna = 55\n",
    "        Vk = -90\n",
    "        Vl = -60\n",
    "        if(eqn == 0):\n",
    "            hinf = 1/(1+np.exp((solns_[3]+53)/7))\n",
    "            tauh = .37 + 2.78/(1+np.exp((solns_[3]+40.5)/6))\n",
    "            tempVal = (hinf - solns_[0])/tauh \n",
    "        elif(eqn == 1):\n",
    "            ninf = 1/(1+np.exp((-solns_[3]-30)/10))\n",
    "            taun = .37 + 1.85/(1+np.exp((solns_[3]+27)/15))\n",
    "            tempVal = (ninf - solns_[1])/taun\n",
    "        elif(eqn == 2):\n",
    "            zinf = 1/(1+np.exp((-solns_[3]-39)/5))\n",
    "            tempVal = (zinf - solns_[2])/75\n",
    "        elif(eqn == 3):\n",
    "            m = 1/(1+np.exp((-solns_[3]-30)/9.5))\n",
    "            tempVal = (-gna*(m**3)*solns_[0]*(solns_[3]-Vna) - gkdr*(solns_[1]**4)*(solns_[3]-Vk) \n",
    "                       - gks*solns_[2]*(solns_[3]-Vk) - gl*(solns_[3]-Vl) + Idrive - Isyn + Inoise)/C\n",
    "            \n",
    "    elif category == 'SST':\n",
    "        gks = gks_SST\n",
    "        C = 1 \n",
    "        gna = 24\n",
    "        gkdr = 3\n",
    "        gl = 0.02\n",
    "        Vna = 55\n",
    "        Vk = -90\n",
    "        Vl = -60\n",
    "        if(eqn == 0):\n",
    "            hinf = 1/(1+np.exp((solns_[3]+53)/7))\n",
    "            tauh = .37 + 2.78/(1+np.exp((solns_[3]+40.5)/6))\n",
    "            tempVal = (hinf - solns_[0])/tauh \n",
    "        elif(eqn == 1):\n",
    "            ninf = 1/(1+np.exp((-solns_[3]-30)/10))\n",
    "            taun = .37 + 1.85/(1+np.exp((solns_[3]+27)/15))\n",
    "            tempVal = (ninf - solns_[1])/taun\n",
    "        elif(eqn == 2):\n",
    "            zinf = 1/(1+np.exp((-solns_[3]-39)/5))\n",
    "            tempVal = (zinf - solns_[2])/75\n",
    "        elif(eqn == 3):\n",
    "            m = 1/(1+np.exp((-solns_[3]-30)/9.5))\n",
    "            tempVal = (-gna*(m**3)*solns_[0]*(solns_[3]-Vna) - gkdr*(solns_[1]**4)*(solns_[3]-Vk) \n",
    "                       - gks*solns_[2]*(solns_[3]-Vk) - gl*(solns_[3]-Vl) + Idrive - Isyn)/C\n",
    "            \n",
    "    elif category == 'PV+':\n",
    "        C = 1 \n",
    "        gna = 35\n",
    "        gkdr = 9\n",
    "        gl = 0.1\n",
    "        Vna = 55\n",
    "        Vk = -90\n",
    "        Vl = -65    \n",
    "        if(eqn == 0):\n",
    "            a_h = 0.07*np.exp(-(solns_[3]+58)/20)\n",
    "            b_h = 1/(np.exp(-0.1*(solns_[3]+28))+1)\n",
    "            phi = 5\n",
    "            tempVal = phi*(a_h*(1-solns_[0]) - b_h*solns_[0])\n",
    "        elif(eqn == 1):\n",
    "            a_n = -0.01*(solns_[3]+34)/(np.exp(-0.1*(solns_[3]+34))-1)\n",
    "            b_n = 0.125*np.exp(-(solns_[3]+44)/80)\n",
    "            phi = 5\n",
    "            tempVal = phi*(a_n*(1-solns_[1])-b_n*solns_[1])\n",
    "        elif(eqn == 2):\n",
    "            zinf = 1/(1+np.exp((-solns_[3]-39)/5))\n",
    "            tempVal = (zinf - solns_[2])/75\n",
    "        elif(eqn == 3):\n",
    "            a_m = -0.1*(solns_[3]+35)/(np.exp(-0.1*(solns_[3]+35))-1)\n",
    "            b_m = 4*np.exp(-(solns_[3]+60)/18)\n",
    "            m = a_m/(a_m+b_m)\n",
    "            tempVal = (-gna*(m**3)*solns_[0]*(solns_[3]-Vna) - gkdr*(solns_[1]**4)*(solns_[3]-Vk) \n",
    "                       - gks*solns_[2]*(solns_[3]-Vk) - gl*(solns_[3]-Vl) + Idrive - Isyn)/C\n",
    "        \n",
    "    return tempVal\n",
    "\n",
    "\n",
    "def RK4(t_ind):\n",
    "    \n",
    "    global neuron\n",
    "    \n",
    "    for nrn in neurons:\n",
    "        \n",
    "        \n",
    "        solns = nrn.solutions\n",
    "        Isyn = nrn.Input_syn\n",
    "        Idrive = nrn.Idrive\n",
    "        k1 = np.zeros(numEquations)\n",
    "        k2 = np.zeros(numEquations)\n",
    "        k3 = np.zeros(numEquations)\n",
    "        k4 = np.zeros(numEquations)\n",
    "        \n",
    "        init_solns = solns\n",
    "        \n",
    "        #Calculates the k1 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k1[ii] = stepSize*equations(solns, ii,Isyn,Idrive,nrn)\n",
    "\n",
    "        #Calculates the k2 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k2[ii] = stepSize*equations(solns+k1/2, ii,Isyn,Idrive,nrn) #important fix done here. solns must be advanced by k\n",
    "                                                                    #for calculation of the next k variable.\n",
    "        #Calculates the k3 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k3[ii] = stepSize*equations(solns+k2/2, ii,Isyn,Idrive,nrn) \n",
    "\n",
    "        #Calculates the k4 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k4[ii] = stepSize*equations(solns+k3, ii,Isyn,Idrive,nrn)\n",
    "        \n",
    "        #Updates the general solution\n",
    "        for ii in range(len(solns)):\n",
    "            solns[ii] = init_solns[ii] + (k1[ii] + 2*k2[ii] + 2*k3[ii] + k4[ii])/6 \n",
    "            nrn.solutions[ii] = solns[ii]\n",
    "            \n",
    "            \n",
    "            \n",
    "def init_nrn(numnrn): #initializes neurons and assigns ID, connections, weights, etc. \n",
    "    global neuron\n",
    "    neurons = [] #List containing neuron objects\n",
    "    nconn_Mat = [np.empty(3)] # 2D matrix for storing new connections.\n",
    "    \n",
    "    if RD_seed: # When true, the simulation will be reproducable entirely (all connections, neuron assignments, initial coniditions).\n",
    "        RD.seed(seed)\n",
    "    \n",
    "    def count_SST(neurons): # A function for counting the number of SST neurons.\n",
    "        count = 0\n",
    "        for nrn in neurons:\n",
    "            if nrn.category == 'SST':\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    \n",
    "    for i in range(numnrn):  \n",
    "        neurons = np.append(neurons,neuron()) #Intiallizes numnrn number of neurons\n",
    "        \n",
    "        \n",
    "    #This for loop ensures that exactly numSST number of E neurons are changed to SST.\n",
    "    for i in range(numSST):\n",
    "        changed_to_SST = False #Keeps loop running until excitatory neuron is found to change to SST neuron.\n",
    "        while changed_to_SST == False: #Loop mentioned above.\n",
    "            nrn = RD.choice(neurons) #grabs one neuron object at random (available for editing)\n",
    "            if nrn.category == 'Excitatory': #If true, turns excitatory neuron to SST. If neuron is not Excitatory, while loop runs again.\n",
    "                nrn.category = 'SST'\n",
    "                nrn.backbone_ID = -1 #Assigns inhibitory neurons to backbone ID = -1.\n",
    "                changed_to_SST = True\n",
    "                \n",
    "    #Create list of only E neurons.\n",
    "    Eneurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.category == 'Excitatory':\n",
    "            Eneurons.append(nrn) #Note that even though this is a different list than neurons, the neuron objects within can be\n",
    "            # changed all the same like they were in neurons. \n",
    "                \n",
    "                \n",
    "    #Changes all excitatory neurons to having high inhibition (i.e. like LE neurons):\n",
    "    for nrn in Eneurons:\n",
    "        nrn.gsyn = gsynH\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_backbones(Eneurons):\n",
    "        #this function initializes backbones into a network assuming that all E neurons have a high gysn (high inhibition level). \n",
    "        # Takes list of excitatory neuron objects as input. WILL NEED TO FIX WITH try->except when num_per_bb > non_bb_size because\n",
    "        #then LElist will sample too many elements from templist on last run of loop. \n",
    "        global neuron \n",
    "\n",
    "        num_bb = 2 #number of backbones to create from number of available E neurons\n",
    "        non_bb_size = 80 #number of non-backbone E neurons to be left in network.\n",
    "        num_bb_nrns = numnrn - (numSST + non_bb_size) #number of neurons for splitting into backbones.\n",
    "        num_per_bb = int(num_bb_nrns/num_bb) # number of E neurons per backbone.\n",
    "\n",
    "        bb_list = RD.sample(Eneurons,num_per_bb) #temp list for looping. Randomly samples num_per_bb # of neurons from Eneurons.\n",
    "\n",
    "        for bb in range(1,num_bb+1): #This makes the notation easier by shifitng indicies +1. This is because nrn.backbone_ID=0\n",
    "        # is reserved for NON-backbone neurons. bb=1 designates backbone_ID=1.\n",
    "            templist=[]\n",
    "\n",
    "            for nrn in bb_list:\n",
    "                nrn.backbone_ID = bb # Assigns first randomly chosen group of neurons to the first backbone.\n",
    "                nrn.gsyn = gsynL #Backbones are created in the \"on\" state.\n",
    "                \n",
    "            for nrn in Eneurons: #Makes a new list with only non-backbone nrns.\n",
    "                if nrn.backbone_ID == 0:\n",
    "                    templist.append(nrn)\n",
    "            bb_list = RD.sample(templist,num_per_bb)\n",
    "\n",
    "        \n",
    "        \n",
    "    create_backbones(Eneurons)\n",
    "\n",
    "\n",
    "    ID = 0\n",
    "    bb_colors = ['cyan','blue','green','orange','purple'] # Colors for backbones, cyan reserved for non-backbone E neurons.\n",
    "    for nrn in neurons: #assigns neurons in list their IDs, init voltage, Idrive, etc.\n",
    "        nrn.ID = ID\n",
    "        ID += 1 \n",
    "        nrn.spikeTimes = []\n",
    "        nrn.solutions = [RD.random(),RD.random(),RD.random(),RD.uniform(-55,-20)] #Initial conditions of each neuron. Initial voltage randomly assigned between -55 and -20 mV.\n",
    "        #nrn.gsyn = round(RD.uniform(0,3),4) #Chooses a connection multiplier between 0 and x.\n",
    "        nrn.connectionWeights = [1]*numnrn #Creates a list of all connection weights to other neurons at value 1. \n",
    "\n",
    "        if nrn.category == 'Excitatory':\n",
    "            nrn.Idrive = round(RD.uniform(Idrive_min, Idrive_max),3) #Random value between min and max rounded to 1 decimal places\n",
    "            nrn.color = bb_colors[nrn.backbone_ID] #Assigns nrn color coded for backbone.\n",
    "            \n",
    "        if nrn.category == 'SST':\n",
    "            nrn.color = 'Red' #Inhibitory given red.\n",
    "            nrn.Idrive = Idrive_SST #Idrive for inhibitory neurons. \n",
    "        if nrn.category == 'PV+':\n",
    "            nrn.color = 'darkorange'\n",
    "            nrn.Idrive = round(RD.uniform(Idrive_PVplus_min,Idrive_PVplus_max),3)\n",
    "    \n",
    "    conn_Matrix = np.zeros((numnrn,numnrn)) #initializes matrix of zeros with numnrn x numnrn size. Row = nrn #, Column = connected nrn #\n",
    "    # Fills matrix with connectivity based on proximity. conn_span # of neurons to right and left are given full connection. \n",
    "    for row_index, row in enumerate(conn_Matrix):\n",
    "        for column_index, conn in enumerate(row):\n",
    "            \n",
    "            if neurons[row_index].category == 'Excitatory': #Determines which connectivity percent to use based on neuron category.\n",
    "                conn_span = int(c_e*numnrn/2) #number of neurons to be connected on either side of a neuron.\n",
    "\n",
    "                #sets neurons at +- conn_span from diagonal to full connectivity.\n",
    "                if column_index >= row_index-conn_span and column_index <= row_index+conn_span:\n",
    "                    conn = 1 \n",
    "                #Full connectivity at edge case of first neurons connected to last neurons in ring.\n",
    "                elif row_index-conn_span < 0 and column_index >= numnrn+row_index-conn_span:\n",
    "                    conn = 1\n",
    "                #Full connectivity at edge case of last neurons connected to first neurons in ring.\n",
    "                elif row_index+conn_span > (numnrn-1) and column_index <= row_index-numnrn+conn_span:\n",
    "                    conn = 1 \n",
    "                #All other neurons have zero connectivity.\n",
    "                else:\n",
    "                    conn = 0\n",
    "                # Sets diagonal entries to zero.\n",
    "                if column_index == row_index:\n",
    "                    conn = 0\n",
    "                    \n",
    "            elif neurons[row_index].category == 'SST' or neurons[row_index].category == 'PV+': # If the presynaptic neuron is inhibitory.\n",
    "                if RD.random() <= c_i and column_index != row_index: # if a random between 0 and 1 is less than the connectivity percent. \n",
    "                    conn = 1\n",
    "                else:\n",
    "                    conn = 0\n",
    "                    \n",
    "            row[column_index] = conn  #Assigns the local connections.\n",
    "        conn_Matrix[row_index] = row\n",
    "\n",
    "    # Changes connections based on proability p. \n",
    "    for row_index, row in enumerate(conn_Matrix): \n",
    "        row_temp = row.copy() #used to store changes while deleting connections from new_conn_list. VERY IMPORTANT TO USE .copy()\n",
    "         # otherwise row will change when row_temp is changed. This is how assignment works. \n",
    "        if neurons[row_index].category == 'Excitatory': #Determines which connectivity percent to use based on neuron category.\n",
    "            conn_span = int(c_e*numnrn/2) #number of neurons to be connected on either side of a neuron.\n",
    "            p = p_e\n",
    "        elif neurons[row_index].category == 'SST' or neurons[row_index].category == 'PV+':\n",
    "            conn_span = int(c_i*numnrn/2)\n",
    "            p = p_i \n",
    "\n",
    "        for column_index, conn in enumerate(row):\n",
    "            \n",
    "            if conn != 0: #only for existing connections.\n",
    "                if RD.random() <= p: # RD.random() selects random float between 0 and 1.\n",
    "\n",
    "                    if local_conn == True: # Allows new local connections.\n",
    "                        new_conn_list = np.append(np.arange(0,row_index,1),np.arange(row_index+1,numnrn,1)) #Creates list of\n",
    "                        #all nrn IDs besides self.\n",
    "                    if local_conn == False: #No new local connections.\n",
    "                        #List of all nrns except local and self. Very gross and uses heaviside functions. May be simplifiable. \n",
    "                        new_conn_list = np.append(np.arange(numnrn - numnrn*np.heaviside(row_index-conn_span-1, 1)\n",
    "                                    +(row_index+conn_span-numnrn+1)*np.heaviside(row_index+conn_span-numnrn,1),row_index-conn_span,1),\n",
    "                                    np.arange(row_index+conn_span+1,(numnrn+row_index-conn_span)-\n",
    "                                    (row_index-conn_span)*np.heaviside(row_index-conn_span, 1),1))\n",
    "                     \n",
    "                    for index, val in enumerate(row_temp):#Deletes established conns from new_conn_list, preventing double connections.\n",
    "\n",
    "                        if val != 0: #Sorts out only established conns.\n",
    "                            delindex = np.where(new_conn_list == index) #Finds where est. conn lies in new_conn_list.\n",
    "                            if len(delindex[0]) > 0: #Stops error from having nothing to delete when local_conn = False. \n",
    "                                delindex = delindex[0][0] #grabs useful integer.\n",
    "                                new_conn_list = np.delete(new_conn_list, delindex) #deletes from possible conns. \n",
    "    \n",
    "                    nconn = RD.choice(new_conn_list) #Randomly selects one neuron to connect to. \n",
    "                    nconn_info = [[row_index, column_index, nconn]] # [neuron #, old connection, new connection]. Must be 2D.\n",
    "                    nconn_Mat = np.concatenate((nconn_Mat,nconn_info)) #Adds this info to a matrix for later use.\n",
    "                    \n",
    "                    #Updates values of the array used in determining new connections. \n",
    "                    row_temp[int(column_index)] = 0 \n",
    "                    row_temp[int(nconn)] = 1\n",
    "\n",
    "\n",
    "    nconn_Mat = np.delete(nconn_Mat,0,0) #Removes np.empty dummy row from matrix.\n",
    "    \n",
    "    #Apply new connection changes.\n",
    "    for info in nconn_Mat:\n",
    "        conn_Matrix[int(info[0]),int(info[1])] = 0 #Sets old connection to zero.\n",
    "        conn_Matrix[int(info[0]),int(info[2])] += 1 #Establishes connection or adds another connection.\n",
    "\n",
    "    nc_Matrix = np.empty((numnrn,numnrn,2)) #Empty matrix to hold final values. nc means neuron # and connection strength. \n",
    "    count = 0\n",
    "    # Creates 3D array, nc_matrix, storing (nrn #, conn strength to nrn receiving Isyn)\n",
    "    for row in conn_Matrix:\n",
    "        conn_tuple = list(enumerate(row)) #list of tuples with info (postsyn nrn #, recieving nrn conn strength)\n",
    "        nc_Matrix[count] = conn_tuple \n",
    "        count += 1\n",
    "\n",
    "    \n",
    "    #Assigns neuron objects the list of tuple connections. \n",
    "    for nrn in neurons:\n",
    "        nrn.connections = nc_Matrix[nrn.ID] #Outgoing connections for nrn.\n",
    "        nrn.conn_in = nc_Matrix[:,nrn.ID][:,1]# Incoming connections for nrn. [0,0,1,1] would mean this neuron recieves no\n",
    "        # signal from neurons 0 and 1, and full signal from neurons 2 and 3. \n",
    "        \n",
    "        \n",
    "    def del_crossbb_conns():\n",
    "        # This function deletes E-E connections between neurons in different backbones. This prevents the activity of one backbone\n",
    "        # form exciting the other.\n",
    "        global neuron\n",
    "\n",
    "        for nrn1 in neurons:\n",
    "            for nrn2 in neurons:\n",
    "                #The following checks that nrns are not inhibitory (bb=-1) or lower excitatory (bb=0) and are in different backbones with a connection.\n",
    "                if nrn1.backbone_ID not in [-1,0] and nrn2.backbone_ID not in [-1,0] and nrn1.backbone_ID != nrn2.backbone_ID and nrn1.connections[int(nrn2.ID)][1] == 1:\n",
    "                    nrn1.connections[int(nrn2.ID)][1] = 0 #Eliminates connection between neurons.\n",
    "                \n",
    "    del_crossbb_conns()\n",
    "    \n",
    "    def del_LEtobb_conns():\n",
    "        # This function deletes LE to BB connections. NOTE that the conn mat/ plas mat are not changed, so they still show these connections as existing.\n",
    "        global neuron\n",
    "\n",
    "        for nrn in neurons:\n",
    "            for postsyn, conn in nrn.connections:\n",
    "                if nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID in bbs_toplot:\n",
    "                    nrn.connections[int(postsyn)][1] = 0 #Eliminates connection between neurons.\n",
    "\n",
    "    #del_LEtobb_conns()\n",
    "    \n",
    "    \n",
    "    return neurons,nc_Matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def init_quad_colors(): # Function for initializing the color groups of LE neurons based on their initial connections to bbs.\n",
    "    # This function should be run after connections are established (after init_neurons()) but before the t_ind loop for the \n",
    "    # simulation begins.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "\n",
    "    LE_sum_cw_bb1,LE_sum_cw_bb2 = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "\n",
    "    # Need to fill LE_sum_cw_bbx with number of connections (effectively the cw) from bbx. This will be used to sort for quadrant colors.\n",
    "    # LE_sum_cw_bbx is analogous to bbx_REM_vals from BBs_scatter().\n",
    "    for LE_nrn in LE_neurons:\n",
    "        for index,conn in enumerate(LE_nrn.conn_in):\n",
    "            if neurons[index].backbone_ID == 1 and conn == 1: # If presyn is bb1 and connection exists.\n",
    "                LE_sum_cw_bb1[LE_neurons.index(LE_nrn)] += 1 # Adds 1 so that at after the loop, index represents total # of\n",
    "                                                             # connections from bb1 to this LE nrn.   \n",
    "            if neurons[index].backbone_ID == 2 and conn == 1:\n",
    "                LE_sum_cw_bb2[LE_neurons.index(LE_nrn)] += 1\n",
    "            \n",
    "    #Seperating LE neurons into 4 quadrants and assigning them colors. This is based off before learning.\n",
    "    #Largest strengths first in lists: (Remember these are LE neuron objects in the lists)\n",
    "    LE_sorted_bb1 = [nrn for cw,nrn in sorted(zip(LE_sum_cw_bb1,LE_neurons),reverse=True,key=sort_tuple)]\n",
    "    LE_sorted_bb2 = [nrn for cw,nrn in sorted(zip(LE_sum_cw_bb2,LE_neurons),reverse=True,key=sort_tuple)]\n",
    "\n",
    "    strong_bb1,weak_bb1,strong_bb2,weak_bb2 = [],[],[],[] #Lists for strong and weakly connected neurons.\n",
    "    for index in range(len(LE_neurons)):\n",
    "        if index < len(LE_neurons)/2: #Sorts strongest half of LE neurons into strong lists.\n",
    "            strong_bb1.append(LE_sorted_bb1[index])\n",
    "            strong_bb2.append(LE_sorted_bb2[index])\n",
    "        else: #Sorts remaining half into weak lists.\n",
    "            weak_bb1.append(LE_sorted_bb1[index])\n",
    "            weak_bb2.append(LE_sorted_bb2[index])\n",
    "\n",
    "    #Assigns color to neurons based on what lists they are in:\n",
    "    for LE_nrn in LE_neurons:\n",
    "        if LE_nrn in strong_bb1 and LE_nrn in strong_bb2: #If LE neuron has strong input from both bbs (top right).\n",
    "            LE_nrn.scatter_quad_color = 'purple'\n",
    "        if LE_nrn in strong_bb1 and LE_nrn in weak_bb2: #If LE neuron has strong input from bb1 and weak from bb2 (Bottom right quadrant)\n",
    "            LE_nrn.scatter_quad_color = 'blue'\n",
    "        if LE_nrn in weak_bb1 and LE_nrn in strong_bb2: # (top left)\n",
    "            LE_nrn.scatter_quad_color = 'green'\n",
    "        if LE_nrn in weak_bb1 and LE_nrn in weak_bb2: # (bottom left)\n",
    "            LE_nrn.scatter_quad_color = 'pink'\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "def updateSyn(t_ind): #Gives synaptic input to all neurons on connection list\n",
    "    #Includes changes in synaptic strengths. t_start is the time at which the presynaptic neuron's voltage breaches -20 mV.\n",
    "    # Has been changed to normalize strength of inputs to a neuron by number of inputs. I.e sum of all inputs comes to w_max. \n",
    "    t_temp = 0 \n",
    "    global neuron\n",
    "\n",
    "    # AMPA connections\n",
    "    w_EE = 0.15\n",
    "    w_EI = 0.08\n",
    "    # GABA A connections\n",
    "    w_II = 0.15\n",
    "    w_IE = 0\n",
    "    # GABA B connections\n",
    "    w_II_B = 0\n",
    "    w_IE_B = 0.05\n",
    "    \n",
    "    tau = 0.5 #Time constant for fast-acting receptors.\n",
    "    tau_B = 50 # Time constant for GABA B receptors, slow-acting.\n",
    "    \n",
    "    LE_mult = 0.8 # Multiplier for synapses where LE neuron is presynaptic neuron.\n",
    "    \n",
    "    for nrn in neurons:# presynaptic neurons.         \n",
    "        if len(nrn.spikeTimes) > 0: # To prevent errors of calling [-1] from an array without any entries. Can change to be l > 2, 3 ...\n",
    "            t_temp = nrn.spikeTimes[-1] #grabs time this neuron spikes at.\n",
    "\n",
    "            for conn in nrn.connections: #Gives all postsynaptic neurons Isyn corrspondping to their voltage.\n",
    "                if conn[1] != 0: #Prevents synaotic current from being calculated to non-connected neurons.\n",
    "                    \n",
    "                    V = neurons[int(conn[0])].solutions[3] #Voltage of postsynaptic neuron. Note conn[1] is the connection strength and conn[0] is the ID.\n",
    "                    Isyn = 0 \n",
    "\n",
    "                    if nrn.category == 'SST' or nrn.category == 'PV+': # Handles GABA A and B receptors in postsyn  neurons.\n",
    "                        \n",
    "                        E_syn = -75 #Chloride reversal potential. \n",
    "                        \n",
    "                        if neurons[int(conn[0])].category == 'SST' or neurons[int(conn[0])].category == 'PV+': # For I-I connections.\n",
    "                            for w,t in (w_II,tau),(w_II_B,tau_B): #Sends two signals, one with w_II/tau and one with w_II_B/tau_B. \n",
    "                                Isyn += conn[1]*(w)*np.exp(-stepSize*(t_ind-t_temp)/t)*(V - E_syn) # t is tau here. \n",
    "                        if neurons[int(conn[0])].category == 'Excitatory': # For I->E connections.\n",
    "                            gsyn = neurons[int(conn[0])].gsyn #Connection strength multiplier of postsynaptic neuron.\n",
    "                            for w,t in (w_IE,tau),(w_IE_B,tau_B):\n",
    "                                Isyn += gsyn*conn[1]*(w)*np.exp(-stepSize*(t_ind-t_temp)/t)*(V - E_syn) # t = tau again.\n",
    "                                \n",
    "                    if nrn.category == 'Excitatory':\n",
    "                        \n",
    "                        E_syn = 0 # Sodium reversal potential. E_syn = 0 for excitory synapse and E_syn = -75 mV for inhibitory synapse\n",
    "                        \n",
    "                        if nrn.backbone_ID == 0: # If presynaptic neuron in an LE neuron.\n",
    "                            if neurons[int(conn[0])].category == 'SST' or neurons[int(conn[0])].category == 'PV+': # For LE->I connections.\n",
    "                                Isyn = LE_mult*conn[1]*(w_EI)*np.exp(-stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                            if neurons[int(conn[0])].category == 'Excitatory': # For LE-E connections.\n",
    "                                if neurons[int(conn[0])].backbone_ID == 0: # If postsynaptic neuron is LE as well. Uses no LE_mult.\n",
    "                                    Isyn = nrn.connectionWeights[int(conn[0])]*conn[1]*(w_EE)*np.exp(-stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                                else: # For LE->BB connections\n",
    "                                    Isyn = LE_mult*nrn.connectionWeights[int(conn[0])]*conn[1]*(w_EE)*np.exp(-stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                        else:\n",
    "                            if neurons[int(conn[0])].category == 'SST' or neurons[int(conn[0])].category == 'PV+': # For E->I connections.\n",
    "                                Isyn = conn[1]*(w_EI)*np.exp(-stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                            if neurons[int(conn[0])].category == 'Excitatory': # For E-E connections.\n",
    "                                Isyn = nrn.connectionWeights[int(conn[0])]*conn[1]*(w_EE)*np.exp(-stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "\n",
    "                    neurons[int(conn[0])].Input_syn += Isyn #Isyn going to Postsynaptic neuron.\n",
    "      \n",
    "        #Additional portion of updateSyn() for calculating noise probabilities. INDENTATION IS IMPORTANT! MUST BE IN nrn LOOP.\n",
    "        noise_mag = 50 #Magnitude of noise input in mV. \n",
    "        probability = 2*10**(-4) #Probability in every integration step that a noise spike will occur for each neuron.\n",
    "        t_noise = nrn.start_noise \n",
    "        global neuron\n",
    "\n",
    "        if RD.random() <= probability: #Handles the start of a noise spike.\n",
    "            #print('Noise Spike at Time ',t_ind*stepSize)\n",
    "            Inoise = noise_mag\n",
    "            nrn.start_noise = t_ind #Time at which noise begins \n",
    "        elif nrn.Input_noise != 0 and (t_ind - t_noise)*stepSize <= 1: #extends noise input for 1 ms.\n",
    "            Inoise = noise_mag\n",
    "        else:\n",
    "            Inoise = 0 #When there is no noise. \n",
    "\n",
    "        nrn.Input_noise = Inoise # Applies noise to neuron. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "def updateSpikeTime(t_ind):\n",
    "    global neuron\n",
    "    # Variables for synaptic plasticity:\n",
    "    A = 0.6/10 # The maximum amount a synapse can change in strength per spike.\n",
    "    tau = 10 # Time constant for exponential function in ms.\n",
    "    \n",
    "    dep_thr = 1 #Depotentiation-only rule threshold frequency(Hz). Firing of neuron pairs below this frequency will only depotentiate.\n",
    "    pot_thr = 10 #Bi-directional rule upper threshold and potentiation-only lower theshold frequency(Hz). Firing between\n",
    "    # dep_thr and pot_thr will be subject to bi-rule, while firing above pot_thr subject to potentiation only. \n",
    "    plas_thr = 0.00001 #If a neuron pair is firing at less than this frequency (Hz), plasticity is not applied.\n",
    "    \n",
    "    w_dep = 20 # The multiplier for plasticity caused by depotentiation-only rule.\n",
    "    w_bi = 10 # The multiplier for plasticity caused by bi-directional rule. \n",
    "    w_pot = 3 # The multiplier for plasticity caused by potentiation-only rule.\n",
    "    \n",
    "    for nrn in neurons:\n",
    "        \n",
    "        # Recording the incoming connection plasticity weights for each neuron:\n",
    "        if t_ind % (1/stepSize) == 0 and t_ind*stepSize >= spike_skip_time: #Only runs code every ms (t_ind with only zero in decimal place). Also skips first 500 ms of no plasticity.\n",
    "            \n",
    "            presyn_weight_list = np.ones(numnrn) #List for storing weight connections from each presyn neuron.\n",
    "            postsyn_weight_list = np.ones(numnrn)\n",
    "            \n",
    "            for nrn_ID in range(numnrn): #Loops through presynaptic connections to nrn.\n",
    "                presyn_weight_list[int(nrn_ID)] = neurons[int(nrn_ID)].connectionWeights[int(nrn.ID)] #Records value \n",
    "                # of connection weight from presynaptic neuron.\n",
    "                postsyn_weight_list[int(nrn_ID)] = nrn.connectionWeights[int(nrn_ID)]\n",
    "            \n",
    "            nrn.cw_in_history.append([presyn_weight_list, t_ind*stepSize]) #Appends conn weights in to this nrn to history. \n",
    "            nrn.cw_out_history.append([postsyn_weight_list, t_ind*stepSize]) # Appends conn weights out of this nrn to history.\n",
    "\n",
    "        # Recording spike times:\n",
    "        if nrn.solutions[3] >= spikeThreshold and nrn.spike == False and (t_ind*stepSize) > spike_skip_time: #Selects spikes, skips anything before the first \"spike_skip_time\" ms. \n",
    "            \n",
    "            nrn.spikeTimes = np.append(nrn.spikeTimes, t_ind) #Records (time/stepSize) of a spike.\n",
    "            nrn.spike = True\n",
    "                        \n",
    "            if nrn.plas_on == True: #If nrn's plas_on is True, plasticity(to and from) nrn is allowed to change. If False, it is frozen.\n",
    "\n",
    "                #Changes synaptic weights. Note, nrn.connections is a tuple [postsyn, conn] while nrn.conn_in is simply a list of conns where the index is the presyn.\n",
    "                # This works using only spikes that have already occured, so in-conns will always be strengthened and out-conns always weakened.\n",
    "                for postsyn,conn in nrn.connections: # The outgoing connections. This weakens synapses. \n",
    "\n",
    "                    if conn == 1 and nrn.category == 'Excitatory' and neurons[int(postsyn)].category == 'Excitatory' \\\n",
    "                    and len(neurons[int(postsyn)].spikeTimes) > 0 and neurons[int(postsyn)].spikeTimes[-1] >= (nrn.spikeTimes[-1] - 30/stepSize)\\\n",
    "                    and neurons[int(postsyn)].plas_on == True: #Excludes all neurons that haven't spiked in the last 30 ms.\n",
    "                            pair_spiketime = stepSize*(nrn.spikeTimes[-1] - (nrn.spikeTimes[-1]-neurons[int(postsyn)].spikeTimes[-1])/2) #Spike time of neuron pair in ms.\n",
    "                            \n",
    "                            if (nrn.backbone_ID == neurons[int(postsyn)].backbone_ID and nrn.backbone_ID in bbs_toplot)\\\n",
    "                            or (nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID in bbs_toplot): # Excludes inter-BB conns and LE to BB conns from plasticity.\n",
    "                                pass # Does nothing if the above is true.\n",
    "                            else:\n",
    "                                # If pair firing frequency is below dep_thr Hz. Also prevents initial pair_spiketimes value of zero from causing unwanted initial depotentiation.\n",
    "                                if 1000/plas_thr > (pair_spiketime - nrn.pair_spiketimes[int(postsyn)]) >= 1000/dep_thr and nrn.pair_spiketimes[int(postsyn)] != 0:\n",
    "                                    nrn.connectionWeights[int(postsyn)] += -w_dep*A*np.exp((-stepSize*abs(neurons[int(postsyn)].spikeTimes[-1] \n",
    "                                                                                               - nrn.spikeTimes[-1]))/tau)# Weaken synapse.\n",
    "                                    if nrn.connectionWeights[int(postsyn)] < 0:\n",
    "                                        nrn.connectionWeights[int(postsyn)] = 0 #This prevents synaptic weakening below zero, which would simulate inhibition.\n",
    "                                \n",
    "                                #Determines pair firing frequency bsed off last fire. Selects firing between dep_thr and pot_thr frequencies (Hz).\n",
    "                                if 1000/dep_thr > (pair_spiketime - nrn.pair_spiketimes[int(postsyn)]) >= 1000/pot_thr: \n",
    "                                    nrn.connectionWeights[int(postsyn)] += -w_bi*A*np.exp((-stepSize*abs(neurons[int(postsyn)].spikeTimes[-1]\n",
    "                                                                                                    - nrn.spikeTimes[-1]))/tau)# Weaken synapse.\n",
    "                                    if nrn.connectionWeights[int(postsyn)] < 0:\n",
    "                                        nrn.connectionWeights[int(postsyn)] = 0 #This prevents synaptic weakening below zero, which would simulate inhibition.\n",
    "                                    \n",
    "                                if pair_spiketime - nrn.pair_spiketimes[int(postsyn)] < 1000/pot_thr: #If frequency is greater than pot_thr Hz. \n",
    "                                    nrn.connectionWeights[int(postsyn)] += w_pot*A*np.exp((-stepSize*abs(neurons[int(postsyn)].spikeTimes[-1] - nrn.spikeTimes[-1]))/tau)# Strengthen synapse.\n",
    "                                    if nrn.connectionWeights[int(postsyn)] > w_max:\n",
    "                                        nrn.connectionWeights[int(postsyn)] = w_max #Caps strength at w_max.\n",
    "\n",
    "                            nrn.pair_spiketimes[int(postsyn)] = pair_spiketime #Updates pair spiketime.\n",
    "\n",
    "                for presyn,conn in enumerate(nrn.conn_in): # Incoming connections. This strengthens synapses.\n",
    "\n",
    "                    if conn == 1 and nrn.category == 'Excitatory' and neurons[int(presyn)].category == 'Excitatory' \\\n",
    "                    and len(neurons[int(presyn)].spikeTimes) > 0 and neurons[int(presyn)].spikeTimes[-1] >= (nrn.spikeTimes[-1] - 30/stepSize)\\\n",
    "                    and neurons[int(presyn)].plas_on == True:\n",
    "                        pair_spiketime = stepSize*(nrn.spikeTimes[-1] - (nrn.spikeTimes[-1]-neurons[int(presyn)].spikeTimes[-1])/2) #Spike time of neuron pair in ms.\n",
    "\n",
    "                        if (nrn.backbone_ID == neurons[int(presyn)].backbone_ID and nrn.backbone_ID in bbs_toplot)\\\n",
    "                        or (nrn.backbone_ID in bbs_toplot and neurons[int(presyn)].backbone_ID == 0):\n",
    "                            pass \n",
    "                        else:\n",
    "                            # If pair firing frequency is below dep_thr Hz. Also prevents initial pair_spiketimes value of zero from causing unwanted initial depotentiation.\n",
    "                            if 1000/plas_thr > (pair_spiketime - neurons[int(presyn)].pair_spiketimes[int(nrn.ID)]) >= 1000/dep_thr and neurons[int(presyn)].pair_spiketimes[int(nrn.ID)] != 0:  \n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] += -w_dep*A*np.exp((-stepSize*abs(neurons[int(presyn)].spikeTimes[-1] \n",
    "                                                                                                - nrn.spikeTimes[-1]))/tau)# Weaken synapse.\n",
    "                                if neurons[int(presyn)].connectionWeights[int(nrn.ID)] < 0:\n",
    "                                    neurons[int(presyn)].connectionWeights[int(nrn.ID)] = 0 #This prevents synaptic weakening below zero, which would simulate inhibition.\n",
    "\n",
    "                            if 1000/dep_thr > (pair_spiketime - neurons[int(presyn)].pair_spiketimes[int(nrn.ID)]) >= 1000/pot_thr: \n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] += w_bi*A*np.exp((-stepSize*abs(neurons[int(presyn)].spikeTimes[-1] \n",
    "                                                                                                - nrn.spikeTimes[-1]))/tau) #Strengthens synapse.\n",
    "                                if neurons[int(presyn)].connectionWeights[int(nrn.ID)] > w_max:\n",
    "                                    neurons[int(presyn)].connectionWeights[int(nrn.ID)] = w_max # Caps strength at w_max.\n",
    "                                \n",
    "                            if pair_spiketime - neurons[int(presyn)].pair_spiketimes[int(nrn.ID)] < 1000/pot_thr: #For frequencies greater than pot_thr Hz.\n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] += w_pot*A*np.exp((-stepSize*abs(neurons[int(presyn)].spikeTimes[-1] \n",
    "                                                                                                - nrn.spikeTimes[-1]))/tau) #Strengthens synapse.\n",
    "                                if neurons[int(presyn)].connectionWeights[int(nrn.ID)] > w_max:\n",
    "                                    neurons[int(presyn)].connectionWeights[int(nrn.ID)] = w_max # Caps strength at w_max.\n",
    "\n",
    "                        neurons[int(presyn)].pair_spiketimes[int(nrn.ID)] = pair_spiketime #Updates pair spiketime.   \n",
    "                    \n",
    "        if nrn.solutions[3] <= -30 and nrn.spike == True: #Resets the spiking status, allows for next spike to be recorded. \n",
    "            nrn.spike = False\n",
    "            \n",
    "            \n",
    "'---------------------------------------------------------------------------'      \n",
    "def param_funcs():\n",
    "    # Function for creating and returning lists needed in vary_param that don't need to be redone every timestep. \n",
    "    # NOTE: Before I actually implement this function, I need to test whether using it increases or decreases simulation runtime.\n",
    "    dummy_var = 0\n",
    "\n",
    "\n",
    "            \n",
    "def vary_param(t_ind): #Changes gks of network as well as vary other parameters. I am also added in a component to weaken all synapses after NREM.\n",
    "    global gks_E, gks_SST #Allows changes to these global variables to be made inside function.\n",
    "    global neuron\n",
    "    \n",
    "    #Vary gks:\n",
    "    t = t_ind*stepSize #changes t_ind to ms.\n",
    "    gt_list = [[1,t_start_NREM],[0,t_start_NREMtest]] #List containing gks values and the time to impliment them. [[gks val,time(ms)],[...]].\n",
    "    \n",
    "    times = [i[1] for i in gt_list] # creates list of times from the gt_list.\n",
    "    if t in times:\n",
    "        gks_val = gt_list[times.index(t)][0] # assigns gks_val the corresponding gks value.\n",
    "        gks_E,gks_SST = gks_val,gks_val #Changes the global variable(s) for gks in the network.\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Vary backbone activity:\n",
    "    # List indicating times and implimentations. [ [ ['on',[bbs to turn on],'off',[bbs to turn off] ], time(ms)] , [...] ]\n",
    "    tot_learning_time = simLength - 2*num_test_phases*BB_len_test #Total learning time, i.e. time not spent in either test phase.\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # NOTE: The number of test phases was changed from 2 to 3 when adding post-NREM test to simulation, so tot_learning_time\n",
    "    # was changed appropriately.\n",
    "    # ---------------------------------------------\n",
    "    \n",
    "    num_osc = np.floor(tot_learning_time/osc_period) # Number of oscillations between BBs during learning.\n",
    "    \n",
    "    NREM_osc_times = list(range(t_start_NREM,t_start_NREMtest,osc_period)) #List of times for switching BBs in NREM.\n",
    "    REM_osc_times = list(range(t_start_REM,t_start_posttest,osc_period)) #List of times for switching BBs in REM.\n",
    "    osc_times = NREM_osc_times + REM_osc_times # Concatenates lists to create one list with all oscillation switch times.\n",
    "    \n",
    "    # Now that I have the times to switch the oscillations at, I need to put them into the form of \n",
    "    # [ [ ['on',[bbs to turn on],'off',[bbs to turn off] ], time(ms)] , [...] ].\n",
    "    \n",
    "    BB_onoff = [ ['on',[1],'off',[2]] , ['on',[2],'off',[1]] ] # Holds the 2 options for turning BBs on and off. \n",
    "    onoff_index = 0 #Used to assign index from BB_onoff. \n",
    "    bbt_list = [] # Will hold BB activity for learning times.\n",
    "    \n",
    "    for osc_t in osc_times: # Loops through times at which to switch BBs.\n",
    "        bbt_list.append([BB_onoff[onoff_index], osc_t ])\n",
    "        \n",
    "        if onoff_index == 0: #This keeps switching between BB_onoff indices.\n",
    "            onoff_index = 1\n",
    "        else:\n",
    "            onoff_index = 0\n",
    "        \n",
    "\n",
    "    insert_values = [[['on',[1],'off',[2]],0], [['on',[2],'off',[1]],BB_len_test], [['on',[1],'off',[2]],t_start_NREMtest],\n",
    "                     [['on',[2],'off',[1]],t_start_NREMtest+BB_len_test], [['on',[1],'off',[2]],t_start_posttest],\n",
    "                     [['on',[2],'off',[1]],t_start_posttest+BB_len_test]] #Values (for test phases) to be inserted.\n",
    "    \n",
    "    # Adding the testing phases to the list.\n",
    "    bbt_list.insert(0,insert_values[0]) # Inserting BB activity rules for pre-learning test.\n",
    "    bbt_list.insert(1,insert_values[1])\n",
    "    \n",
    "    \n",
    "    # It is more difficult to insert the post-NREM test phase because I have to know between exactly which oscillations\n",
    "    # to place it. To use np.where() I need to use arrays.\n",
    "    np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) # This eliminates the depreciation warning \n",
    "    # that arises from converting a \"ragged\" list into an array. I don't think this actually does anything harmful, so I will\n",
    "    # supress the warning like this.\n",
    "    \n",
    "    bbt_array = np.array(bbt_list) # convert to array.\n",
    "    \n",
    "    post_NREMtest_results = np.where(bbt_array[:,1] > t_start_NREMtest) # Object containing first-axis indices of elements in bbt_array where\n",
    "    # the time is greater than the start time of NREM test phase, but this object is not the indices themselves.\n",
    "    post_NREMtest_indices = post_NREMtest_results[0] # List containing the desired indices.\n",
    "    smallest_index = post_NREMtest_indices[0] # Grabs first index in list. This should be the index of the smallest time in\n",
    "    # bbt_list that comes after t_start_NREMtest.\n",
    "    \n",
    "    bbt_list.insert(smallest_index,insert_values[2]) # Inserts BB activity rules for post-NREM test.\n",
    "    bbt_list.insert(smallest_index+1,insert_values[3])\n",
    "    \n",
    "    \n",
    "    bbt_list.append(insert_values[-2]) # BB activity rules for post-learning test.\n",
    "    bbt_list.append(insert_values[-1])\n",
    "    \n",
    "                \n",
    "    times_bb = [i[1] for i in bbt_list]\n",
    "\n",
    "    if t in times_bb:\n",
    "        #print('onoff triggered at',t)\n",
    "        #'On' Operations:\n",
    "        on_off = bbt_list[times_bb.index(t)][0][0] #This grabs the 'on' string\n",
    "        bb_toswitch = bbt_list[times_bb.index(t)][0][1] #Grabs bb IDs to be turned on.\n",
    "        bb_onoff(on_off,bb_toswitch)\n",
    "        #'Off' Operations:\n",
    "        on_off = bbt_list[times_bb.index(t)][0][2] #This grabs the 'off' string\n",
    "        bb_toswitch = bbt_list[times_bb.index(t)][0][3] #Grabs bb IDs to be turned off.\n",
    "        bb_onoff(on_off,bb_toswitch)\n",
    "                \n",
    "        \n",
    "        \n",
    "    #Vary plasticity activity:\n",
    "    #List for turning off plasticity to and from specific bbs or LE neurons. [[LE,bb1,bb2],time] , ...\n",
    "    plas_onoff_list = [[[False,False,False],0], [[False,False,False],t_start_NREMtest], [[False,False,False],t_start_posttest]]\n",
    "    \n",
    "    if NABP_boo == True: #For NABP on.\n",
    "        plas_onoff_list.insert(1,[[True,True,True],t_start_NREM])\n",
    "        plas_onoff_list.insert(3,[[True,True,True],t_start_REM]) # Turns plasticity back on after post-NREM test phase\n",
    "    \n",
    "    # Loop through bbt_list used for BB activity and use it to create the plasticity activity list.\n",
    "    if NABP_boo == False: #Only adds these elements if NABP is supposed to be off. \n",
    "        for item in bbt_list:\n",
    "            if item[1] >= t_start_NREM and item[1] < t_start_NREMtest or item[1] >= t_start_REM and \\\n",
    "            item[1] < t_start_posttest: #If the time related to the command is in learning:\n",
    "                \n",
    "                if item[0][1] == [1] and item[0][3] == [2]:\n",
    "                    plas_onoff_list.insert(-1, [[True,True,False],item[1]] ) # Adds element for turning on BB1.\n",
    "                if item[0][1] == [2] and item[0][3] == [1]:\n",
    "                    plas_onoff_list.insert(-1, [[True,False,True],item[1]] ) # Adds element for turning on BB2.\n",
    "            \n",
    "    times_plas = [i[1] for i in plas_onoff_list]\n",
    "    if t in times_plas: #If the simulation reaches one of desired times:\n",
    "        plas_boo_list = plas_onoff_list[times_plas.index(t)][0] #Assigns plas_on the boolean associated with time t. \n",
    "        \n",
    "        for nrn in neurons: #Changes plas_on attribute for all neurons to match plas_boo_list vals. Uses index. \n",
    "            nrn.plas_on = plas_boo_list[int(nrn.backbone_ID)]\n",
    "        \n",
    "        \n",
    "'-------------------------------------------------------------------------'   \n",
    "        \n",
    "            \n",
    "def zeroTempVars(): #Zeros all variables to prevent accidental accumulation of unwanted terms. Just a safety measure, good habit.\n",
    "        #Note: Do not zero solutions, because they are used in calculating next solutions. \n",
    "        global neuron\n",
    "        for nrn in neurons:\n",
    "            nrn.Input_syn = 0 #Zeroed because ISyn must be added to account for input from multiple neurons. If Isyn was\n",
    "            # simply assigned, the Isyn would not accumulate. But now it must be zeroed. \n",
    "            \n",
    "            \n",
    "def plot(tarray,nc_matrix): #Plots neuron spikes\n",
    "    \n",
    "    #Plots pixel-plot of neuron connectivities.\n",
    "    fig, ax = plt.subplots(1,figsize=(12,12))\n",
    "    connplot = ax.imshow(nc_Matrix[:,:,1], extent=(0,numnrn,0,numnrn), cmap='cividis') #Generates pixel-like plot of connection strengths.\n",
    "    ax.grid(which='both', axis='both', color='black', linewidth=1)\n",
    "    ax.set_xticks(np.arange(0,numnrn,1)) #Sets lines for axes, off of which the grid is based.\n",
    "    ax.set_yticks(np.arange(0,numnrn,1))\n",
    "    ax.set_title('Neuron Connectivity Graphic', size=20)\n",
    "    ax.set_xlabel('Postsynaptic Neuron ID',size=12)\n",
    "    ax.set_ylabel('(numnrn - Presynaptic Neuron ID)',size=12);\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Plots Raster plot of neuron spikes.\n",
    "    fig, ax1 = plt.subplots(1,figsize=(20,5))\n",
    "    start = 0/stepSize #time to start plotting from.\n",
    "    \n",
    "    list1,list2 = [],[]\n",
    "    for nrn in neurons: #Seperates neuron IDs into a list of inhibtory and excitory.\n",
    "        if nrn.category == 'SST' or nrn.category == 'PV+':\n",
    "            list1.append(nrn.ID)\n",
    "        if nrn.category == 'Excitatory':\n",
    "            list2.append(nrn.ID)\n",
    "    neuron_list = list1 + list2 #Adds the two lists such that inhibitory neurons come first and excitory second.\n",
    "    \n",
    "    for index, ID in enumerate(neuron_list):\n",
    "        spikeTimes_toplot = []\n",
    "        \n",
    "        for t in neurons[ID].spikeTimes: # Runs through spike times of every neuron in 'neuron_list', starting with inhibitory.3\n",
    "            if t >= start: #only selects times greater than 'start' for plotting.\n",
    "                spikeTimes_toplot = np.append(spikeTimes_toplot,t*stepSize)\n",
    "        index_plot_list = [index]*len(spikeTimes_toplot)\n",
    "        ax1.scatter((spikeTimes_toplot),index_plot_list,c=neurons[ID].color,s=2) # c controls nrn dot color, s controls dot size.\n",
    "        \n",
    "    ax1.set_title('Raster Plot | ACh Levels: gks_E={0}, gks_SST={1} | Idrive_E={2}, Idrive_SST={3}'\n",
    "                  .format(gks_E,gks_SST,Idrive_min,Idrive_SST))\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    ax1.set_ylabel('Red - SST, Blue - Excitatory')\n",
    "\n",
    "    \n",
    "    \n",
    "def sort_gsyn(item): #Function for returning the gsyn of a neuron\n",
    "    # Built to handle nrn simply as an object, and also as a list [nrn_object,index_val].\n",
    "    if isinstance(item,tuple): #if item is a tuple.\n",
    "        val = item[0].gsyn    \n",
    "    elif isinstance(item,neurons[0].__class__): #If this item is object type of a neuron.\n",
    "        val = item.gsyn\n",
    "    elif isinstance(item, list): #If item is a list.\n",
    "        val = item[0].gsyn\n",
    "    else:\n",
    "        print(\"Exception: val=0 in sort_gsyn.\")\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "\n",
    "def sort_Idrive(nrn):\n",
    "    return nrn.Idrive\n",
    "\n",
    "\n",
    "def sort_bb(nrn):\n",
    "    val = nrn.backbone_ID\n",
    "    return val\n",
    "\n",
    "def sort_bb_tuple(list1):\n",
    "    val = list1[0].backbone_ID\n",
    "    return val\n",
    "                    \n",
    "def sort_tuple(tup): #Sorts tuple by first element.\n",
    "    val = tup[0]\n",
    "    return val\n",
    "\n",
    "def sort_LE_bycolor(LE_nrn): # Function used to sort LE neurons by color. Green first, then blue, then pink, then purple.\n",
    "    val = 0\n",
    "    if LE_nrn.scatter_quad_color == 'green':\n",
    "        val = 1\n",
    "    if LE_nrn.scatter_quad_color == 'blue':\n",
    "        val = 2\n",
    "    if LE_nrn.scatter_quad_color == 'pink':\n",
    "        val = 3\n",
    "    if LE_nrn.scatter_quad_color == 'purple':\n",
    "        val = 4\n",
    "    \n",
    "    return val\n",
    "    \n",
    "\n",
    "    \n",
    "def plot_raster(start_time, nc_Matrix): # Plots raster plot.\n",
    "    plot_raster_boo = True\n",
    "    \n",
    "    list_i,list_bb,list_LE = [],[],[]\n",
    "    for nrn in neurons: #Seperates neuron IDs into a list of inhibtory and excitory.\n",
    "        if nrn.category == 'SST' or nrn.category == 'PV+':\n",
    "            list_i.append(nrn) #Appends full nrn object (not just the ID) to make sorting by gsyn easier.\n",
    "        if nrn.category == 'Excitatory' and nrn.backbone_ID in bbs_toplot:\n",
    "            list_bb.append(nrn)\n",
    "        if nrn.category == 'Excitatory' and nrn.backbone_ID == 0: # If an LE neuron\n",
    "            list_LE.append(nrn)\n",
    "            \n",
    "    list_bb.sort(key=sort_bb) # Sorts list by key function. Can reverse order of sort with reverse=True. \n",
    "    list_i.sort(key=sort_bb)\n",
    "    list_LE.sort(key=sort_LE_bycolor, reverse=True)\n",
    "    \n",
    "    neuron_list = list_i + list_LE + list_bb #Adds the two lists such that inhibitory neurons come first and excitory second.\n",
    "    \n",
    "    \n",
    "    if plot_raster_boo: #Plots raster plot of neuron spikes. Ordered with inhibitory on the bottom, followed by sorted E neurons.\n",
    "        fig, ax1 = plt.subplots(1,figsize=(20,5))\n",
    "        start = start_time/stepSize #time to start plotting from.\n",
    "\n",
    "        for index, nrn in enumerate(neuron_list):\n",
    "            spikeTimes_toplot = []\n",
    "\n",
    "            for t in nrn.spikeTimes: # Runs through spike times of every neuron in 'neuron_list', starting with inhibitory.3\n",
    "                if t >= start: #only selects times greater than 'start' for plotting.\n",
    "                    spikeTimes_toplot = np.append(spikeTimes_toplot,t*stepSize)\n",
    "\n",
    "            index_plot_list = [index]*len(spikeTimes_toplot)\n",
    "            \n",
    "            color = nrn.color # Color of spikes plotted for this neuron on raster plot.\n",
    "            # Uses quad group color if neuron is LE neuron:\n",
    "            if nrn.backbone_ID == 0:\n",
    "                color = nrn.scatter_quad_color\n",
    "                \n",
    "            ax1.scatter((spikeTimes_toplot),index_plot_list,c=color,s=2) # c controls nrn dot color, s controls dot size.\n",
    "\n",
    "        ax1.set_title('Raster Plot')\n",
    "        ax1.set_xlabel('Time (ms)')\n",
    "        ax1.set_ylabel('Neurons Sorted by Group');\n",
    "        fig.savefig(directory+'Raster.pdf',format='pdf') #Saves figure as a pdf file to Zochowski Lab under directory. \n",
    "        fig.savefig(directory+'Raster.png',format='png')\n",
    "        \n",
    "    \n",
    "    \n",
    "    reorder_list = []\n",
    "\n",
    "    for nrn in neuron_list:\n",
    "        reorder_list.append(nrn.ID)\n",
    "\n",
    "    reorder_list.reverse() #Reverses order to match the setup of raster plot.\n",
    "    reor_mat = nc_Matrix[reorder_list] # Creates new matrix reor_mat that is the reordered version of nc_Matrix.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def plot_mat_onlyE_b(t_ind): # Function that creates new connection and weight matrices from scratch and includes only excitatory neurons.\n",
    "    # NOTE: the axis labelling does not match nrn.ID and is only for use with the matrix.\n",
    "    plot_conn_sorted = False\n",
    "    plot_plas_sorted = True\n",
    "    \n",
    "    #Create list of only E neurons.\n",
    "    neurons_E = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.category == 'Excitatory':\n",
    "            neurons_E.append(nrn)\n",
    "    neurons_E.sort(key=sort_bb,reverse=True) # Sorts list by key function. Can reverse order of sort with reverse=True. \n",
    "\n",
    "    conn_mat_E = np.empty((len(neurons_E),len(neurons_E)))  # Initialize connection matrix.\n",
    "    w_mat_E = np.empty((len(neurons_E),len(neurons_E))) # Initialize weight matrix.\n",
    "    \n",
    "    for index,nrn in enumerate(neurons_E): #runs through sorted list of E neurons.\n",
    "        connections_out = nrn.connections # Creates 2D lists of connections and connection IDs.\n",
    "        conn_weights = nrn.connectionWeights #1D list of connection weights for outgoing connections\n",
    "        zip_list = list(zip(neurons,connections_out,conn_weights)) #puts nrn connection val, and weight in tuples.\n",
    "        zip_list.sort(key=sort_bb_tuple,reverse=True) #Sorts tuples based on gsyn of nrns. \n",
    "        sorted_conn_out = np.array([conn for nrn,conn,weight in zip_list]) #extracts connections sorted by gsyn. This sorts of the columns in the conn matrix.d\n",
    "        sorted_weight = np.array([weight for nrn,conn,weight in zip_list]) #extracts weight sorted by gsyn. \n",
    "\n",
    "        for postsyn_ID,conn in sorted_conn_out:\n",
    "            if neurons[int(postsyn_ID)].category != 'Excitatory': #Eliminates connections to I neurons from list.\n",
    "                sorted_weight = np.delete(sorted_weight,np.where(sorted_conn_out[:,0]==postsyn_ID),axis=0) # Deletes element from connection weights list. THIS MUST COME BEFORE deleting connections out element.\n",
    "                sorted_conn_out = np.delete(sorted_conn_out,np.where(sorted_conn_out[:,0]==postsyn_ID),axis=0) #Deletes terms that are not going to excitatory neurons.\n",
    "        \n",
    "        conn_mat_E[index] = sorted_conn_out[:,1] #assigns rows in matrix as modified connection list.\n",
    "        w_mat_E[index] = sorted_weight #These two matrices are already sorted once all rows are put in!\n",
    "\n",
    "    \n",
    "    if plot_conn_sorted:\n",
    "        #Plots sorted pixel-plot of neuron connectivities.\n",
    "        fig, ax = plt.subplots(1,figsize=(10,10))\n",
    "        connplot = ax.imshow(conn_mat_E, extent=(0,len(neurons_E),0,len(neurons_E)), cmap='cividis') #Generates pixel-like plot of connection strengths.\n",
    "        ax.grid(which='both', axis='both', color='black', linewidth=1)\n",
    "        ax.set_xticks(np.arange(0,len(neurons_E),1)) #Sets lines for axes, off of which the grid is based.\n",
    "        ax.set_yticks(np.arange(0,len(neurons_E),1))\n",
    "        ax.tick_params(labelbottom=False,labelleft=False)#Turns off number labels\n",
    "        ax.set_title('Excitatory Only Neuron Connectivity Graphic - Sorted', size=20)\n",
    "        ax.set_xlabel('Postsynaptic E Neuron',size=12)\n",
    "        ax.set_ylabel('Presynaptic E Neuron (Raster Plot Order)',size=12);\n",
    "\n",
    "    #Creates custom cmap:\n",
    "    colors_array = np.array(['purple','white','darkgreen'])\n",
    "    bounds_array = np.array([0,1,w_max])\n",
    "    norm = plt.Normalize(min(bounds_array),max(bounds_array))\n",
    "    tuples = list(zip(map(norm,bounds_array),colors_array))\n",
    "    cmap = colors.LinearSegmentedColormap.from_list(\"my cmap\",tuples)\n",
    "\n",
    "    if plot_plas_sorted:\n",
    "        # Plots synaptic weight matrix and colorbar\n",
    "        fig, ax_w = plt.subplots(1,figsize=(12,12))\n",
    "        weightplot = ax_w.imshow(w_mat_E,extent=(0,len(neurons_E),0,len(neurons_E)), norm=norm, cmap=cmap)\n",
    "        ax_w.grid(which='both', axis='both', color='black', linewidth=1)\n",
    "        ax_w.set_xticks(np.arange(0,len(neurons_E),1)) #Sets lines for axes, off of which the grid is based.\n",
    "        ax_w.set_yticks(np.arange(0,len(neurons_E),1))\n",
    "        ax_w.tick_params(labelbottom=False,labelleft=False)#Turns off number labels\n",
    "        cbar = fig.colorbar(weightplot,shrink=0.8)\n",
    "        cbar.set_label('Synaptic Weight Multiplier')\n",
    "        ax_w.set_title('Excitatory Synaptic Weights - Sorted | t={0}'.format(int(t_ind*stepSize)), size=20)\n",
    "        ax_w.set_xlabel('Postsynaptic E Neuron',size=12)\n",
    "        ax_w.set_ylabel('Presynaptic E Neuron (Raster Plot Order)',size=12);\n",
    "    \n",
    "    \n",
    "    return w_mat_E,conn_mat_E\n",
    "    \n",
    "    \n",
    "def plot_bb_mat(bbs_toplot,show_mats): #PLots seperate E conn and plas matrices for each bb. bb_toplot is list of bb IDs to be plotted.\n",
    "    # Note bbs must be in order: [1,2,3,...] or else will get labeled incorrectly on matrices. Show_mats is boolean, True to\n",
    "    # plot any matrices, False not to. \n",
    "    plot_conn = False\n",
    "    plot_plas = True\n",
    "    \n",
    "    #Create list of only E neurons.\n",
    "    neurons_bb, neurons_LE = [],[]\n",
    "#     for nrn in neurons:\n",
    "#         if nrn.category == 'Excitatory':\n",
    "#             neurons_E.append(nrn)\n",
    "#     neurons_E.sort(key=sort_bb,reverse=True)\n",
    "#     neurons_E = np.array(neurons_E) #Changing to an array.\n",
    "    \n",
    "    \n",
    "    for nrn in neurons: #Seperates neuron IDs into a list of inhibtory and excitory.\n",
    "        if nrn.category == 'Excitatory' and nrn.backbone_ID in bbs_toplot:\n",
    "            neurons_bb.append(nrn)\n",
    "        if nrn.category == 'Excitatory' and nrn.backbone_ID == 0: # If an LE neuron\n",
    "            neurons_LE.append(nrn)\n",
    "            \n",
    "    neurons_bb.sort(key=sort_bb) # Sorts list by key function. Can reverse order of sort with reverse=True. \n",
    "    neurons_LE.sort(key=sort_LE_bycolor)\n",
    "    \n",
    "    neurons_E = neurons_bb + neurons_LE  #Adds the two lists such that BB neurons come first and LE second.\n",
    "    \n",
    "    \n",
    "    conn_mat_list = [] #list to store conn matrices \n",
    "    w_mat_list = []\n",
    "    \n",
    "    \n",
    "    for bb in bbs_toplot:\n",
    "        #Selecting only bb and lower E neurons.\n",
    "        bb_nrns = []\n",
    "        for nrn in neurons_E:\n",
    "            if nrn.backbone_ID == 0 or nrn.backbone_ID == bb:\n",
    "                bb_nrns.append(nrn)\n",
    "  \n",
    "        conn_mat = np.empty((len(bb_nrns),len(bb_nrns)))\n",
    "        w_mat = np.empty((len(bb_nrns),len(bb_nrns)))\n",
    "        \n",
    "        for index,nrn in enumerate(bb_nrns): #runs through sorted list of bb nrns\n",
    "            connections_out = nrn.connections # Creates 2D lists of connections and connection IDs.\n",
    "            conn_weights = nrn.connectionWeights #1D list of connection weights for outgoing connections\n",
    "            zip_list = list(zip(neurons,connections_out,conn_weights)) #puts nrn connection val, and weight in tuples.\n",
    "            zip_list.sort(key=sort_bb_tuple, reverse=True) #Sorts tuples based on gsyn of nrns. \n",
    "            sorted_conn_out = np.array([conn for nrn,conn,weight in zip_list]) #extracts connections sorted by gsyn. This sorts of the columns in the conn matrix.d\n",
    "            sorted_weight = np.array([weight for nrn,conn,weight in zip_list]) #extracts weight sorted by gsyn. \n",
    "\n",
    "            for postsyn_ID,conn in sorted_conn_out:\n",
    "                if neurons[int(postsyn_ID)].category != 'Excitatory' or (neurons[int(postsyn_ID)].backbone_ID != 0 and neurons[int(postsyn_ID)].backbone_ID != bb): #Eliminates connections to I neurons and other bb\n",
    "                    sorted_weight = np.delete(sorted_weight,np.where(sorted_conn_out[:,0]==postsyn_ID),axis=0) # Deletes element from connection weights list. THIS MUST COME BEFORE deleting connections out element.\n",
    "                    sorted_conn_out = np.delete(sorted_conn_out,np.where(sorted_conn_out[:,0]==postsyn_ID),axis=0) #Deletes terms that are not going to excitatory neurons.\n",
    "\n",
    "            conn_mat[index] = sorted_conn_out[:,1] #assigns rows in matrix as modified connection list.\n",
    "            w_mat[index] = sorted_weight #These two matrices are already sorted once all rows are put in!\n",
    "        \n",
    "        \n",
    "        if plot_conn and show_mats:\n",
    "            #Plots sorted pixel-plot of neuron connectivities.\n",
    "            fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "            connplot = ax.imshow(conn_mat, extent=(0,len(bb_nrns),0,len(bb_nrns)), cmap='cividis') #Generates pixel-like plot of connection strengths.\n",
    "            ax.grid(which='both', axis='both', color='black', linewidth=1)\n",
    "            ax.set_xticks(np.arange(0,len(bb_nrns),1)) #Sets lines for axes, off of which the grid is based.\n",
    "            ax.set_yticks(np.arange(0,len(bb_nrns),1))\n",
    "            ax.tick_params(labelbottom=False,labelleft=False)#Turns off number labels\n",
    "            ax.set_title('E Only Connectivity Matrix, bb#{0}'.format(bb), size=20)\n",
    "            ax.set_xlabel('Postsynaptic E Neuron',size=12)\n",
    "            ax.set_ylabel('Presynaptic E Neuron (Raster Plot Order)',size=12);\n",
    "\n",
    "        #Creates custom cmap:\n",
    "        colors_array = np.array(['purple','white','darkgreen'])\n",
    "        bounds_array = np.array([0,1,w_max])\n",
    "        norm = plt.Normalize(min(bounds_array),max(bounds_array))\n",
    "        tuples = list(zip(map(norm,bounds_array),colors_array))\n",
    "        cmap = colors.LinearSegmentedColormap.from_list(\"my cmap\",tuples)\n",
    "\n",
    "        if plot_plas and show_mats:\n",
    "            # Plots synaptic weight matrix and colorbar\n",
    "            fig, ax_w = plt.subplots(1,figsize=(10,10))\n",
    "            weightplot = ax_w.imshow(w_mat,extent=(0,len(bb_nrns),0,len(bb_nrns)), norm=norm, cmap=cmap)\n",
    "            ax_w.grid(which='both', axis='both', color='black', linewidth=1)\n",
    "            ax_w.set_xticks(np.arange(0,len(bb_nrns),1)) #Sets lines for axes, off of which the grid is based.\n",
    "            ax_w.set_yticks(np.arange(0,len(bb_nrns),1))\n",
    "            ax_w.tick_params(labelbottom=False,labelleft=False)#Turns off number labels\n",
    "            cbar = fig.colorbar(weightplot,shrink=0.8)\n",
    "            cbar.set_label('Synaptic Weight Multiplier')\n",
    "            ax_w.set_title('E Synaptic Weights, bb#{0}'.format(bb), size=20)\n",
    "            ax_w.set_xlabel('Postsynaptic E Neuron',size=12)\n",
    "            ax_w.set_ylabel('Presynaptic E Neuron (Raster Plot Order)',size=12);\n",
    "            fig.savefig(directory+'Plasticity Matrix bb#{0}.pdf'.format(bb),format='pdf')\n",
    "            fig.savefig(directory+'Plasticity Matrix bb#{0}.png'.format(bb),format='png')\n",
    "            \n",
    "        conn_mat_list.append(conn_mat) #stores matrix in list. Stored in same order as bb_toplot.\n",
    "        w_mat_list.append(w_mat)\n",
    "        \n",
    "    return\n",
    "    \n",
    "    \n",
    "def plot_voltage(V_data): #Plots the voltages of all neurons.\n",
    "    fig, stimplot = plt.subplots(1,figsize=(15,5))\n",
    "    stimplot.set_xlabel('time (ms)')\n",
    "    stimplot.set_ylabel('Voltage (mV)')\n",
    "    stimplot.set_title('Neuron Voltages')\n",
    "\n",
    "    start = int(0*Ntimes) #index for viewing only portions of graph. Set to 0*Ntimes for normal graph.\n",
    "    end = int(simLength*Ntimes)\n",
    "    for index,V_list in enumerate(V_data):\n",
    "        stimplot.plot(tarray[start:end],V_list[start:end],color=neurons[index].color,label='Idrive {0}'.format(neurons[index].Idrive))\n",
    "        \n",
    "    stimplot.legend()\n",
    "    tens = np.zeros(len(tarray))\n",
    "    tens += spikeThreshold\n",
    "    stimplot.plot(tarray[start:end],tens[start:end],'--r')\n",
    "    \n",
    "    \n",
    "def plot_weight(w_data): #Plots the synaptic weights of all connections of all neurons over time.\n",
    "    fig, stimplot = plt.subplots(1,figsize=(15,5))\n",
    "    stimplot.set_xlabel('time (ms)')\n",
    "    stimplot.set_ylabel('Synaptic Weight')\n",
    "    stimplot.set_title('Change of synaptic weights over time')\n",
    "\n",
    "    start = int(0*Ntimes) #index for viewing only portions of graph. Set to 0*Ntimes for normal graph.\n",
    "    end = int(simLength*Ntimes)\n",
    "    for index,w_list in enumerate(w_data):\n",
    "        w_list = np.delete(w_list,index,axis=1) #This removes the nonexistant \"connection to self\" weight variable.\n",
    "        stimplot.plot(tarray[start:end],w_list[start:end],color=neurons[index].color,label='Presyn nrn {0}'.format(neurons[index].ID))\n",
    "        \n",
    "    stimplot.legend()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def beep(makeSound): #Makes a series of beeps. Meant to signal end of code-running. \n",
    "    if makeSound: #When True, plays beeps.\n",
    "        winsound.Beep(349,500)\n",
    "        winsound.Beep(440,500)\n",
    "        winsound.Beep(523,500)\n",
    "        \n",
    "        \n",
    "def Avg_MPC(t_start): #Prints the average mean phase coherence over the entire network. 1 means perfect coherence, i.e. all neurons are locked in phase. \n",
    "    #Be CAREFUL to check that the stepSize referenced in this function matches that used in the simulation!!\n",
    "    # t_start gives a time at which after to calculate, allowing for skipping of transients. t_start is in ms. \n",
    "    MPC_list = []\n",
    "    for nrnb in neurons:\n",
    "        for nrna in neurons:\n",
    "            if nrnb.ID != nrna.ID and len(nrna.spikeTimes) > 0:\n",
    "                phi_list = [] \n",
    "                MPC_ab_complex = 0 #initiate variables.\n",
    "                for t_bk in nrnb.spikeTimes: \n",
    "                    if t_bk*stepSize >= t_start:\n",
    "                        t_ak = max(np.where(nrna.spikeTimes < t_bk, nrna.spikeTimes, 0)) #Finds the latest spiketime from nrna that is\n",
    "                        # smaller than nrnb.\n",
    "                        t_ak1 = min(np.where(nrna.spikeTimes >= t_bk, nrna.spikeTimes, nrna.spikeTimes[-1]+1))# Finds earliest spiketime\n",
    "                        # after or equal to spike from nrnb. When one of the neurons is not spiking, edge case assigned. \n",
    "                        if t_ak != 0 and t_ak1 <= nrna.spikeTimes[-1]: #Eliminating edge cases.\n",
    "                            phi_k = 2*round(np.pi,5)*((t_bk - t_ak)/(t_ak1 - t_ak)) #Calculating phase difference between spikes.\n",
    "                            phi_list = np.append(phi_list,phi_k)\n",
    "\n",
    "                            #print(nrnb.ID,t_bk,'  ',nrna.ID, t_ak ,t_ak1)\n",
    "\n",
    "                for phi_k in phi_list:\n",
    "                    MPC_ab_complex += (1/len(phi_list))*np.e**(complex(0,1)*phi_k) #MPC between neurons a and b. \n",
    "\n",
    "                MPC_ab = abs(MPC_ab_complex) # Magnitude of complex number\n",
    "                MPC_list = np.append(MPC_list, MPC_ab)\n",
    "                \n",
    "    MPC_avg = sum(MPC_list)/len(MPC_list)\n",
    "    print('Average MPC Across Network: ',round(MPC_avg,5))\n",
    "    \n",
    "    \n",
    "def BS(t_start): #Measures burst synchrony, how well network of neurons fire together. 1 is all firing simultaneously,\n",
    "    # 0 is complete randomness. t_start is the time (in ms) at which to start running calculations. \n",
    "    calc_t = int(t_start/stepSize) #time at which to start synchronization measure.\n",
    "    V_all,V2_all = 0,0 #Average voltage of all neurons, average voltage squared.  \n",
    "    #V(t)_tavg = (1/(tarray[-1]-tarray[calc_t]))\n",
    "\n",
    "    for t in tarray[calc_t:-1]: #Integration loop. Integrates over time from calc_t to end of runtime.\n",
    "        t_ind = int(t/stepSize) #Index for grabbing correct voltages. \n",
    "        V_all += sum(V_data[:,t_ind])/len(neurons) * stepSize # Integrating V(t)\n",
    "        V2_all += (sum(V_data[:,t_ind])/len(neurons))**2 * stepSize # Integrating V(t)^2\n",
    "\n",
    "    V_tavg = V_all/(tarray[-1]-tarray[calc_t]) #Time average of mean voltage from all neurons. \n",
    "    V2_tavg = V2_all/(tarray[-1]-tarray[calc_t])\n",
    "\n",
    "    V_avg_var = V2_tavg - V_tavg**2 # Equation (2) from link above. Calculates variance of \n",
    "\n",
    "    V_i_var = 0 # Average of Variances of all neurons.\n",
    "    for nrn in neurons: #Calculating sum of variances of all neurons.  \n",
    "        V_i, V2_i = 0,0 #Voltage and voltage squared of ith neuron.\n",
    "        for t in tarray[calc_t:-1]: #Integration loop. Analagous to above loop.\n",
    "            t_ind = int(t/stepSize)\n",
    "            V_i += V_data[nrn.ID,t_ind] * stepSize\n",
    "            V2_i += V_data[nrn.ID,t_ind]**2 * stepSize\n",
    "\n",
    "        V_i_var += V2_i/(tarray[-1]-tarray[calc_t]) - (V_i/(tarray[-1]-tarray[calc_t]))**2 # Equation (3).\n",
    "    V_i_var = V_i_var/len(neurons) #Diving by N. \n",
    "\n",
    "    BS = np.sqrt(V_avg_var/V_i_var) #Equation (4), the measure of Burst Synchrony.\n",
    "    print('Burst Synchrony Measure: ',round(BS,5))\n",
    "    \n",
    "    \n",
    "def frequency(): #Finds the average frequency of neurons firing in the network.\n",
    "    freq_list = []\n",
    "    for nrn in neurons:\n",
    "        if len(nrn.spikeTimes) > 1: #Avoids divide by zero errors for neurons with only one spike.\n",
    "            freq_list.append((len(nrn.spikeTimes)-1)*1000/(stepSize*(nrn.spikeTimes[-1]-nrn.spikeTimes[0]))) # Makes a list of average frequency for each neuron.\n",
    "    try: #Handles the divide by zero error when there are no spikes.\n",
    "        freq_avg = sum(freq_list)/len(freq_list) #Averages this list.\n",
    "    except ZeroDivisionError:\n",
    "        freq_avg = 0\n",
    "    print('Average Frequency: ',round(freq_avg,4),'Hz')\n",
    "    \n",
    "    \n",
    "def frequency_E(): # Function for finding the frequency of excitatory neurons in a network.\n",
    "    freq_list = []\n",
    "    for nrn in neurons:\n",
    "        if len(nrn.spikeTimes) > 1 and nrn.category == 'Excitatory': #Avoids divide by zero errors for neurons with only one spike.\n",
    "            freq_list.append((len(nrn.spikeTimes)-1)*1000/(stepSize*(nrn.spikeTimes[-1]-nrn.spikeTimes[0]))) # Makes a list of average frequency for each neuron.\n",
    "    try: #Handles the divide by zero error when there are no spikes.\n",
    "        freq_avg = sum(freq_list)/len(freq_list) #Averages this list.\n",
    "    except ZeroDivisionError:\n",
    "        freq_avg = 0\n",
    "    print('Frequency of Excitatory: ',round(freq_avg,4),'Hz')\n",
    "    \n",
    "    \n",
    "\n",
    "def frequency_Theta(): #This function measures the frequency of theta oscillations in a network. A theta oscillation is defined\n",
    "    # by a given number of neurons that fire within a given time interval.\n",
    "    # NOTE: in order for a good result, theta spikes must be consistent.\n",
    "    # NOTE: For higher Idrive_E (i.e. when burst firing occurs in theta spikes), def_time will need to be lowered in order to\n",
    "    # accurately capture spiketimes and reset during less active periods.\n",
    "    def_numnrn = 40 #The number of neurons that must fire within an interval to be recorded as an oscillation.\n",
    "    def_time = 10 #The time interval for the neurons to fire in (ms).\n",
    "    \n",
    "    time_list = np.arange(0,int(len(tarray)*stepSize)) #This is an array of miliseconds. each element is a time that a theta oscillation will be tested for.\n",
    "    spike_boo = False # Boolean for counting spikes.\n",
    "    theta_spiketimes = []\n",
    "    num_theta_spikes = 0\n",
    "    \n",
    "    for t in time_list:\n",
    "        spikeCount = 0 #Counts number of neurons that spike in interval.\n",
    "        for nrn in neurons:\n",
    "            spikeTimes_array = stepSize*np.array(nrn.spikeTimes) #Changes from list to array and puts time vals in ms. \n",
    "            num_array = spikeTimes_array[abs(spikeTimes_array-t) <= def_time/2] #This is the meat and beans. Selects all spike times that fall within def_time/2 of the time t.\n",
    "            spikeCount += len(num_array) # Gathers the number of spikes recorded per neuron inside the interval.   \n",
    "                \n",
    "        if spikeCount >= def_numnrn and spike_boo == False: #If the spikecount is high enough to qualify as a theta spike.\n",
    "            theta_spiketimes.append(t) \n",
    "            spike_boo = True\n",
    "            \n",
    "        elif spikeCount <= 5 and spike_boo == True: #resets spike_boo when there is a segment with no spiking.\n",
    "            spike_boo = False\n",
    "                    \n",
    "    print('Number of Theta Spikes: ',len(theta_spiketimes))\n",
    "    calc_freq_list = theta_spiketimes[1:] #Takes out the first spike to be a little more accurate (does it make it better?)\n",
    "    try:\n",
    "        freq = (len(calc_freq_list)-1)*1000/(calc_freq_list[-1] - calc_freq_list[0]) #Calculates frequency in Hz (1/s). \n",
    "    except IndexError:\n",
    "        freq = 0\n",
    "    print('Frequency of Theta Oscillation: ',round(freq,2),'Hz')\n",
    "    \n",
    "    \n",
    "def strengthen_backbone(): # Increases strength of all connections between backbone neurons.\n",
    "    global neuron\n",
    "    for nrn1 in neurons: # Loops over all possible pairs of neurons.\n",
    "        for nrn2 in neurons:\n",
    "            if nrn1.backbone_ID == nrn2.backbone_ID and nrn1.backbone_ID not in [-1,0] and nrn1.connections[int(nrn2.ID)][1] == 1: #if both neurons are to be part of the same backbone and are actually connected.\n",
    "                nrn1.connectionWeights[int(nrn2.ID)] = 2.5 # Strengthens connections between neurons in the same BB.\n",
    "                \n",
    "                \n",
    "                \n",
    "def strengthen_LE(): # Gives the LE neurons with largest number of connections from each backbone an increased connection weight\n",
    "    # for all those connections, as well as a smaller connection weight for the least connected LE neurons. NOTE that this is \n",
    "    # based off of quad colors, which takes into account the number of connections from both bbs. So, in reality, the LE\n",
    "    # neurons with most connections to one bb and also least connections to the other bb have their plasticity weights changed\n",
    "    # for those connections. These are the blue and green quad color labeled LE neurons.\n",
    "    # This function should be run after init_quad_colors() but before the t_ind loop for the simulation begins.\n",
    "    global neuron\n",
    "    bg_str = 0 # The amount to strengthen connections from BB to blue and green LE neurons.\n",
    "    pu_weak = 0 # The amount to weaken connections from both BBs to purple LE neurons.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "            \n",
    "    for nrn_LE in LE_neurons: # Changes plasticity weight based on quad color.\n",
    "        for nrn in neurons:\n",
    "            if nrn.connections[int(nrn_LE.ID)][1] == 1:\n",
    "                \n",
    "                if nrn.backbone_ID == 1: # For connections from a bb1 neuron to LE neuron. \n",
    "                    if nrn_LE.scatter_quad_color == 'blue':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += bg_str # Strenghthens connections to LE neurons that have many\n",
    "                        # synapses from bb1 and few synapses from bb2.\n",
    "                    if nrn_LE.scatter_quad_color == 'green':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += 0 # Weakens connections to LE neurons that have many \n",
    "                        # synapses from bb2 and few synapses from bb1.\n",
    "                    if nrn_LE.scatter_quad_color == 'purple': #Weakens connections to LE neurons strongly connected to both BBs.\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += -pu_weak\n",
    "                        \n",
    "                if nrn.backbone_ID == 2: # For connections from a bb2 neuron to LE neuron. \n",
    "                    if nrn_LE.scatter_quad_color == 'blue':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += 0 # Strenghthens connections to LE neurons that have many\n",
    "                        # synapses from bb1 and few synapses from bb2.\n",
    "                    if nrn_LE.scatter_quad_color == 'green':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += bg_str # Weakens connections to LE neurons that have many \n",
    "                        # synapses from bb2 and few synapses from bb1.\n",
    "                    if nrn_LE.scatter_quad_color == 'purple': #Weakens connections to LE neurons strongly connected to both BBs.\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += -pu_weak\n",
    "                        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "           \n",
    "        \n",
    "def plot_plasvstime(): # Function that uses nrn.cw_in_history to plot network plasticity vs time. First plot is for E-E\n",
    "    # connections, the avg plasticity per connection type group (like BB->BB, BB->LE, LE->BB, and LE->LE). Should be called\n",
    "    # after simulation is finished.\n",
    "    \n",
    "    num_groups = 4 # Number of connection group types. Currently there are four: BB->BB, BB->LE, LE->BB, LE->LE.\n",
    "    \n",
    "    avg_plas_array = np.zeros((len(bbs_toplot),num_groups,simLength-spike_skip_time)) # Array to store averages between groups.\n",
    "    # Each row is for each BB, and within each row looks like: [BB->BB, BB->LE, LE->BB, LE->LE]. Stored for every ms.\n",
    "    \n",
    "    counts = np.zeros((len(bbs_toplot),num_groups)) # Array to hold counts for number of connections falling into each category\n",
    "    # so that the average value can be found later.\n",
    "    \n",
    "    for BB_index, BB_ID in enumerate(bbs_toplot): # Loops through backbones\n",
    "        \n",
    "        for nrn in neurons:\n",
    "\n",
    "            if nrn.category == 'Excitatory':\n",
    "                \n",
    "                for postsyn_ID, conn in nrn.connections:\n",
    "                    \n",
    "                    if neurons[int(postsyn_ID)].category == 'Excitatory' and conn == 1: # For E-E connections\n",
    "                        \n",
    "                        cw_out_hist = nrn.cw_out_history # Grabs full data from presyn neuron.\n",
    "\n",
    "                        # list to separate the conn weights from the times in cw_out_hist. This is necessary because I later\n",
    "                        # need to convert the cw list to an array and this can only be done right if the nested list sizes\n",
    "                        # are equal.\n",
    "                        cw_out_list = []\n",
    "\n",
    "                        for (weights, time) in cw_out_hist: # weights is a list, time is a scalar in ms. \n",
    "                            cw_out_list.append(weights)\n",
    "\n",
    "                        cw_out_array = np.array(cw_out_list) # Needs to be an array for indexing over dimensions.\n",
    "\n",
    "                        postsyn_cws = cw_out_array[:,int(postsyn_ID)] # Extracts conn weights over time to correct postsyn \n",
    "                        # neuron. Thus postsyn_cws is a 1D list of length (simLength - spike_skip_time).\n",
    "                            \n",
    "                        if nrn.backbone_ID == BB_ID and neurons[int(postsyn_ID)].backbone_ID == BB_ID: # BB->BB\n",
    "                            \n",
    "                            counts[BB_index][0] += 1\n",
    "                            avg_plas_array[BB_index][0] += postsyn_cws\n",
    "                            \n",
    "                        if nrn.backbone_ID == BB_ID and neurons[int(postsyn_ID)].backbone_ID == 0: # BB->LE\n",
    "                            \n",
    "                            counts[BB_index][1] += 1\n",
    "                            avg_plas_array[BB_index][1] += postsyn_cws\n",
    "                            \n",
    "                        if nrn.backbone_ID == 0 and neurons[int(postsyn_ID)].backbone_ID == BB_ID: # LE->BB\n",
    "                            \n",
    "                            counts[BB_index][2] += 1\n",
    "                            avg_plas_array[BB_index][2] += postsyn_cws\n",
    "                            \n",
    "                        if nrn.backbone_ID == 0 and neurons[int(postsyn_ID)].backbone_ID == 0: # LE->LE\n",
    "                            \n",
    "                            counts[BB_index][3] += 1\n",
    "                            avg_plas_array[BB_index][3] += postsyn_cws\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        for i in range(num_groups):\n",
    "            avg_plas_array[BB_index][i] = avg_plas_array[BB_index][i]/counts[BB_index][i]\n",
    "            \n",
    "    time_list = []        \n",
    "    for (weights,time) in neurons[0].cw_out_history: # to grab the times of cw storage from the first neuron.\n",
    "        time_list.append(time)\n",
    "        \n",
    "    # Plots plasticity conn weights vs time for each group:\n",
    "    labels = ['BB->BB', 'BB->LE', 'LE->BB', 'LE->LE']\n",
    "    colors = ['blue', 'cyan', 'lime', 'green']\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(2,figsize=(16,16))\n",
    "    \n",
    "    for BB_index, BB_ID in enumerate(bbs_toplot): \n",
    "        \n",
    "        for i, cw_data in enumerate(avg_plas_array[BB_index]):\n",
    "            \n",
    "            if BB_ID == 1:\n",
    "                ax1.plot(time_list, cw_data, label=labels[i], color=colors[i])\n",
    "                \n",
    "            if BB_ID == 2:\n",
    "                ax2.plot(time_list, cw_data, label=labels[i], color=colors[i])\n",
    "    \n",
    "    ax1.set_title('Avg Plasticity of Excitatory Groups', size=20)\n",
    "    ax1.set_ylabel('Avg Conn Weight Strength per Synapse - BB1', size=15)\n",
    "    ax2.set_ylabel('Avg Conn Weight Strength per Synapse - BB2', size=15)\n",
    "    ax2.set_xlabel('Time (ms)', size=15)\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    fig.savefig(directory+'Plasticity vs Time.pdf',format='pdf')\n",
    "    fig.savefig(directory+'Plasticity vs Time.png',format='png')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "' May want to delete this function if I can get the cw_in_history working for plotting all the avg plasticity weights'    \n",
    "def avg_plas_BBLE(t_ind): # Function to replace to old job of avg_conn_strength_bbs(). This function will calculate average \n",
    "    # plasticity weights between groups of neurons, but do so without having to create a new plasticity matrix every time.\n",
    "    \n",
    "    t = t_ind*stepSize #Changes time to ms.\n",
    "    calc_interval = 100 # interval between avgeraging calculations during simulation in ms.\n",
    "    quadplot_times = list(range(0,simLength+1,calc_interval)) #List of times to plot the quadrant connection strengths at.\n",
    "    \n",
    "    plas_avg_array = np.empty((len(bbs_toplot),4)) # Array to store averages between groups.\n",
    "    # Each row is for each BB, and within each row looks like: [BB->BB, BB->LE, LE->BB, LE->LE]\n",
    "    \n",
    "    counts = np.empty((len(bbs_toplot),4)) # Array to hold counts for number of connections falling into each category\n",
    "    # so that the average value can be found later.\n",
    "    \n",
    "    if t in quadplot_times:\n",
    "        \n",
    "        for BB_index, BB_ID in enumerate(bbs_toplot): # Loops through backbones\n",
    "            \n",
    "            for nrn in neurons:\n",
    "                \n",
    "                if nrn.category == 'Excitatory':\n",
    "                    \n",
    "                    for postsyn_ID, conn in nrn.connections:\n",
    "                        \n",
    "                        if neurons[int(postsyn_ID)].category == 'Excitatory' and conn == 1: # For E-E connections\n",
    "                            \n",
    "                            if nrn.backbone_ID == BB_ID and neurons[int(postsyn_ID)].backbone_ID == BB_ID: # BB->BB\n",
    "                                \n",
    "                                plas_avg_array[BB_index][0] += nrn.connectionWeights[int(postsyn_ID)]\n",
    "                                counts[BB_index][0] += 1\n",
    "                            \n",
    "                            if nrn.backbone_ID == BB_ID and neurons[int(postsyn_ID)].backbone_ID == 0: # BB->LE\n",
    "                                \n",
    "                                plas_avg_array[BB_index][1] += nrn.connectionWeights[int(postsyn_ID)]\n",
    "                                counts[BB_index][1] += 1\n",
    "                                \n",
    "                            if nrn.backbone_ID == 0 and neurons[int(postsyn_ID)].backbone_ID == BB_ID: # LE->BB\n",
    "                                \n",
    "                                plas_avg_array[BB_index][2] += nrn.connectionWeights[int(postsyn_ID)]\n",
    "                                counts[BB_index][2] += 1\n",
    "                                \n",
    "                            if nrn.backbone_ID == 0 and neurons[int(postsyn_ID)].backbone_ID == 0: # LE->LE\n",
    "                                \n",
    "                                plas_avg_array[BB_index][3] += nrn.connectionWeights[int(postsyn_ID)]\n",
    "                                counts[BB_index][3] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "def count_recruited():\n",
    "    numnrn_intheta = 30 #Number of neurons needed to trigger theta spike.\n",
    "    numnrn_resettheta = 10 #Minimum number of neurons needed to stay in theta spike.\n",
    "    width_theta = 15 #Time width for neurons to be counted in (ms).\n",
    "    width_count_lower = 25 #Time width to search for lower E neurons firing as soon as theta spike is detected. \n",
    "    lower_count_array = np.array([]).reshape(0,2) #Defines array for storing counts of lower E neurons in each theta spike. \n",
    "    time_array_ms = np.arange(350,int(len(tarray)*stepSize))\n",
    "    in_thetaspike = False #boolean for noting whether a theta spike has been reached or not. \n",
    "    \n",
    "    for t in time_array_ms:\n",
    "        spike_count = 0 # Counter for the number of spikes within detection interval from time t. \n",
    "        for nrn in neurons:\n",
    "            spiketime_array_ms = stepSize*np.array(nrn.spikeTimes) #List of all a nrn's spike times in ms. \n",
    "            array_first_edit = spiketime_array_ms[spiketime_array_ms >= t] #Eliminate all spiketimes less than t from the array.\n",
    "            array_final_edit = array_first_edit[(array_first_edit-t) <= width_theta] #Leaves only spiketimes within 15 ms after t.\n",
    "            \n",
    "            spike_count += len(array_final_edit) #grabs number of spikes in this range and adds them to running total.\n",
    "            \n",
    "        if spike_count >= numnrn_intheta and in_thetaspike == False: #If enough neurons fire and program is not already in a theta spike.\n",
    "            in_thetaspike = True\n",
    "            lower_count = 0 #Counter for number of lower E neurons that spike at least once during given theta period.\n",
    "            for nrn in neurons:\n",
    "                if nrn.gsyn > 1: #If nrn is a lower E neuron.\n",
    "                    spiketimes_lower = stepSize*np.array(nrn.spikeTimes)\n",
    "                    lower_first_edit = spiketimes_lower[spiketimes_lower >= t]\n",
    "                    lower_final_edit = lower_first_edit[(lower_first_edit-t) <= width_count_lower]\n",
    "                    if len(lower_final_edit) > 0: #because we only care about the number of lower E neurons firing.\n",
    "                        lower_count += 1 \n",
    "            lower_count_array = np.vstack((lower_count_array,[lower_count,t]))\n",
    "                        \n",
    "        if spike_count < numnrn_resettheta and in_thetaspike == True: #If not enough spikes are present and program is already in a theta spike.\n",
    "            in_thetaspike = False #Resets program to be ready for the next theta spike.\n",
    "    \n",
    "    \n",
    "    fig,ax1 = plt.subplots(1,figsize=(20,8))\n",
    "    ax1.plot(lower_count_array[:,1],lower_count_array[:,0],'o',color='green')\n",
    "    ax1.set_title('Lower Excitatory Neuron Firing',fontsize=20)\n",
    "    ax1.set_ylabel('Number of Lower E Nrns Firing in Theta Spike')\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    \n",
    "    return lower_count_array #Returns array of number of lower E neurons that fired in every theta spike. Length of this\n",
    "                            # array is number of total theta spikes. \n",
    "    \n",
    "    \n",
    "def count_recruited_bb():\n",
    "    numnrn_intheta = 30 #Number of neurons needed to trigger theta spike.\n",
    "    numnrn_resettheta = 10 #Minimum number of neurons needed to stay in theta spike.\n",
    "    width_theta = 15 #Time width for neurons to be counted in (ms).\n",
    "    width_count_lower = 25 #Time width to search for lower E neurons firing as soon as theta spike is detected. \n",
    "    bbs_LE_count_list = [] #List for holding all LE count data from all bbs.\n",
    "    time_array_ms = np.arange(350,int(len(tarray)*stepSize))\n",
    "    in_thetaspike = False #boolean for noting whether a theta spike has been reached or not. \n",
    "    \n",
    "    for index,bb in enumerate(bbs_toplot):\n",
    "        lower_count_array = np.array([]).reshape(0,2) #Defines array for storing counts of lower E neurons in each theta spike for 1 bb.\n",
    "        \n",
    "        for t in time_array_ms:\n",
    "            spike_count = 0 # Counter for the number of spikes within detection interval from time t. \n",
    "            \n",
    "            for nrn in neurons:\n",
    "                if nrn.backbone_ID == bb: #Determines if theta spike is present using # of bb neurons firing.\n",
    "                    \n",
    "                    spiketime_array_ms = stepSize*np.array(nrn.spikeTimes) #List of all a nrn's spike times in ms. \n",
    "                    array_first_edit = spiketime_array_ms[spiketime_array_ms >= t] #Eliminate all spiketimes less than t from the array.\n",
    "                    array_final_edit = array_first_edit[(array_first_edit-t) <= width_theta] #Leaves only spiketimes within 15 ms after t.\n",
    "\n",
    "                    spike_count += len(array_final_edit) #grabs number of spikes in this range and adds them to running total.\n",
    "\n",
    "            if spike_count >= numnrn_intheta and in_thetaspike == False: #If enough neurons fire and program is not already in a theta spike.\n",
    "                in_thetaspike = True\n",
    "                lower_count = 0 #Counter for number of lower E neurons that spike at least once during given theta period.\n",
    "                for nrn in neurons:\n",
    "                    if nrn.backbone_ID == 0: #If nrn is a lower E neuron.\n",
    "                        spiketimes_lower = stepSize*np.array(nrn.spikeTimes)\n",
    "                        lower_first_edit = spiketimes_lower[spiketimes_lower >= t]\n",
    "                        lower_final_edit = lower_first_edit[(lower_first_edit-t) <= width_count_lower]\n",
    "                        if len(lower_final_edit) > 0: #because we only care about the number of lower E neurons firing.\n",
    "                            lower_count += 1 \n",
    "                lower_count_array = np.vstack((lower_count_array,[lower_count,t]))\n",
    "                \n",
    "        \n",
    "            if spike_count < numnrn_resettheta and in_thetaspike == True: #If not enough spikes are present and program is already in a theta spike.\n",
    "                in_thetaspike = False #Resets program to be ready for the next theta spike. \n",
    "\n",
    "\n",
    "        fig,ax1 = plt.subplots(1,figsize=(20,8))\n",
    "        ax1.plot(lower_count_array[:,1],lower_count_array[:,0],'o',color='green')\n",
    "        ax1.set_title('Lower Excitatory Neuron Firing | bb#{0}'.format(bb),fontsize=20)\n",
    "        ax1.set_ylabel('Number of Lower E Nrns Firing in Theta Spikes')\n",
    "        ax1.set_xlabel('Time (ms)')\n",
    "\n",
    "    return\n",
    "    \n",
    "    \n",
    "    \n",
    "def bb_onoff(onoff,bb_listtoswitch):\n",
    "    # Function for turning backbones on or off through changes in inhibiton level(gsyn multiplier). onoff can be string value \n",
    "    # 'on' or 'off', determining the action to be taken and bb_listtoswitch are the IDs of the backbones to apply this action to.\n",
    "    # Also lowers Idrive of non-active backbone to ensure they do not fire.\n",
    "    global neurons\n",
    "    \n",
    "    if onoff == 'on': #Turns on backbone through low gsyn.\n",
    "        #print('bb',bb_listtoswitch, 'turned on')\n",
    "        for nrn in neurons:\n",
    "            if nrn.backbone_ID in bb_listtoswitch: #if the nrn belongs to a backbone in the list.\n",
    "                nrn.gsyn = gsynL\n",
    "                nrn.Idrive = Idrive_min #This is the high Idrive value. Could use Idrive_max also because there is no distribution of E idrive.\n",
    "                \n",
    "    if onoff == 'off': #Turns off backbone through high gsyn.\n",
    "        #print('bb',bb_listtoswitch,'turned off')\n",
    "        for nrn in neurons:\n",
    "            if nrn.backbone_ID in bb_listtoswitch:\n",
    "                nrn.gsyn = gsynH\n",
    "                nrn.Idrive = -3 #Low enough to hopefully prevent backbone from theta spiking when it is \"off.\"\n",
    "                \n",
    "\n",
    "                \n",
    "def record_gaussian(): # Gives neuron objects their gaussian spike data. Must be run before any dot product functions can work.\n",
    "    global neuron \n",
    "    \n",
    "    for nrn in neurons: #This loop is to add the spike gaussians to the neurons.\n",
    "        spike_gauss_sum = np.zeros(len(tarray)) #List to hold all the guassians together from one neuron.\n",
    "\n",
    "        for spike_time in nrn.spikeTimes: #Note spikeTimes are still in ms/stepSize\n",
    "            temp_gauss = stats.norm.pdf(tarray,loc=int(stepSize*spike_time),scale=2) #Temp list to hold 1 spike gaussian. Scale = 2 gives\n",
    "            # Gaussian curve of total width about 10 ms. \n",
    "            spike_gauss_sum += temp_gauss #Adds to total sum.\n",
    "\n",
    "        nrn.spike_gaussian = spike_gauss_sum #updates neuron object to the gaussian curves at each spike time.\n",
    "\n",
    "                \n",
    "                \n",
    "def LE_recruited_vec(vec_start,vec_end): #function to quantify how much of a difference there is between which LE neurons are firing with bb1 vs\n",
    "    # bb2. vec_start and end are the times from which to add LE spikes to the vector output (in ms). Times given to dotp_activity()\n",
    "    # in start_stop_times later become vec_start and vec_end. \n",
    "    # Function has been further modified to create similar vectors for both bbs. \n",
    "    #NOTE: the word \"burst\" willl be used to talk about the spiking of the network synchronously, such as a theta spike.\n",
    "    # Function has AGAIN been modified to instead return fraction of LE neurons firing in bursts, both as a scalar and vector.\n",
    "    global neuron\n",
    "    #Making list of all LE neurons will be useful.\n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    num_LE = len(LE_neurons)\n",
    "    \n",
    "    #Making list of only bb neurons will also be useful.\n",
    "    bb1_neurons = []\n",
    "    bb2_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 1:\n",
    "            bb1_neurons.append(nrn)\n",
    "        elif nrn.backbone_ID == 2:\n",
    "            bb2_neurons.append(nrn)\n",
    "            \n",
    "    num_bb = len(bb1_neurons) #All bbs have the same number of neurons.\n",
    "    \n",
    "            \n",
    "    gauss_threshold = 3 #The threshold value for the magnitude of summed gaussians of all neurons to be considered \"inside\" a spike.\n",
    "    \n",
    "    #add the gaussians from each neuron to determine a spike.\n",
    "    sum_allnrns = np.zeros(len(tarray)) #List for sum of gaussians from all neurons.\n",
    "    sum_bbnrns = np.zeros(len(tarray)) #List for sum of gaussians for all backbone neurons (from all backbones). \n",
    "    sum_LEnrns = np.zeros(len(tarray)) #List for sum of gaussians from LE neurons.\n",
    "    for nrn in neurons:\n",
    "        sum_allnrns += nrn.spike_gaussian\n",
    "        if nrn.backbone_ID == 0: #if LE neuron\n",
    "            sum_LEnrns += nrn.spike_gaussian\n",
    "        if nrn.backbone_ID != -1 and nrn.backbone_ID != 0: #If not inhbitory or LE neuron.\n",
    "            sum_bbnrns += nrn.spike_gaussian\n",
    "    \n",
    "    #Now I need to run over the all_nrn summed gaussian times and record the intervals in which the spikes occured.\n",
    "    inburst = False\n",
    "    record_burst = False #boolean to only record a burst start and end time once. \n",
    "    burst_times = [[0,0]] #Defines with dummy element \n",
    "    for t_ind,val in enumerate(sum_allnrns):\n",
    "        #The following grabs start and end times of each burst\n",
    "        if val >= gauss_threshold and inburst == False and vec_start <= int(stepSize*t_ind) <= vec_end: #Places the time contraints on what bursts are considered.\n",
    "            burst_start = t_ind\n",
    "            inburst = True\n",
    "        if val < gauss_threshold and inburst == True:\n",
    "            burst_end = t_ind\n",
    "            inburst = False\n",
    "            record_burst = True\n",
    "        #Actually recording a burst time:\n",
    "        if record_burst == True : \n",
    "            burst_times.append([burst_start,burst_end])\n",
    "            record_burst = False\n",
    "    burst_times.pop(0) #eliminates dummy element \n",
    "    \n",
    "    \n",
    "    #This section creates a vector that counts the number of spikes for neurons within bursts. \n",
    "    \n",
    "    burst_vec_LE = np.zeros(num_LE) # For storing nrn spike info in one burst. NOTE THIS LIST MUST HAVE LENGTH = # LE NRNS.\n",
    "    burst_vec_bb1 = np.zeros(num_bb) \n",
    "    burst_vec_bb2 = np.zeros(num_bb)\n",
    "    \n",
    "    for burst_start,burst_end in burst_times: #Loops over bursts\n",
    "        \n",
    "        #Portion for LE neuron vector:\n",
    "        for index, nrn in enumerate(LE_neurons): #Loops through LE neurons. Carefully note that we are not using nrn.ID but rather the\n",
    "            # list index of LE_neurons in order to make the basis of the burst_vec vector.\n",
    "            for t_spike in nrn.spikeTimes:\n",
    "                if burst_start <= t_spike <= burst_end: #Note both t_spike and burst times are in ms/stepSize. \n",
    "                    burst_vec_LE[index] += 1 # NOTE: this will count multiple spikes from the same neuron inside a single burst.\n",
    "       \n",
    "        #Portion for bb neuron vectors:\n",
    "        for index, nrn in enumerate(bb1_neurons): #Loops through bb1 neurons.\n",
    "                for t_spike in nrn.spikeTimes:\n",
    "                    if burst_start <= t_spike <= burst_end:\n",
    "                        burst_vec_bb1[index] += 1\n",
    "                        \n",
    "        for index, nrn in enumerate(bb2_neurons): #Loops through bb2 neurons.\n",
    "                for t_spike in nrn.spikeTimes:\n",
    "                    if burst_start <= t_spike <= burst_end:\n",
    "                        burst_vec_bb2[index] += 1\n",
    "\n",
    "    # Calculates Fraction of LE neuron spikes that happen in theta bursts over vec_start to vec_end time range:\n",
    "    num_LE_spikes_tot = 0 #Counter for total number of LE spikes between vec_start and vec_end.\n",
    "    tot_vec_LE = np.zeros(len(LE_neurons)) #Vector for storing the total number of spikes from each LE nrn. \n",
    "    for index,nrn_LE in enumerate(LE_neurons):\n",
    "        for t_spike in nrn_LE.spikeTimes:\n",
    "            if vec_start <= t_spike*stepSize <= vec_end:\n",
    "                num_LE_spikes_tot += 1 #Counts the number of LE neuron spikes.\n",
    "                tot_vec_LE[index] += 1 #Indexes LE neuron spikes. Records total number of LE spikes for each nrn. \n",
    "\n",
    "    num_LE_spikes_burst = sum(burst_vec_LE) #sum of burst_vec_LE is the total number of LE spikes in theta bursts (between vec_start and vec_end).\n",
    "    frac_LE_inburst = num_LE_spikes_burst/num_LE_spikes_tot # Fraction of LE spikes in bursts. This is a scalar and for all LE neurons.\n",
    "    \n",
    "    #Now we divide each index of burst_vec_LE (for LE nrn) by its total number of spikes, giving us a vector where each index\n",
    "    # represents the fraction of spikes that LE neuron fired inside theta bursts. A value of 1 means all spikes were in theta bursts.\n",
    "    frac_vec_LE = np.zeros(len(LE_neurons))\n",
    "    for index,num_burstspikes in enumerate(burst_vec_LE):\n",
    "        if tot_vec_LE[index] > 0: #Handles divide by zero case.\n",
    "            frac_vec_LE[index] = num_burstspikes/tot_vec_LE[index]\n",
    "   \n",
    "    frac_vec_LE = frac_vec_LE/np.sqrt(np.dot(frac_vec_LE,frac_vec_LE)) #Normalize by mag. This shouldn't lose any information. \n",
    "    tot_vec_LE = tot_vec_LE/np.sqrt(np.dot(tot_vec_LE,tot_vec_LE)) #Also normalize vector holding all spikes of LE nrns in time range.\n",
    "    '''                    \n",
    "    #Plots gaussian sums\n",
    "    fig,ax1=plt.subplots(2,1,figsize=(20,10))\n",
    "    ax1[0].plot(tarray[int(vec_start/stepSize):int(vec_end/stepSize)],sum_allnrns[int(vec_start/stepSize):int(vec_end/stepSize)])\n",
    "    ax1[0].set_title('Gaussian All Neurons')\n",
    "    ax1[0].set_xlabel('Time (ms)')\n",
    "    ax1[0].set_ylabel('Magnitude of Summed Gaussian Curves')\n",
    "    ax1[1].plot(tarray[int(vec_start/stepSize):int(vec_end/stepSize)],sum_LEnrns[int(vec_start/stepSize):int(vec_end/stepSize)])\n",
    "    ax1[1].set_title('Gaussian LE Neurons')\n",
    "    ax1[1].set_xlabel('Time (ms)')\n",
    "    ax1[1].set_ylabel('Magnitude of Summed Gaussian Curves')\n",
    "    '''\n",
    "    #Returns vectors indexed with respective neurons. Also returns LE vector with total numbber of spikes in time range.\n",
    "    return frac_LE_inburst, frac_vec_LE, tot_vec_LE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dotp_activity(start_stop_times): #Function that takes a list of start/stop times for LE count vectors and returns the dot product.\n",
    "    # start_stop_times = [[vec1_start,vec1_stop],[...],...] (CAN ONLY REALLY TAKE 2 VECTORS AT A TIME).\n",
    "    # Note that this function calculates the dot product between two vectors, each of length (# LE neurons), each index representing\n",
    "    # a single LE neuron. Each index counts how many times this LE neuron spikes during theta spikes of a backbone or in general. Start and \n",
    "    # stop times should usually be chosen to correlate with the REM stages of each backbone. The dot product between these two \n",
    "    # vectors determines if the same LE neurons fire during REM of the two bbs (dotp ~ 1) or if the bbs have recruited the firing \n",
    "    # of different LE neurons (dotp ~ 0). The function also runs the same process for vectors of the backbone neurons, except it\n",
    "    # takes the dot product between a bb vector and an LE vector. \n",
    "    # NOTE: Function modified to process fraction of LE in bursts data. BB processing code deleted.  \n",
    "    # NOTE: Function modified again to include dotp calculation based off all LE neuron firing, not just the fraction in theta bursts\n",
    "    LE_neurons = []\n",
    "    for nrn in neurons: #This is just to get the number of LE neurons and # of neurons in a backbone.\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "            \n",
    "    all_vecs_LE = np.array(np.zeros(len(LE_neurons)))\n",
    "    all_vecs_tot = np.array(np.zeros(len(LE_neurons)))\n",
    "    scalar_frac_LE = [] #List of fraction of LE in burst scalars.\n",
    "    #Putting all the vectors together is not useful yet, but it may be in the future. That is why I create all_vecs.\n",
    " \n",
    "    for t_start,t_stop in start_stop_times:\n",
    "        frac_LE_inburst,frac_vec_LE,tot_vec_LE = LE_recruited_vec(t_start,t_stop) #vectors of one time period.\n",
    "        all_vecs_LE = np.vstack((all_vecs_LE,frac_vec_LE)) #Stores all vectors in one big array.\n",
    "        all_vecs_tot = np.vstack((all_vecs_tot,tot_vec_LE))\n",
    "        scalar_frac_LE.append(frac_LE_inburst)\n",
    "\n",
    "    #After deleting the dummy element these lists should contain the same number of vectors as the length of start_stop_times. \n",
    "    all_vecs_LE = np.delete(all_vecs_LE,0,axis=0) # Deletes dummy zeros element. \n",
    "    all_vecs_tot = np.delete(all_vecs_tot,0,axis=0) # Deletes dummy zeros element. \n",
    "    \n",
    "    #Now because I can only take the dot product between two vectors and I expect there to only be two vectors(one for each time period)\n",
    "    #anyways, I will assume there are only two vectors in the all_vecs vectors.\n",
    "    vec1_LE,vec2_LE = all_vecs_LE[0],all_vecs_LE[1]\n",
    "    sca1_LE,sca2_LE = scalar_frac_LE[0],scalar_frac_LE[1]\n",
    "    # Do the same for all-LE-spike vectors:\n",
    "    vec1_tot,vec2_tot = all_vecs_tot[0],all_vecs_tot[1]\n",
    "\n",
    "\n",
    "    # Remember these vectors are already normalized. \n",
    "    \n",
    "    dotp_LE = np.dot(vec1_LE,vec2_LE)\n",
    "    dotp_tot = np.dot(vec1_tot,vec2_tot)\n",
    "    print('LE Fraction of Theta Burst Dotp: ',round(dotp_LE,3),' For Vectors Made at Times: ',start_stop_times)\n",
    "    print('Fraction of LE Spikes in Theta Bursts:  bb1:',round(sca1_LE,3),\n",
    "          'bb2:',round(sca2_LE,3),' For Vectors Made at Times: ',start_stop_times)\n",
    "\n",
    "    print('LE Total Firing Dotp: ',round(dotp_tot,3),' For Vectors Made at Times: ',start_stop_times)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def dotp_wvec(t_ind): #function to create weight vectors for each bb to LE then evaluate dot product between them.\n",
    "    # FOR 2 BBs ONLY\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons: #This is just to get the number of LE neurons.\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "            \n",
    "    wvec_bb1,wvec_bb2 = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Vectors to hold summed weights from separate bbs for each LE nrn. \n",
    "    \n",
    "    for index,LE_nrn in enumerate(LE_neurons): \n",
    "        for nrn in neurons:\n",
    "            if nrn.connections[LE_nrn.ID][1] == 1: #If nrn is connected to LE_nrn\n",
    "                \n",
    "                if nrn.backbone_ID == 1:     \n",
    "                    wvec_bb1[index] += nrn.connectionWeights[LE_nrn.ID]  #Adds plas_weight from nrn to LE_nrn to the vector.\n",
    "                elif nrn.backbone_ID == 2:\n",
    "                    wvec_bb2[index] += nrn.connectionWeights[LE_nrn.ID]\n",
    "    \n",
    "    #print(wvec_bb1,wvec_bb2)\n",
    "    #Normalizing the vectors:\n",
    "    wvec_bb1 = wvec_bb1/(np.sqrt(np.dot(wvec_bb1,wvec_bb1)))\n",
    "    wvec_bb2 = wvec_bb2/(np.sqrt(np.dot(wvec_bb2,wvec_bb2)))\n",
    "    \n",
    "    dotp = np.dot(wvec_bb1,wvec_bb2) #Calculates the dot product between to sets of LE neurons. 1 means they have all the\n",
    "    #same connectivities, 0 means they have none in common. \n",
    "    print('Plasticity Dot Product Between LE: ',round(dotp,3),' Calculated at: ',round((t_ind*stepSize),0))\n",
    "    \n",
    "\n",
    "    \n",
    "def NREM_REM_scatter(NR_times,bb,mark_boo): #Plots a scatter plot of 40 points (# of LE neurons), with x axis as total connectivity weight from \n",
    "    # a given backbone after NREM learning, and y axis connectivity weight after REM learning. Takes times of NREM and REM\n",
    "    # for which to plot (can only be 2 times). Format: [end of NREM time, end of REM time]. mark_boo tells the function \n",
    "    # whether or not to mark LE neuron with strong cw after REM as blue and weak cw as orange. Make sure to only set\n",
    "    # mark_boo=True after bb1 REM, and not after bb2. bb signifies which bb to calculate cw with. \n",
    "    time_NREM = NR_times[0] #Selects the NREM calculation time.\n",
    "    time_REM = NR_times[1] #REM calculation time.\n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "\n",
    "    NREM_vals,REM_vals = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "\n",
    "    for nrn_LE in LE_neurons:\n",
    "        cw_vec_NREM = nrn_LE.cw_in_history[recorded_times.index(time_NREM)][0] #Vector of cw inputs to nrn at time time_NREM.\n",
    "        cw_vec_REM = nrn_LE.cw_in_history[recorded_times.index(time_REM)][0] #Similar, at time time_REM.\n",
    "\n",
    "        #Now I need to sort through these vectors and find connections comming from backbone bb. \n",
    "        for index,cw in enumerate(cw_vec_NREM): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                NREM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "\n",
    "        for index,cw in enumerate(cw_vec_REM): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron.\n",
    "\n",
    "\n",
    "    if mark_boo: #if the boolean mark_boo is true, mark the most stengthened and most weakened neurons after REM.\n",
    "                \n",
    "        #List below contains LE neurons sorted by REM cw strength, with highest strength first in list. NOTE it is important to\n",
    "        # use key to sort, otherwise sorted() reverts to sorting by second element in tuple when two vals in first element of tuple are the same.\n",
    "        LE_sortedby_cw = [nrn for cw,nrn in sorted(zip(REM_vals,LE_neurons),reverse=True,key=sort_tuple)]\n",
    "        num_ext_nrn = 10 #Number of neurons to be marked on each end, so 2*(num_ext_nrn) will have color changed, half\n",
    "        # with the strongest REM conn and half with weakest. This variable changes every loop.\n",
    "        for index,LE_nrn in enumerate(LE_sortedby_cw): #Loops through LE neurons starting with ones of highest net conn strength. \n",
    "            if index < num_ext_nrn: #Only loops num_ext_nrn times.\n",
    "                if bb == 1:\n",
    "                    LE_nrn.scatter_color = 'blue' #Labeled blue as these neurons should be tied to bb1\n",
    "                if bb == 2:\n",
    "                    LE_nrn.scatter_color = 'green'\n",
    "            if index > (len(LE_sortedby_cw)-num_ext_nrn): # Loops over last num_ext_nrn vals.\n",
    "                if bb == 1:\n",
    "                    LE_nrn.scatter_color = 'orange' #These neurons should be later picked up by bb2. \n",
    "                if bb == 2:\n",
    "                    LE_nrn.scatter_color = 'red'\n",
    "                \n",
    "                    \n",
    "\n",
    "    #Plotting values and reference diagonal line:\n",
    "    x_line = np.arange(0,w_max*40) #Creating diagonal line for reference to changes in plasticity.\n",
    "    y_line = x_line\n",
    "    fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    ax.scatter(NREM_vals,REM_vals,color=[LE_nrn.scatter_color for LE_nrn in LE_neurons])\n",
    "    ax.plot(x_line,y_line,color='red') #Reference line\n",
    "    ax.set_xlim([0,w_max*40/3]) #NOTE 40 is the size of each bb. Should be changed if bb size is changed.\n",
    "    ax.set_ylim([0,w_max*40/3])\n",
    "    ax.set_title('NREM, REM CW to LE From bb{0}'.format(bb),size=15)\n",
    "    ax.set_xlabel('Sum of CW after NREM ({0}ms)'.format(time_NREM))\n",
    "    ax.set_ylabel('Sum of CW after REM ({0}ms)'.format(time_REM))\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "def NREM_dREM_scatter(NR_times,bb,mark_boo): #Plots a scatter plot of 40 points (# of LE neurons), with x axis as total connectivity weight from \n",
    "    # a given backbone after NREM learning, and change in y axis connectivity weight after REM learning. Takes times of NREM and REM\n",
    "    # for which to plot (can only be 2 times). Format: [end of NREM time, end of REM time]. mark_boo tells the function \n",
    "    # whether or not to mark LE neuron with strong cw after REM as blue and weak cw as orange. Make sure to only set\n",
    "    # mark_boo=True after bb1 REM, and not after bb2. bb signifies which bb to calculate cw with. \n",
    "    time_NREM = NR_times[0] #Selects the NREM calculation time.\n",
    "    time_REM = NR_times[1] #REM calculation time.\n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "\n",
    "    NREM_vals,REM_vals = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "\n",
    "    for nrn_LE in LE_neurons:\n",
    "        cw_vec_NREM = nrn_LE.cw_in_history[recorded_times.index(time_NREM)][0] #Vector of cw inputs to nrn at time time_NREM.\n",
    "        cw_vec_REM = nrn_LE.cw_in_history[recorded_times.index(time_REM)][0] #Similar, at time time_REM.\n",
    "\n",
    "        #Now I need to sort through these vectors and find connections comming from backbone bb. \n",
    "        for index,cw in enumerate(cw_vec_NREM): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                NREM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "\n",
    "        for index,cw in enumerate(cw_vec_REM): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron.\n",
    "\n",
    "\n",
    "\n",
    "    if mark_boo: #if the boolean mark_boo is true, mark the most stengthened and most weakened neurons after REM.\n",
    "        for LE_nrn in LE_neurons: #Gives LE neurons grey color for scatter plot.\n",
    "            LE_nrn.scatter_color = 'grey'\n",
    "            \n",
    "        #List below contains LE neurons sorted by REM cw strength, with highest strength first in list. NOTE it is important to\n",
    "        # use key to sort, otherwise sorted() reverts to sorting by second element in tuple when two vals in first element of tuple are the same.\n",
    "        LE_sortedby_cw = [nrn for cw,nrn in sorted(zip(REM_vals,LE_neurons),reverse=True,key=sort_tuple)]\n",
    "        num_ext_nrn = 10 #Number of neurons to be marked on each end, so 2*(num_ext_nrn) will have color changed, half\n",
    "        # with the strongest REM conn and half with weakest. This variable changes every loop.\n",
    "        for index,LE_nrn in enumerate(LE_sortedby_cw): #Loops through LE neurons starting with ones of highest net conn strength. \n",
    "            if index < num_ext_nrn: #Only loops num_ext_nrn times.\n",
    "                LE_nrn.scatter_color = 'blue' #Labeled blue as these neurons should be tied to bb1\n",
    "            if index > (len(LE_sortedby_cw)-num_ext_nrn): # Loops over last num_ext_nrn vals.\n",
    "                LE_nrn.scatter_color = 'orange' #These neurons should be later picked up by bb2. \n",
    "                \n",
    "                \n",
    "    dREM_vals = REM_vals - NREM_vals #This calculates the change in weight during REM.  \n",
    "\n",
    "    #Plotting values and reference diagonal line:\n",
    "    x_line = np.arange(0,w_max*40) #Creating diagonal line for reference to changes in plasticity.\n",
    "    y_line = np.zeros(len(x_line))\n",
    "    fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    ax.scatter(NREM_vals,dREM_vals,color=[LE_nrn.scatter_color for LE_nrn in LE_neurons])\n",
    "    ax.plot(x_line,y_line,color='red') #Reference line\n",
    "    ax.set_xlim([0,w_max*40/3])\n",
    "    ax.set_ylim([-w_max*40/9,w_max*40/9])\n",
    "    ax.set_title(r'NREM, $\\Delta$REM CW to LE From bb{0}'.format(bb),size=15)\n",
    "    ax.set_xlabel('Sum of CW after NREM ({0}ms)'.format(time_NREM))\n",
    "    ax.set_ylabel('Change in CW after REM (between {0}ms and {1}ms)'.format(time_NREM,time_REM))\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "def dNREM_dREM_scatter(NREM_start,NR_times,bb,mark_boo): #Plots a scatter plot of 40 points (# of LE neurons), with x axis as total connectivity weight from \n",
    "    # a given backbone after NREM learning, and y axis connectivity weight after REM learning. Takes times of NREM and REM\n",
    "    # for which to plot (can only be 2 times). Format: [end of NREM time, end of REM time]. mark_boo tells the function \n",
    "    # whether or not to mark LE neuron with strong cw after REM as blue and weak cw as orange. Make sure to only set\n",
    "    # mark_boo=True after bb1 REM, and not after bb2. bb signifies which bb to calculate cw with. \n",
    "    time_NREM = NR_times[0] #Selects the NREM calculation time.\n",
    "    time_REM = NR_times[1] #REM calculation time.\n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "\n",
    "    NREM_vals,REM_vals = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "    start_NREM_vals = np.zeros(len(LE_neurons))\n",
    "    \n",
    "    for nrn_LE in LE_neurons:\n",
    "        cw_vec_NREM = nrn_LE.cw_in_history[recorded_times.index(time_NREM)][0] #Vector of cw inputs to nrn at time time_NREM.\n",
    "        cw_vec_REM = nrn_LE.cw_in_history[recorded_times.index(time_REM)][0] #Similar, at time time_REM.\n",
    "        cw_vec_start_NREM = nrn_LE.cw_in_history[recorded_times.index(NREM_start)][0] #Vector at start of NREM.\n",
    "        \n",
    "        #Now I need to sort through these vectors and find connections comming from backbone bb. \n",
    "        for index,cw in enumerate(cw_vec_NREM): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                NREM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "                \n",
    "        for index,cw in enumerate(cw_vec_start_NREM): # Same thing as above, but recording initial NREM vals (before learning)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                start_NREM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron.\n",
    "\n",
    "        for index,cw in enumerate(cw_vec_REM): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron.\n",
    "\n",
    "    dREM_vals = REM_vals - NREM_vals #This calculates the change in weight during REM. (Assuming REM comes right after NREM) \n",
    "    dNREM_vals = NREM_vals - start_NREM_vals #Change in weight during NREM. \n",
    "                \n",
    "\n",
    "    if mark_boo: #if the boolean mark_boo is true, mark the most stengthened and most weakened neurons after REM.\n",
    "        for LE_nrn in LE_neurons: #Gives nrns colors and fills color list with grey as defeault \n",
    "            LE_nrn.scatter_color = 'grey'\n",
    "            \n",
    "        #List below contains LE neurons sorted by REM cw strength, with highest strength first in list. NOTE it is important to\n",
    "        # use key to sort, otherwise sorted() reverts to sorting by second element in tuple when two vals in first element of tuple are the same.\n",
    "        LE_sortedby_cw = [nrn for cw,nrn in sorted(zip(REM_vals,LE_neurons),reverse=True,key=sort_tuple)]\n",
    "        num_ext_nrn = 10 #Number of neurons to be marked on each end, so 2*(num_ext_nrn) will have color changed, half\n",
    "        # with the strongest REM conn and half with weakest. This variable changes every loop.\n",
    "        for index,LE_nrn in enumerate(LE_sortedby_cw): #Loops through LE neurons starting with ones of highest net conn strength. \n",
    "            if index < num_ext_nrn: #Only loops num_ext_nrn times.\n",
    "                LE_nrn.scatter_color = 'blue' #Labeled blue as these neurons should be tied to bb1\n",
    "            if index > (len(LE_sortedby_cw)-num_ext_nrn): # Loops over last num_ext_nrn vals.\n",
    "                LE_nrn.scatter_color = 'orange' #These neurons should be later picked up by bb2. \n",
    "                    \n",
    "\n",
    "    #Plotting values and reference diagonal line:\n",
    "    x_line = np.arange(-w_max*40,w_max*40) #Creating diagonal line for reference to changes in plasticity.\n",
    "    y_line = np.zeros(len(x_line))\n",
    "    y_vert = np.arange(-w_max*40,w_max*40)\n",
    "    x_vert = np.zeros(len(y_vert))\n",
    "    fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    ax.scatter(dNREM_vals,dREM_vals,color=[LE_nrn.scatter_color for LE_nrn in LE_neurons])\n",
    "    ax.plot(x_line,y_line,color='red') #Reference line\n",
    "    ax.plot(x_vert,y_vert,color='red') #Reference line\n",
    "    ax.set_xlim([-w_max*40/9,w_max*40/9])\n",
    "    ax.set_ylim([-w_max*40/9,w_max*40/9])\n",
    "    ax.set_title(r'$\\Delta$NREM, $\\Delta$REM CW to LE From bb{0}'.format(bb),size=15)\n",
    "    ax.set_xlabel('Change in CW after NREM (between {0}ms and {1}ms)'.format(NREM_start,time_NREM))\n",
    "    ax.set_ylabel('Change in CW after REM (between {0}ms and {1}ms)'.format(time_NREM,time_REM))\n",
    "    \n",
    "    #Plotting dREM vs CW before learning:\n",
    "    x_line = np.arange(0,w_max*40) #Creating diagonal line for reference to changes in plasticity.\n",
    "    y_line = np.zeros(len(x_line))\n",
    "    fig, ax1 = plt.subplots(1,figsize=(8,8))\n",
    "    ax1.scatter(start_NREM_vals,dREM_vals,color=[LE_nrn.scatter_color for LE_nrn in LE_neurons])\n",
    "    ax1.plot(x_line,y_line,color='red') #Reference line\n",
    "    ax1.set_title(r'$\\Delta$REM, BL CW to LE From bb{0}'.format(bb),size=15)\n",
    "    ax1.set_xlabel('CW Before Learning')\n",
    "    ax1.set_ylabel('Change in CW after REM (between {0}ms and {1}ms)'.format(time_NREM,time_REM))    \n",
    "    ax1.set_xlim(0,w_max*40/3)\n",
    "    ax1.set_ylim([-w_max*40/9,w_max*40/9])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def CW_scatter(learn_start,learn_middle,learn_end,bb):#I plot 2 graphs, 1) CW after REM or NREM, whichever comes first, vs CW \n",
    "    # before learning. 2) CW after both REM and NREM vs CW before learning. #The learn_start, learn_middle, learn_end are times\n",
    "    # corresponding to start of learning, where learning switches between NREM and REM, amd where learning ends for that bb.\n",
    "    \n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "\n",
    "    start_vals,middle_vals = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "    end_vals = np.zeros(len(LE_neurons))\n",
    "    \n",
    "    for nrn_LE in LE_neurons:\n",
    "        cw_vec_start = nrn_LE.cw_in_history[recorded_times.index(learn_start)][0] #Vector of cw inputs to nrn at time time_NREM.\n",
    "        cw_vec_middle = nrn_LE.cw_in_history[recorded_times.index(learn_middle)][0] #Similar, at time time_REM.\n",
    "        cw_vec_end = nrn_LE.cw_in_history[recorded_times.index(learn_end)][0] #Vector at start of NREM.\n",
    "        \n",
    "        #Now I need to sort through these vectors and find connections comming from backbone bb. \n",
    "        for index,cw in enumerate(cw_vec_start): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                start_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "                \n",
    "        for index,cw in enumerate(cw_vec_middle): # Same thing as above, but recording initial NREM vals (before learning)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                middle_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron.\n",
    "\n",
    "        for index,cw in enumerate(cw_vec_end): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == bb and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                end_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron.\n",
    "\n",
    "        \n",
    "    \n",
    "    x_line = np.arange(0,w_max*40) #Creating diagonal line for reference to changes in plasticity.\n",
    "    y_line = x_line\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,8))\n",
    "    ax1.scatter(start_vals,middle_vals,color=[LE_nrn.scatter_quad_color for LE_nrn in LE_neurons])\n",
    "    ax1.plot(x_line,y_line,color='red') #Reference line\n",
    "    fig.suptitle(r'Connection Weights During and After Learning of LE Nrns From bb{0} w Inhibition Labels'.format(bb),size=15)\n",
    "    ax1.set_xlabel('CW Before Learning ({0} ms)'.format(learn_start))\n",
    "    ax1.set_ylabel('CW During Learning ({0} ms)'.format(learn_middle))    \n",
    "    ax1.set_xlim(0,w_max*40/3)\n",
    "    ax1.set_ylim(0,w_max*40/3)\n",
    "    ax2.scatter(start_vals,end_vals,color=[LE_nrn.scatter_quad_color for LE_nrn in LE_neurons])\n",
    "    ax2.plot(x_line,y_line,color='red') #Reference line\n",
    "    ax2.set_xlabel('CW Before Learning ({0} ms)'.format(learn_start))\n",
    "    ax2.set_ylabel('CW After Learning ({0} ms)'.format(learn_end))    \n",
    "    ax2.set_xlim(0,w_max*40/3)\n",
    "    ax2.set_ylim(0,w_max*40/3)\n",
    "    \n",
    "    for index,LE_nrn in enumerate(LE_neurons): #Annotes scatter plot points with nrn ID\n",
    "        num_inhib_conns = return_inhib_conns(LE_nrn)\n",
    "        ax1.annotate(num_inhib_conns,(start_vals[index],middle_vals[index]))\n",
    "        ax2.annotate(num_inhib_conns,(start_vals[index],end_vals[index]))\n",
    "    \n",
    "    fig.savefig(directory+'CW Learning bb#{0}.pdf'.format(bb),format='pdf')\n",
    "    fig.savefig(directory+'CW Learning bb#{0}.png'.format(bb),format='png')\n",
    "    \n",
    "    \n",
    "        \n",
    "def BBs_scatter(RR_times,norm_boo): #Plots a scatter plot of 40 points (# of LE neurons), with x axis as total connectivity weight\n",
    "    # from bb1 after learning, and y axis connectivity weight from bb2 after learning. Function takes times for bb1 and bb2\n",
    "    # for which to plot (can only be 2 times). Format: [bb1 time, bb2 time]. Note it will usually be useful to \n",
    "    # calculate cw for both bbs after learnig is finished for both bbs, i.e., have both vals RR_times be the same. \n",
    "    # NOTE QUADRANT COLORING is done only for RR_times before learning, but this is dependent on when plasticity is turned on,\n",
    "    # so the if-statement below will need to be adjusted if this changes.\n",
    "    time_bb1 = RR_times[0] #Selects bb1 calc time.\n",
    "    time_bb2 = RR_times[1] #bb2 calculation time.\n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "\n",
    "    bb1_REM_vals,bb2_REM_vals = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "\n",
    "    for nrn_LE in LE_neurons:\n",
    "        cw_vec_bb1 = nrn_LE.cw_in_history[recorded_times.index(time_bb1)][0] #Vector of cw inputs to nrn at time time_NREM.\n",
    "        cw_vec_bb2 = nrn_LE.cw_in_history[recorded_times.index(time_bb2)][0] #Similar, at time time_REM.\n",
    "\n",
    "        #Now I need to sort through these vectors and find connections comming from backbone 1. \n",
    "        for index,cw in enumerate(cw_vec_bb1): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == 1 and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                bb1_REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "\n",
    "        for index,cw in enumerate(cw_vec_bb2): # cw is connection weight value (between 0 and w_max)\n",
    "            if neurons[index].backbone_ID == 2 and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                bb2_REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "              \n",
    "            \n",
    "    #Now I want to calculate center of mass for each group, then dot the COM vectors:\n",
    "    COM_bb1_pu,COM_bb1_b,COM_bb1_g,COM_bb1_pi = [],[],[],[] #Lists for finding COM along x axis.\n",
    "    COM_bb2_pu,COM_bb2_b,COM_bb2_g,COM_bb2_pi = [],[],[],[] # y axis.\n",
    "    \n",
    "    if norm_boo == True:\n",
    "        #We also want to normalize all values so we can easily compare before and after learning. Do this by dividing all points\n",
    "        # by largest value in x and y directions:\n",
    "        max_val_bb1,max_val_bb2 = max(bb1_REM_vals),max(bb2_REM_vals)\n",
    "        bb1_REM_vals, bb2_REM_vals = bb1_REM_vals/max_val_bb1, bb2_REM_vals/max_val_bb2 #New lists of normalized values.\n",
    "    \n",
    "    for index,(val1,val2) in enumerate(zip(bb1_REM_vals, bb2_REM_vals)): #Loops over both lists simultaneously. \n",
    "        if LE_neurons[index].scatter_quad_color == 'purple':\n",
    "            COM_bb1_pu.append(val1), COM_bb2_pu.append(val2)\n",
    "        if LE_neurons[index].scatter_quad_color == 'blue':\n",
    "            COM_bb1_b.append(val1), COM_bb2_b.append(val2)\n",
    "        if LE_neurons[index].scatter_quad_color == 'green':\n",
    "            COM_bb1_g.append(val1), COM_bb2_g.append(val2)\n",
    "        if LE_neurons[index].scatter_quad_color == 'pink':\n",
    "            COM_bb1_pi.append(val1), COM_bb2_pi.append(val2)\n",
    "            \n",
    "    # Calculating the COM vectors for each color group:\n",
    "    COM_pu = np.array([sum(COM_bb1_pu)/len(COM_bb1_pu) , sum(COM_bb2_pu)/len(COM_bb2_pu)]) #Turn into arrays to later use A.dot()\n",
    "    COM_b = np.array([sum(COM_bb1_b)/len(COM_bb1_b) , sum(COM_bb2_b)/len(COM_bb2_b)])\n",
    "    COM_g = np.array([sum(COM_bb1_g)/len(COM_bb1_g) , sum(COM_bb2_g)/len(COM_bb2_g)])\n",
    "    COM_pi = np.array([sum(COM_bb1_pi)/len(COM_bb1_pi) , sum(COM_bb2_pi)/len(COM_bb2_pi)])\n",
    "    \n",
    "    #Calculating standard deviation of points from COM. Note COM_bbx_color lists are actually just lists of conn strengths, not COM values.\n",
    "    #vec_color vectors are filled with points for each color group, each with their group's COM as the new origin. \n",
    "    vecs_pu = [[x_val-COM_pu[0],y_val-COM_pu[1]] for x_val,y_val in zip(COM_bb1_pu,COM_bb2_pu)] \n",
    "    vecs_b = [[x_val-COM_b[0],y_val-COM_b[1]] for x_val,y_val in zip(COM_bb1_b,COM_bb2_b)]\n",
    "    vecs_g = [[x_val-COM_g[0],y_val-COM_g[1]] for x_val,y_val in zip(COM_bb1_g,COM_bb2_g)]\n",
    "    vecs_pi = [[x_val-COM_pi[0],y_val-COM_pi[1]] for x_val,y_val in zip(COM_bb1_pi,COM_bb2_pi)]\n",
    "\n",
    "    #(Std dev) = sqrt( average(vecs^2) ) where vecs are the vectors wrt COM.\n",
    "    stddev_pu = np.sqrt(sum([x**2 + y**2 for x,y in vecs_pu])/len(vecs_pu))\n",
    "    stddev_b = np.sqrt(sum([x**2 + y**2 for x,y in vecs_b])/len(vecs_b))\n",
    "    stddev_g = np.sqrt(sum([x**2 + y**2 for x,y in vecs_g])/len(vecs_g))\n",
    "    stddev_pi = np.sqrt(sum([x**2 + y**2 for x,y in vecs_pi])/len(vecs_pi))\n",
    "    \n",
    "    #Calculating cos(theta) = (V . W)/(|V|*|W|):\n",
    "    cos_b_g = COM_b.dot(COM_g)/(np.sqrt(COM_b.dot(COM_b)*COM_g.dot(COM_g))) \n",
    "    cos_pu_pi = COM_pu.dot(COM_pi)/(np.sqrt(COM_pu.dot(COM_pu)*COM_pi.dot(COM_pi)))\n",
    "    cos_b_pu = COM_b.dot(COM_pu)/(np.sqrt(COM_b.dot(COM_b)*COM_pu.dot(COM_pu)))\n",
    "    cos_g_pu = COM_g.dot(COM_pu)/(np.sqrt(COM_g.dot(COM_g)*COM_pu.dot(COM_pu)))\n",
    "    \n",
    "    #Calculates distance between green and blue COM:\n",
    "    diff_b_g = COM_b - COM_g \n",
    "    dist_b_g = np.sqrt(abs(diff_b_g.dot(diff_b_g))) # Length of vector between COM.\n",
    "                      \n",
    "                      \n",
    "    \n",
    "    #Plotting values \n",
    "    #fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    #ax.scatter(bb1_REM_vals,bb2_REM_vals,color=[LE_nrn.scatter_color for LE_nrn in LE_neurons])\n",
    "    #ax.set_xlim([0,w_max*40/3]) #NOTE 40 is the size of each bb. Should be changed if bb size is changed.\n",
    "    #ax.set_ylim([0,w_max*40/3])\n",
    "    #ax.set_title('CW for bb1 and bb2',size=15)\n",
    "    #ax.set_xlabel('Sum of CW for bb1 at ({0}ms)'.format(time_bb1))\n",
    "    #ax.set_ylabel('Sum of CW for bb2 at ({0}ms)'.format(time_bb2))\n",
    "    \n",
    "    # Quadrant Color Graph:\n",
    "    fig, ax1 = plt.subplots(1,figsize=(8,8))\n",
    "    ax1.scatter(bb1_REM_vals,bb2_REM_vals, color=[LE_nrn.scatter_quad_color for LE_nrn in LE_neurons])\n",
    "    ax1.scatter([COM_pu[0],COM_b[0],COM_g[0],COM_pi[0]],[COM_pu[1],COM_b[1],COM_g[1],COM_pi[1]],\n",
    "                color=['purple','blue','green','pink'], marker='x',s=60) #Plots COM.\n",
    "    \n",
    "    for index,LE_nrn in enumerate(LE_neurons): #Annotes scatter plot points with nrn ID.\n",
    "        ax1.annotate(LE_nrn.ID,(bb1_REM_vals[index],bb2_REM_vals[index]))\n",
    "        ax1.set_title('Quad-Based bb1 and bb2 Unnormalized',size=15)\n",
    "        ax1.set_xlabel('Sum of CW for bb1 at ({0}ms)'.format(time_bb1))\n",
    "        ax1.set_ylabel('Sum of CW for bb2 at ({0}ms)'.format(time_bb2))\n",
    "        fig.savefig(directory+'Quadrant CW at Time={0} Unnormalized.pdf'.format(time_bb1),format='pdf')\n",
    "        fig.savefig(directory+'Quadrant CW at Time={0} Unnormalized.png'.format(time_bb1),format='png')\n",
    "\n",
    "    \n",
    "    print('COM Dot Products: Blue,Green:',round(cos_b_g,4),' Purple,Pink:',round(cos_pu_pi,4),' Blue,Purple:',\\\n",
    "            round(cos_b_pu,4),' Green,Purple:',round(cos_g_pu,4),'  At Time bb1:{0}, bb2:{1}'.format(time_bb1,time_bb2))\n",
    "    \n",
    "    print('Distance Between Blue and Green COM: ',dist_b_g)\n",
    "    \n",
    "    print('Standard Deviation From COM. Blue: ',stddev_b, ' Green: ',stddev_g)\n",
    "    \n",
    "    return bb1_REM_vals, bb2_REM_vals\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "def COM_vectors(time_start, time_end,norm_boo): # Calculates and plots vectors showing movement of COM of quad color groups between\n",
    "    # the two times time_start and time_end. norm_boo is boolean, True means normalize COM data and thus the vector plot, while\n",
    "    # False means do not normalize. \n",
    "\n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "            \n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    all_COM_vecs = np.zeros(shape=(1,4,2)) #Array for holding COM vectors.\n",
    "    \n",
    "    \n",
    "    #Loops over times. Each loop finds COM vecs for that time. \n",
    "    for time in [time_start,time_end]:\n",
    "\n",
    "        bb1_REM_vals,bb2_REM_vals = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "\n",
    "        for nrn_LE in LE_neurons:\n",
    "            cw_vec_bb1 = nrn_LE.cw_in_history[recorded_times.index(time)][0] #Vector of cw inputs to nrn at time\n",
    "            cw_vec_bb2 = nrn_LE.cw_in_history[recorded_times.index(time)][0] \n",
    "\n",
    "            #Now I need to sort through these vectors and find connections comming from backbone 1. \n",
    "            for index,cw in enumerate(cw_vec_bb1): # cw is connection weight value (between 0 and w_max)\n",
    "                if neurons[index].backbone_ID == 1 and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                    bb1_REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "\n",
    "            for index,cw in enumerate(cw_vec_bb2): # cw is connection weight value (between 0 and w_max)\n",
    "                if neurons[index].backbone_ID == 2 and neurons[index].connections[nrn_LE.ID][1] == 1: # If the presyn neuron is from correct backbone and the connections exists.\n",
    "                    bb2_REM_vals[LE_neurons.index(nrn_LE)] += cw #conn weight is summed to that neuron. \n",
    "\n",
    "\n",
    "\n",
    "        #Now I want to calculate center of mass for each group, then dot the COM vectors:\n",
    "        COM_bb1_pu,COM_bb1_b,COM_bb1_g,COM_bb1_pi = [],[],[],[] #Lists for finding COM along x axis.\n",
    "        COM_bb2_pu,COM_bb2_b,COM_bb2_g,COM_bb2_pi = [],[],[],[] # y axis.\n",
    "        \n",
    "        if norm_boo == True:\n",
    "            #We also want to normalize all values so we can easily compare before and after learning. Do this by dividing all points\n",
    "            # by largest value in x and y directions:\n",
    "            max_val_bb1,max_val_bb2 = max(bb1_REM_vals),max(bb2_REM_vals)\n",
    "            bb1_REM_vals, bb2_REM_vals = bb1_REM_vals/max_val_bb1, bb2_REM_vals/max_val_bb2 #New lists of normalized values.\n",
    "\n",
    "        for index,(val1,val2) in enumerate(zip(bb1_REM_vals, bb2_REM_vals)): #Loops over both lists simultaneously. \n",
    "            if LE_neurons[index].scatter_quad_color == 'purple':\n",
    "                COM_bb1_pu.append(val1), COM_bb2_pu.append(val2)\n",
    "            if LE_neurons[index].scatter_quad_color == 'blue':\n",
    "                COM_bb1_b.append(val1), COM_bb2_b.append(val2)\n",
    "            if LE_neurons[index].scatter_quad_color == 'green':\n",
    "                COM_bb1_g.append(val1), COM_bb2_g.append(val2)\n",
    "            if LE_neurons[index].scatter_quad_color == 'pink':\n",
    "                COM_bb1_pi.append(val1), COM_bb2_pi.append(val2)\n",
    "\n",
    "        # Calculating the COM vectors for each color group:\n",
    "        COM_pu = np.array([sum(COM_bb1_pu)/len(COM_bb1_pu) , sum(COM_bb2_pu)/len(COM_bb2_pu)]) #Turn into arrays to later use A.dot()\n",
    "        COM_b = np.array([sum(COM_bb1_b)/len(COM_bb1_b) , sum(COM_bb2_b)/len(COM_bb2_b)])\n",
    "        COM_g = np.array([sum(COM_bb1_g)/len(COM_bb1_g) , sum(COM_bb2_g)/len(COM_bb2_g)])\n",
    "        COM_pi = np.array([sum(COM_bb1_pi)/len(COM_bb1_pi) , sum(COM_bb2_pi)/len(COM_bb2_pi)])\n",
    "        \n",
    "        all_COM_vecs = np.append(all_COM_vecs,[[COM_pu,COM_b,COM_g,COM_pi]],axis=0) #Adds COM vectors to the array.\n",
    "        \n",
    "    \n",
    "    all_COM_vecs = np.delete(all_COM_vecs,0,axis=0) # Deletes dummy first element from array. Now array looks like:\n",
    "    # [ [ [COM_x_pu, COM_y_pu] , [COM_x_b, COM_y_b] , ... ] , ...] where the first element along axis=0 holds COM vectors at\n",
    "    # time time_start, and second element holds time_end vectors.\n",
    "    \n",
    "    diff_COM_vecs = all_COM_vecs[1] - all_COM_vecs[0] # Simply subtract time_start vector componenets from time_end components.\n",
    "    \n",
    "    plot_vecs = zip(all_COM_vecs[0],diff_COM_vecs) # Combines initial position of COM with change in position for looping.\n",
    "    plot_colors = ['purple','blue','green','pink'] # Important that this is same order as groups added to all_COM_vecs.\n",
    "    # Time to plot the difference vectors:\n",
    "    fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    \n",
    "    if norm_boo == True:\n",
    "        for index,(xy,dxdy) in enumerate(plot_vecs): #Loops through starting coordinates and change in position for all 4 color groups.\n",
    "            ax.arrow(xy[0],xy[1],dxdy[0],dxdy[1],width=0.02,head_width=0.05,head_length=0.02,color=plot_colors[index])\n",
    "        ax.set_title('Movement of COM Vectors From Learning (From {0}ms to {1}ms) Normalized'.format(time_start,time_end),size=13)\n",
    "        ax.set_xlabel('Normalized Sum of CW from bb1')\n",
    "        ax.set_ylabel('Normalized Sum of CW from bb2')\n",
    "        ax.set_xlim(0,1.1)\n",
    "        ax.set_ylim(0,1.1)\n",
    "        fig.savefig(directory+'Vector Quadrant Plot Normalized.pdf',format='pdf')\n",
    "        fig.savefig(directory+'Vector Quadrant Plot Normalized.png',format='png')\n",
    "    if norm_boo == False:\n",
    "        for index,(xy,dxdy) in enumerate(plot_vecs): #Loops through starting coordinates and change in position for all 4 color groups.\n",
    "            ax.arrow(xy[0],xy[1],dxdy[0],dxdy[1],width=0.1,head_width=0.2,head_length=0.15,color=plot_colors[index])\n",
    "        ax.set_title('Movement of COM Vectors From Learning (From {0}ms to {1}ms) Unnormalized'.format(time_start,time_end),size=13)\n",
    "        ax.set_xlabel('Sum of CW from bb1')\n",
    "        ax.set_ylabel('Sum of CW from bb2')\n",
    "        fig.savefig(directory+'Vector Quadrant Plot Unnormalized.pdf',format='pdf')\n",
    "        fig.savefig(directory+'Vector Quadrant Plot Unnormalized.png',format='png')\n",
    "        \n",
    "        \n",
    "        \n",
    "def LE_connections(sum_intervals): # Calculates multiple statistics and graphs concerning connecitons to LE neurons.\n",
    "    # sum_intervals is a list of all the times of which inbetween the total inhibiton to LE groups will be calculated.\n",
    "    global neuron\n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "    # Prints blue and green LE neurons, their IDs, and how many inhiitory connections come to them.\n",
    "    for LE_nrn in LE_neurons:\n",
    "        count = 0\n",
    "        if LE_nrn.scatter_quad_color == 'blue' or LE_nrn.scatter_quad_color == 'green':\n",
    "            # Counting the number of incoming inhibitory synapses for each LE neuron:\n",
    "            for presyn,conn in enumerate(LE_nrn.conn_in):\n",
    "                if neurons[int(presyn)].backbone_ID == -1:\n",
    "                    count += conn # conn_in values are all 0 or 1, so summing gives the total in-degree from inhibitory neurons.\n",
    "            #print(LE_nrn.scatter_quad_color,' nrn, ID = ',LE_nrn.ID,', # inhib conns = ',count)\n",
    "            \n",
    "    \n",
    "    # The next part of this function calculates the strength of connections between different LE groups and then plots them\n",
    "    # vs time.\n",
    "    recorded_times = [i[1] for i in neurons[0].cw_in_history] #Recorded plasticity times are the same for all neurons.\n",
    "    \n",
    "    LE_to_blue, LE_to_green, LE_to_purple, LE_to_pink = np.zeros(len(recorded_times)),np.zeros(len(recorded_times)) \\\n",
    "        ,np.zeros(len(recorded_times)),np.zeros(len(recorded_times))#For conns from rest of LE neurons to a group\n",
    "    blue_to_blue, green_to_green, purple_to_purple, pink_to_pink = np.zeros(len(recorded_times)),np.zeros(len(recorded_times)) \\\n",
    "        ,np.zeros(len(recorded_times)),np.zeros(len(recorded_times)) #For conns from a group to itself\n",
    "    blue_to_green, green_to_blue = np.zeros(len(recorded_times)),np.zeros(len(recorded_times))\n",
    "    \n",
    "    # Sorts LE neurons and sums connection weights:\n",
    "    for LE_nrn in LE_neurons: \n",
    "        for index, (conn_weights,time) in enumerate(LE_nrn.cw_in_history): # Loops through time, where conn_weights are all incoming connection weights.\n",
    "        #  NOTE: by default connection weights are 1, so non-existant connections have a value of 1 in conn_weights.\n",
    "        \n",
    "            if LE_nrn.scatter_quad_color == 'blue': #Connections to blue LE neurons:\n",
    "                for presyn_ID, w_conn in enumerate(conn_weights): #Loops through all incoming connection weights.\n",
    "                    if neurons[presyn_ID].backbone_ID == 0 and neurons[presyn_ID].connections[LE_nrn.ID][1] == 1: #If the connection\n",
    "                    # exists and the presynaptic neuron is an LE neuron:\n",
    "                    \n",
    "                        if neurons[presyn_ID].scatter_quad_color != 'blue': #Sums all conns that are not blue to blue.\n",
    "                            LE_to_blue[index] += w_conn\n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'blue': # Sums all blue to blue conn weights\n",
    "                            blue_to_blue[index] += w_conn\n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'green':\n",
    "                            green_to_blue[index] += w_conn\n",
    "\n",
    "            if LE_nrn.scatter_quad_color == 'green': #Connections to green LE neurons:\n",
    "                for presyn_ID, w_conn in enumerate(conn_weights): #Loops through all incoming connection weights.\n",
    "                    if neurons[presyn_ID].backbone_ID == 0 and neurons[presyn_ID].connections[LE_nrn.ID][1] == 1: #If the connection\n",
    "                    # exists and the presynaptic neuron is an LE neuron:\n",
    "                        \n",
    "                        if neurons[presyn_ID].scatter_quad_color != 'green':\n",
    "                            LE_to_green[index] += w_conn\n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'green': # Sums all blue to blue conn weights\n",
    "                            green_to_green[index] += w_conn\n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'blue':\n",
    "                            blue_to_green[index] += w_conn\n",
    "\n",
    "            if LE_nrn.scatter_quad_color == 'purple':\n",
    "                for presyn_ID, w_conn in enumerate(conn_weights): #Loops through all incoming connection weights.\n",
    "                    if neurons[presyn_ID].backbone_ID == 0 and neurons[presyn_ID].connections[LE_nrn.ID][1] == 1: #If the connection\n",
    "                    # exists and the presynaptic neuron is an LE neuron:\n",
    "                    \n",
    "                        if neurons[presyn_ID].scatter_quad_color != 'purple':\n",
    "                            LE_to_purple[index] += w_conn\n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'purple': # Sums all blue to blue conn weights\n",
    "                            purple_to_purple[index] += w_conn\n",
    "\n",
    "            if LE_nrn.scatter_quad_color == 'pink':\n",
    "                for presyn_ID, w_conn in enumerate(conn_weights): #Loops through all incoming connection weights.\n",
    "                    if neurons[presyn_ID].backbone_ID == 0 and neurons[presyn_ID].connections[LE_nrn.ID][1] == 1: #If the connection\n",
    "                    # exists and the presynaptic neuron is an LE neuron:\n",
    "                    \n",
    "                        if neurons[presyn_ID].scatter_quad_color != 'pink':\n",
    "                            LE_to_pink[index] += w_conn\n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'pink': # Sums all blue to blue conn weights\n",
    "                            pink_to_pink[index] += w_conn\n",
    "\n",
    "    # Now that we have the total connection strength coming into different groups, we divide by the number of neurons to get\n",
    "    # the average connection strength to a neuron within each group. First we have to grab the number of neurons in each group.\n",
    "    quad_counters = np.zeros(4) #List for holding number of LE neurons in each group. [blue,green,purple,pink]\n",
    "    for nrn in neurons:\n",
    "        if nrn.scatter_quad_color == 'blue':\n",
    "            quad_counters[0] += 1\n",
    "        if nrn.scatter_quad_color == 'green':\n",
    "            quad_counters[1] += 1\n",
    "        if nrn.scatter_quad_color == 'purple':\n",
    "            quad_counters[2] += 1\n",
    "        if nrn.scatter_quad_color == 'pink':\n",
    "            quad_counters[3] += 1\n",
    "    # Now normalize by the number of neurons:        \n",
    "    LE_to_blue, LE_to_green, LE_to_purple, LE_to_pink = LE_to_blue/quad_counters[0], LE_to_green/quad_counters[1],\\\n",
    "    LE_to_purple/quad_counters[2], LE_to_pink/quad_counters[3]\n",
    "    blue_to_blue, green_to_green, purple_to_purple, pink_to_pink = blue_to_blue/quad_counters[0], green_to_green/quad_counters[1],\\\n",
    "    purple_to_purple/quad_counters[2], pink_to_pink/quad_counters[3]\n",
    "    blue_to_green, green_to_blue = blue_to_green/quad_counters[1], green_to_blue/quad_counters[0]\n",
    "    \n",
    "    # Now we plot the results:\n",
    "    fig1, (ax1,ax2) = plt.subplots(2,figsize=(15,15))\n",
    "    \n",
    "    ax1.plot(recorded_times, LE_to_blue, color='blue', linestyle='dashed')\n",
    "    ax1.plot(recorded_times, LE_to_green, color='green', linestyle='dashed')\n",
    "    ax1.plot(recorded_times, LE_to_purple, color='purple', linestyle='dashed')\n",
    "    ax1.plot(recorded_times, LE_to_pink, color='pink', linestyle='dashed')\n",
    "    ax1.set_title('Average Connection Strength From Other LE Groups')\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    ax1.set_ylabel('Summed Connection Strength Divided by 10')\n",
    "    \n",
    "    ax2.plot(recorded_times, blue_to_blue, color='blue', linestyle='dashed', label='b to b')\n",
    "    ax2.plot(recorded_times, green_to_green, color='green', linestyle='dashed', label='g to g')\n",
    "    ax2.plot(recorded_times, purple_to_purple, color='purple', linestyle='dashed', label='pu to pu')\n",
    "    ax2.plot(recorded_times, pink_to_pink, color='pink', linestyle='dashed', label='pi to pi')\n",
    "    ax2.plot(recorded_times, blue_to_green, color='green', label='b to g')\n",
    "    ax2.plot(recorded_times, green_to_blue, color='blue', label='g to b')\n",
    "    ax2.set_title('Average Connection Strength Inside Own Group and Between Blue and Green')\n",
    "    ax2.set_xlabel('Time (ms)')\n",
    "    ax2.set_ylabel('Summed Connection Strength Divided by 10')\n",
    "    ax2.legend()\n",
    "    \n",
    "    fig1.savefig(directory+'Connection Strengths Between LE Groups.pdf',format='pdf')\n",
    "    fig1.savefig(directory+'Connection Strengths Between LE Groups.png',format='png')\n",
    "\n",
    "    '''\n",
    "    #This next part plots the average total inhibiton each neuron in a group receives.\n",
    "    \n",
    "    # To make the graph below function, I need to add this code back in to UpdateSyn():\n",
    "    ------------------------------------------------------------------------------\n",
    "        # Recording inhibitory input to each LE neuron:\n",
    "        if neurons[int(conn[0])].backbone_ID == 0 and t_ind % (1/stepSize) == 0: \n",
    "            gsyn = neurons[int(conn[0])].gsyn #Connection strength multiplier of postsynaptic neuron.\n",
    "            for w,t in (w_IE,tau),(w_IE_B,tau_B):\n",
    "                neurons[int(conn[0])].i_current_hist[int(t_ind*stepSize)][0] += gsyn*conn[1]*(w)*np.exp(-stepSize*(t_ind-t_temp)/t)*(V - E_syn) # t = tau again.\n",
    "                #print(nrn.i_current_hist[int(t_ind*stepSize)][0], 'time ', t_ind*stepSize)\n",
    "    ------------------------------------------------------------------------------\n",
    "    \n",
    "    tot_i_blue,tot_i_green,tot_i_purple,tot_i_pink = np.zeros(simLength),np.zeros(simLength),\\\n",
    "    np.zeros(simLength),np.zeros(simLength)\n",
    "    \n",
    "    for LE_nrn in LE_neurons: #This sums the inhibition values at each index together.\n",
    "        if LE_nrn.scatter_quad_color == 'blue':\n",
    "            tot_i_blue += np.array([i_sum for i_sum,i_time in LE_nrn.i_current_hist])\n",
    "            \n",
    "        if LE_nrn.scatter_quad_color == 'green':\n",
    "            tot_i_green += np.array([i_sum for i_sum,i_time in LE_nrn.i_current_hist])\n",
    "            \n",
    "        if LE_nrn.scatter_quad_color == 'purple':\n",
    "            tot_i_purple += np.array([i_sum for i_sum,i_time in LE_nrn.i_current_hist])\n",
    "            \n",
    "        if LE_nrn.scatter_quad_color == 'pink':\n",
    "            tot_i_pink += np.array([i_sum for i_sum,i_time in LE_nrn.i_current_hist])\n",
    "        \n",
    "    #Now divide by the number of LE neurons in each group to get the average inhbition a neuron in each group might receive.\n",
    "    tot_i_blue,tot_i_green,tot_i_purple,tot_i_pink = tot_i_blue/quad_counters[0],tot_i_green/quad_counters[1],\\\n",
    "    tot_i_purple/quad_counters[2],tot_i_pink/quad_counters[3]\n",
    "    times_list = np.arange(simLength)\n",
    "    \n",
    "    fig2, ax1 = plt.subplots(1,figsize=(15,8))\n",
    "    ax1.plot(times_list, tot_i_blue, color='blue', linestyle='dotted')\n",
    "    ax1.plot(times_list, tot_i_green, color='green', linestyle='dotted')\n",
    "    ax1.plot(times_list, tot_i_purple, color='purple', linestyle='dotted')\n",
    "    ax1.plot(times_list, tot_i_pink, color='pink', linestyle='dotted')\n",
    "    ax1.set_title('Average Inhibitory Current to LE Neurons')\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    ax1.set_ylabel('Summed Inhibitory Current Divided by 10')\n",
    "    \n",
    "    #Now I sum total inhibiton to LE groups over certain time intervals:\n",
    "    for start_time, end_time in sum_intervals:\n",
    "        start_index = np.where(times_list == start_time)[0][0]\n",
    "        end_index = np.where(times_list == end_time)[0][0]\n",
    "        \n",
    "        sum_blue = np.sum(tot_i_blue[start_index:end_index])\n",
    "        sum_green = np.sum(tot_i_green[start_index:end_index])\n",
    "        sum_purple = np.sum(tot_i_purple[start_index:end_index])\n",
    "        sum_pink = np.sum(tot_i_pink[start_index:end_index])\n",
    "        \n",
    "        print('Sum over interval ',start_time, 'to',end_time, 'per neuron on average' )\n",
    "        print('blue: ',round(sum_blue))\n",
    "        print('green: ',round(sum_green))\n",
    "        print('purple: ',round(sum_purple))\n",
    "        print('pink: ',round(sum_pink))\n",
    "    '''\n",
    "    \n",
    "    \n",
    "def return_inhib_conns(nrn):\n",
    "    # Function that returns the number of inhibitory connections to \"nrn\".\n",
    "    count = 0\n",
    "    for presyn,conn in enumerate(nrn.conn_in):\n",
    "        if neurons[int(presyn)].backbone_ID == -1:\n",
    "            count += conn # conn_in values are all 0 or 1, so summing gives the total in-degree from inhibitory neurons.\n",
    "            \n",
    "    return count #Returns number of inhibitory conns to this nrn. \n",
    "\n",
    "\n",
    "\n",
    "def barplots(): #Function for making all the barplots.\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # LE group activity:\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    # These arrays will store the gaussian activities for all neurons in their group summed together.        \n",
    "    act_b,act_g,act_pu,act_pi = np.zeros(len(tarray)),np.zeros(len(tarray)),np.zeros(len(tarray)),np.zeros(len(tarray))\n",
    "    \n",
    "    for LE_nrn in LE_neurons: #This stores the complete activity data for each group.\n",
    "        if LE_nrn.scatter_quad_color == 'blue':\n",
    "            act_b += LE_nrn.spike_gaussian\n",
    "        if LE_nrn.scatter_quad_color == 'green':\n",
    "            act_g += LE_nrn.spike_gaussian\n",
    "        if LE_nrn.scatter_quad_color == 'purple':\n",
    "            act_pu += LE_nrn.spike_gaussian\n",
    "        if LE_nrn.scatter_quad_color == 'pink':\n",
    "            act_pi += LE_nrn.spike_gaussian\n",
    "            \n",
    "    # Now the activity data will be seperated into bins and summed for barplot plotting. We want data for each BB during every\n",
    "    # phase, so that comes out to 8 bar plot bins.\n",
    "    bars_b,bars_g,bars_pu,bars_pi = np.zeros(8),np.zeros(8),np.zeros(8),np.zeros(8)\n",
    "    \n",
    "    # The gaussian data from act_x are seperated into time chunks corresponding with each phase and BB activity. The data from\n",
    "    # this time chunk is then summed and normalized by the length of time over which the data spanned.\n",
    "    # NOTE that spike.gaussian data is in t_ind increments, so the phase times need to be divided by stepSize. (Also, I may be\n",
    "    # able to rewrite this code into a loop so I don't have to write it all out...)\n",
    "    \n",
    "    # Pre-learning test phase:\n",
    "    bars_b[0] += sum(act_b[int(550/stepSize):int(BB_len_test/stepSize)])/(BB_len_test-550)\n",
    "    bars_g[0] += sum(act_g[int(550/stepSize):int(BB_len_test/stepSize)])/(BB_len_test-550)\n",
    "    bars_pu[0] += sum(act_pu[int(550/stepSize):int(BB_len_test/stepSize)])/(BB_len_test-550)\n",
    "    bars_pi[0] += sum(act_pi[int(550/stepSize):int(BB_len_test/stepSize)])/(BB_len_test-550)\n",
    "    bars_b[1] += sum(act_b[int(BB_len_test/stepSize):int(t_start_NREM/stepSize)])/(t_start_NREM-BB_len_test)\n",
    "    bars_g[1] += sum(act_g[int(BB_len_test/stepSize):int(t_start_NREM/stepSize)])/(t_start_NREM-BB_len_test)\n",
    "    bars_pu[1] += sum(act_pu[int(BB_len_test/stepSize):int(t_start_NREM/stepSize)])/(t_start_NREM-BB_len_test)\n",
    "    bars_pi[1] += sum(act_pi[int(BB_len_test/stepSize):int(t_start_NREM/stepSize)])/(t_start_NREM-BB_len_test)\n",
    "    \n",
    "    # NREM phase:\n",
    "    bars_b[2] += sum(act_b[int(t_start_NREM/stepSize):int((t_start_NREM+BB_len_NREM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_g[2] += sum(act_g[int(t_start_NREM/stepSize):int((t_start_NREM+BB_len_NREM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_pu[2] += sum(act_pu[int(t_start_NREM/stepSize):int((t_start_NREM+BB_len_NREM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_pi[2] += sum(act_pi[int(t_start_NREM/stepSize):int((t_start_NREM+BB_len_NREM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_b[3] += sum(act_b[int((t_start_NREM+BB_len_NREM)/stepSize):int((t_start_REM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_g[3] += sum(act_g[int((t_start_NREM+BB_len_NREM)/stepSize):int((t_start_REM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_pu[3] += sum(act_pu[int((t_start_NREM+BB_len_NREM)/stepSize):int((t_start_REM)/stepSize)])/(BB_len_NREM)\n",
    "    bars_pi[3] += sum(act_pi[int((t_start_NREM+BB_len_NREM)/stepSize):int((t_start_REM)/stepSize)])/(BB_len_NREM)\n",
    "    \n",
    "    # REM phase:\n",
    "    bars_b[4] += sum(act_b[int((t_start_REM)/stepSize):int((t_start_REM+BB_len_REM)/stepSize)])/(BB_len_REM)\n",
    "    bars_g[4] += sum(act_g[int((t_start_REM)/stepSize):int((t_start_REM+BB_len_REM)/stepSize)])/(BB_len_REM)\n",
    "    bars_pu[4] += sum(act_pu[int((t_start_REM)/stepSize):int((t_start_REM+BB_len_REM)/stepSize)])/(BB_len_REM)\n",
    "    bars_pi[4] += sum(act_pi[int((t_start_REM)/stepSize):int((t_start_REM+BB_len_REM)/stepSize)])/(BB_len_REM)\n",
    "    bars_b[5] += sum(act_b[int((t_start_REM+BB_len_REM)/stepSize):int((t_start_posttest)/stepSize)])/(BB_len_REM)\n",
    "    bars_g[5] += sum(act_g[int((t_start_REM+BB_len_REM)/stepSize):int((t_start_posttest)/stepSize)])/(BB_len_REM)\n",
    "    bars_pu[5] += sum(act_pu[int((t_start_REM+BB_len_REM)/stepSize):int((t_start_posttest)/stepSize)])/(BB_len_REM)\n",
    "    bars_pi[5] += sum(act_pi[int((t_start_REM+BB_len_REM)/stepSize):int((t_start_posttest)/stepSize)])/(BB_len_REM)\n",
    "    \n",
    "    # Post-learning test phase:\n",
    "    bars_b[6] += sum(act_b[int((t_start_posttest)/stepSize):int((t_start_posttest+BB_len_test)/stepSize)])/(BB_len_test)\n",
    "    bars_g[6] += sum(act_g[int((t_start_posttest)/stepSize):int((t_start_posttest+BB_len_test)/stepSize)])/(BB_len_test)\n",
    "    bars_pu[6] += sum(act_pu[int((t_start_posttest)/stepSize):int((t_start_posttest+BB_len_test)/stepSize)])/(BB_len_test)\n",
    "    bars_pi[6] += sum(act_pi[int((t_start_posttest)/stepSize):int((t_start_posttest+BB_len_test)/stepSize)])/(BB_len_test)\n",
    "    bars_b[7] += sum(act_b[int((t_start_posttest+BB_len_test)/stepSize):int((simLength)/stepSize)])/(BB_len_test)\n",
    "    bars_g[7] += sum(act_g[int((t_start_posttest+BB_len_test)/stepSize):int((simLength)/stepSize)])/(BB_len_test)\n",
    "    bars_pu[7] += sum(act_pu[int((t_start_posttest+BB_len_test)/stepSize):int((simLength)/stepSize)])/(BB_len_test)\n",
    "    bars_pi[7] += sum(act_pi[int((t_start_posttest+BB_len_test)/stepSize):int((simLength)/stepSize)])/(BB_len_test)\n",
    "    \n",
    "    # Here the data is plotted on a barplot:\n",
    "    # This gives the x-axis location of where each bar will be placed on the plot:\n",
    "    locations_b = np.array([0,5,13,18,26,31,39,44])\n",
    "    locations_g = locations_b + 1\n",
    "    locations_pu = locations_b + 2\n",
    "    locations_pi = locations_b + 3\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1,figsize=(15,5))\n",
    "    ax1.bar(locations_b,bars_b,align='edge',color='blue')\n",
    "    ax1.bar(locations_g,bars_g,align='edge',color='green')\n",
    "    ax1.bar(locations_pu,bars_pu,align='edge',color='purple')\n",
    "    ax1.bar(locations_pi,bars_pi,align='edge',color='pink')\n",
    "    ax1.set_xticks(locations_pu) #This places the x-axis labels in the center of each bar group.\n",
    "    ax1.set_xticklabels(['Pre BB1','Pre BB2','NREM BB1','NREM BB2','REM BB1','REM BB2','Post BB1','Post BB2']);\n",
    "    ax1.set_title('LE Activity Over Time')\n",
    "    ax1.set_ylabel('Activity Normalized by Phase Length')\n",
    "    \n",
    "    fig.savefig(directory+'LE Activity Barplot.pdf',format='pdf')\n",
    "    fig.savefig(directory+'LE Activity Barplot.png',format='png')\n",
    "    \n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # Activity Dot Product:\n",
    "    # ALTERED FOR TOTAL NUMBER OF LE SPIKES, INSTEAD OF LE FRACTION IN THETA BURSTS.\n",
    "    \n",
    "    # This phase_periods list holds all the start and stop times designating the backbone activities within each phase of the\n",
    "    # simulation. [ [[phase 1 BB1 start, phase 1 BB1 end],[phase 1 BB2 start, phase 1 BB2 end]], [phase 2....], ...]\n",
    "    phase_periods = np.array([[[550,BB_len_test],[BB_len_test+50,t_start_NREM]],\n",
    "                     [[t_start_NREM+50,t_start_NREM+BB_len_NREM],[t_start_NREM+BB_len_NREM+50,t_start_REM]],\n",
    "                     [[t_start_REM+50,t_start_REM+BB_len_REM],[t_start_REM+BB_len_REM+50,t_start_posttest]],\n",
    "                     [[t_start_posttest+50,t_start_posttest+BB_len_test],[t_start_posttest+BB_len_test+50,simLength]]])\n",
    "    \n",
    "    #ALL_scalars_LE = np.empty((0,2)) #Array for holding the scalar fraction of LE firing within theta burst values for all phases.\n",
    "    ALL_dotp_tot = np.empty((0,1)) # Array for holding dot products between normalized activity vectors for each phase.\n",
    "    ALL_dotp_ratio = np.empty((0,1)) # Holds dot product ratios of (activity dotp)/(randomly shuffled vector dotp)\n",
    "    ALL_rand_dotp_avg = np.empty((0,1)) # Holds dotp randomized averages for each phase.\n",
    " \n",
    "    for phase in phase_periods: #Loops through phases, i.e. pre-learning test, NREM, REM, and post-learning test.\n",
    "        \n",
    "        \n",
    "        #scalars_LE = [] #List of 'fraction of LE in burst' scalars. This is only for one phase.\n",
    "        #vecs_LE = np.array(np.zeros(len(LE_neurons))) # Array for holding the two LE activity vectors. Only for one phase.\n",
    "        vecs_tot = np.array(np.zeros(len(LE_neurons))) # _tot vectors indicate data from all-LE firing, not just the fraction in theta bursts.\n",
    "        \n",
    "        for BB_t_start,BB_t_stop in phase: #Loops through the start and stop times of each BB.\n",
    "            BB_scalar_LE,BB_vec_LE,BB_vec_tot = LE_recruited_vec(BB_t_start,BB_t_stop) #vector of one time period. Remember the vector (second\n",
    "            # term) output from LE_recruited_vec is really a vector where each index represents an LE neuron, and the value of that\n",
    "            # index is the fraction of spikes from that LE neuron that were inside theta bursts over the time period BB_t_start to\n",
    "            # BB_t_stop. Note this vector is normalized. \n",
    "           #vecs_LE = np.vstack((vecs_LE,BB_vec_LE)) #Stores vectors from both BBs in one array.\n",
    "           #scalars_LE.append(BB_scalar_LE) #Stores scalars from both BBs in one list. \n",
    "            vecs_tot = np.vstack((vecs_tot,BB_vec_tot))\n",
    "\n",
    "        #After deleting the dummy element these lists should contain the same number of vectors as the length of start_stop_times. \n",
    "        #vecs_LE = np.delete(vecs_LE,0,axis=0) # Deletes dummy zeros element. \n",
    "        vecs_tot = np.delete(vecs_tot,0,axis=0) # Deletes dummy zeros element. \n",
    "        \n",
    "        # Now I am going to randomize the order of LE neurons in these two vectors, and then take the dot product between them. \n",
    "        # This process will be repeated 100 times to get an average for the dot product.\n",
    "        #BB1_LE_vec,BB2_LE_vec = vecs_LE[0],vecs_LE[1] # Grabs LE fraction-in-theta vectors. \n",
    "        BB1_tot_vec, BB2_tot_vec = vecs_tot[0],vecs_tot[1]\n",
    "        \n",
    "        rand_dotp_sum = 0 # This holds the sum of dot products between the randomly shuffled vectors.\n",
    "        \n",
    "        for i in range(100): # Done 100 times just to ensure a good average value\n",
    "            rand_BB1_tot_vec,rand_BB2_tot_vec = BB1_tot_vec,BB2_tot_vec #Make copies to shuffle.\n",
    "            np.random.shuffle(rand_BB1_tot_vec),np.random.shuffle(rand_BB2_tot_vec) #shuffles the vector elements randomly. This mixes up the order of LE\n",
    "            # neuron activities in the vector.\n",
    "            rand_dotp_sum += np.dot(rand_BB1_tot_vec,rand_BB2_tot_vec) #Sums each dot product.\n",
    "        \n",
    "        \n",
    "        rand_dotp_avg = rand_dotp_sum/100 # The average dot product between the random vectors. \n",
    "        dotp_ratio = np.dot(BB1_tot_vec,BB2_tot_vec)/rand_dotp_avg # Ratio of the real dotp to the average of a randomly shuffled dotp.\n",
    "\n",
    "        dotp_tot = np.dot(BB1_tot_vec,BB2_tot_vec) #Normal dotp between tot activity vectors.\n",
    "        \n",
    "        #ALL_scalars_LE = np.append(ALL_scalars_LE, [scalars_LE] ,axis=0) # Adds the data from this phase to the full array.\n",
    "        ALL_dotp_tot = np.append(ALL_dotp_tot, [[dotp_tot]] ,axis=0)\n",
    "        ALL_dotp_ratio = np.append(ALL_dotp_ratio, [[dotp_ratio]], axis=0) \n",
    "        ALL_rand_dotp_avg = np.append(ALL_rand_dotp_avg, [[rand_dotp_avg]],axis=0)\n",
    "        \n",
    "    #Now to plot the frac LE firing data:\n",
    "    #ALL_scalars_flat = ALL_scalars_LE.flatten() #This makes it easier to plot.\n",
    "        \n",
    "#     fig1, ax1 = plt.subplots(1,figsize=(15,5))\n",
    "#     ax1.bar(locations_b,ALL_scalars_flat,align='edge',color='grey') #Using the same x-axis locations as the LE group activity bar plot.\n",
    "#     ax1.set_xticks(locations_b) #This places the x-axis labels in the center of each bar group.\n",
    "#     ax1.set_xticklabels(['Pre BB1','Pre BB2','NREM BB1','NREM BB2','REM BB1','REM BB2','Post BB1','Post BB2']);\n",
    "#     ax1.set_title('LE Activity inside Theta Bursts')\n",
    "#     ax1.set_ylabel('(Firing in Theta) / (Total Firing)')\n",
    "#     ax1.set_ylim(0,1)\n",
    "    \n",
    "#     fig1.savefig(directory+'Fraction LE Activity.pdf',format='pdf')\n",
    "    \n",
    "    # And to plot the dotp data:\n",
    "    \n",
    "#     fig2, ax1 = plt.subplots(1,figsize=(15,5))\n",
    "#     ax1.bar(locations_phase,ALL_dotp_flat,align='center',color='black',width=0.1) #Using the same x-axis locations as the LE group activity bar plot.\n",
    "#     ax1.set_xticks(locations_phase) #This places the x-axis labels in the center of each bar group.\n",
    "#     ax1.set_xticklabels(['Pre-Leanring','NREM','REM','Post-Leanring']);\n",
    "#     ax1.set_title('Orthogonality of LE Activity Between Backbones')\n",
    "#     ax1.set_ylabel('Dot Product of LE Activity Vectors')\n",
    "#     ax1.set_ylim(0,1)\n",
    "    \n",
    "#     fig2.savefig(directory+'LE Activity Dotp.pdf',format='pdf')\n",
    "    \n",
    "    \n",
    "    # For the ratio dotp data:\n",
    "    ALL_dotp_flat = ALL_dotp_tot.flatten()\n",
    "    locations_phase = np.arange(4)\n",
    "    ALL_dotp_ratio_flat = ALL_dotp_ratio.flatten()\n",
    "    ALL_rand_dotp_avg_flat = ALL_rand_dotp_avg.flatten()\n",
    "    locations_phase = np.arange(0,16,5)\n",
    "    \n",
    "    fig3, ax1 = plt.subplots(1,figsize=(15,5))\n",
    "    ax1.bar(locations_phase,ALL_dotp_flat,align='center',color='black',width=0.5,label='Dotp')\n",
    "    ax1.bar(locations_phase+1,ALL_rand_dotp_avg_flat,align='center',color='orange',width=0.5,label='Rand Avg')\n",
    "    ax1.bar(locations_phase+2,ALL_dotp_ratio_flat,align='center',color='red',width=0.5,label='Ratio') #Using the same x-axis locations as the LE group activity bar plot.\n",
    "    ax1.set_xticks(locations_phase+1) #This places the x-axis labels in the center of each bar group.\n",
    "    ax1.set_xticklabels(['Pre-Leanring','NREM','REM','Post-Leanring']);\n",
    "    ax1.set_title('Orthogonality of LE Activity Between Backbones')\n",
    "    ax1.set_ylabel('...')\n",
    "    ax1.legend()\n",
    "    \n",
    "    fig3.savefig(directory+'LE Activity Dotp Ratio.pdf',format='pdf')\n",
    "    fig3.savefig(directory+'LE Activity Dotp Ratio.png',format='png')\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------\n",
    "    # LE Group Connection Strengths\n",
    "    \n",
    "    # I need to reshape the phase_periods array so that it is a 2D array with simply each BB's activity during each phase.\n",
    "    # This way, the for loop below can simply run through indexing with no problems.\n",
    "    BB_phases = np.reshape(phase_periods,(-1,2))\n",
    "    \n",
    "    BBs_to_bg = np.zeros((len(BB_phases),2,2)) # Holds connections from BBs to blue and green for each phase. This requires 4 numbers per\n",
    "    # phase, and looks like: [ [end phase 1 [BB1 to blue,BB1 to green],[BB2 to blue,BB2 to green] ], ...phase2 ].\n",
    "    quad_to_b = np.zeros((len(BB_phases),4)) # Holds connections strengths from each individual quad group to blue.\n",
    "    # [ [b to b, g to b, pu to b, pi to b], ... ]\n",
    "    quad_to_g = np.zeros((len(BB_phases),4)) # Same, but to green. [ [b to g, g to g, pu to g, pi to g], ... ]\n",
    "    \n",
    "    #It will be easier to seperate LE neurons into groups:\n",
    "    LE_quad_neurons = [[],[],[],[]] #For holding LE neurons by quad group.\n",
    "    for LE_nrn in LE_neurons: \n",
    "        if LE_nrn.scatter_quad_color == 'blue':\n",
    "            LE_quad_neurons[0].append(LE_nrn)\n",
    "        if LE_nrn.scatter_quad_color == 'green':\n",
    "            LE_quad_neurons[1].append(LE_nrn)\n",
    "        if LE_nrn.scatter_quad_color == 'purple':\n",
    "            LE_quad_neurons[2].append(LE_nrn)\n",
    "        if LE_nrn.scatter_quad_color == 'pink':\n",
    "            LE_quad_neurons[3].append(LE_nrn)\n",
    "            \n",
    "    #Using the BB_phases list from above:\n",
    "    for index_phase,(start_phase,end_phase) in enumerate(BB_phases):\n",
    "        \n",
    "        try:\n",
    "            index = [time for cws,time in neurons[0].cw_in_history].index(end_phase) #Gets index of cw_in_history at time when \n",
    "            # the phase ends.\n",
    "        except ValueError: #This covers the case where we try and index the simLength. Simulation of course only runs\n",
    "            # to simLength-1, so we just tell it to grab that value instead.\n",
    "            index = [time for cws,time in neurons[0].cw_in_history].index(end_phase-1)\n",
    "            \n",
    "        for b_nrn in LE_quad_neurons[0]: #Loops through blue quad neurons.\n",
    "            endofphase_connweights = b_nrn.cw_in_history[index][0] #Connection weights at just this point in time.\n",
    "            \n",
    "            for presyn_ID, w_conn in enumerate(endofphase_connweights): #Loops through all incoming connection weights.\n",
    "                    if neurons[presyn_ID].connections[b_nrn.ID][1] == 1: #If the connection exists. \n",
    "                            \n",
    "                        if neurons[presyn_ID].backbone_ID == 1 or neurons[presyn_ID].backbone_ID == 2: # If the presynaptic \n",
    "                            # neuron is a backbone neuron.\n",
    "                            BBs_to_bg[index_phase,(neurons[presyn_ID].backbone_ID-1),0] += w_conn\n",
    "                            \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'blue': #For blue to blue connections.\n",
    "                            quad_to_b[index_phase,0] += w_conn \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'green': #For green to blue connections.\n",
    "                            quad_to_b[index_phase,1] += w_conn \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'purple': #For purple to blue connections.\n",
    "                            quad_to_b[index_phase,2] += w_conn \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'pink': #For pink to blue connections.\n",
    "                            quad_to_b[index_phase,3] += w_conn \n",
    "            \n",
    "            \n",
    "        for g_nrn in LE_quad_neurons[1]: #Loops through green quad neurons.\n",
    "            endofphase_connweights = g_nrn.cw_in_history[index][0] #Connection weights at just this point in time.\n",
    "            \n",
    "            for presyn_ID, w_conn in enumerate(endofphase_connweights): #Loops through all incoming connection weights.\n",
    "                    if neurons[presyn_ID].connections[g_nrn.ID][1] == 1: #If the connection exists. \n",
    "                            \n",
    "                        if neurons[presyn_ID].backbone_ID == 1 or neurons[presyn_ID].backbone_ID == 2: # If the presynaptic \n",
    "                            # neuron is a backbone neuron.\n",
    "                            BBs_to_bg[index_phase,(neurons[presyn_ID].backbone_ID-1),1] += w_conn\n",
    "                            \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'blue': #For blue to green connections.\n",
    "                            quad_to_g[index_phase,0] += w_conn \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'green': #For green to green connections.\n",
    "                            quad_to_g[index_phase,1] += w_conn \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'purple': #For purple to green connections.\n",
    "                            quad_to_g[index_phase,2] += w_conn \n",
    "                        if neurons[presyn_ID].scatter_quad_color == 'pink': #For pink to green connections.\n",
    "                            quad_to_g[index_phase,3] += w_conn \n",
    "            \n",
    "    \n",
    "    \n",
    "    #Normalizing:\n",
    "    BBs_to_bg[:,:,0] = BBs_to_bg[:,:,0]/len(LE_quad_neurons[0])\n",
    "    BBs_to_bg[:,:,1] = BBs_to_bg[:,:,1]/len(LE_quad_neurons[1])\n",
    "    \n",
    "    fig4, ax1 = plt.subplots(1,figsize=(15,5))\n",
    "    ax1.bar(locations_b,BBs_to_bg[:,0,0],align='edge',color='blue',label='BB1 to b')\n",
    "    ax1.bar(locations_b+1,BBs_to_bg[:,0,1],align='edge',color='green',edgecolor='blue',linewidth=2,label='BB1 to g')\n",
    "    ax1.bar(locations_b+2,BBs_to_bg[:,1,1],align='edge',color='green',label='BB2 to g')\n",
    "    ax1.bar(locations_b+3,BBs_to_bg[:,1,0],align='edge',color='blue',edgecolor='green',linewidth=2,label='BB2 to b')\n",
    "    ax1.set_xticks(locations_b+2) #This places the x-axis labels in the center of each bar group.\n",
    "    ax1.set_xticklabels(['Pre BB1','Pre BB2','NREM BB1','NREM BB2','REM BB1','REM BB2','Post BB1','Post BB2']);\n",
    "    ax1.set_title('Connection Strength from BB to Quad Groups')\n",
    "    ax1.set_ylabel('Avg CW per Neuron')\n",
    "    ax1.set_ylim(0,20)\n",
    "    ax1.legend()\n",
    "    \n",
    "    fig4.savefig(directory+'CW BBs to bg.pdf',format='pdf')\n",
    "    fig4.savefig(directory+'CW BBs to bg.png',format='png')\n",
    "    \n",
    "    #Normalizing the connection strengths by number of neurons in group:\n",
    "    quad_to_b = quad_to_b/len(LE_quad_neurons[0])\n",
    "    quad_to_g = quad_to_g/len(LE_quad_neurons[1])\n",
    "    \n",
    "    bar_locations = np.array([0,12,24,36,48,60,72,84])\n",
    "    \n",
    "#     fig5, ax1 = plt.subplots(1,figsize=(15,5))\n",
    "#     ax1.bar(bar_locations,quad_to_b[:,0],align='edge',color='blue',edgecolor='blue',linewidth=3,label='b to b')\n",
    "#     ax1.bar(bar_locations+1,quad_to_b[:,1],align='edge',color='blue',edgecolor='green',linewidth=3,label='g to b')\n",
    "#     ax1.bar(bar_locations+2,quad_to_b[:,2],align='edge',color='blue',edgecolor='purple',linewidth=3,label='pu to b')\n",
    "#     ax1.bar(bar_locations+3,quad_to_b[:,3],align='edge',color='blue',edgecolor='pink',linewidth=3,label='pi to b')\n",
    "    \n",
    "#     ax1.bar(bar_locations+5,quad_to_g[:,0],align='edge',color='green',edgecolor='blue',linewidth=3,label='b to g')\n",
    "#     ax1.bar(bar_locations+6,quad_to_g[:,1],align='edge',color='green',edgecolor='green',linewidth=3,label='g to g')\n",
    "#     ax1.bar(bar_locations+7,quad_to_g[:,2],align='edge',color='green',edgecolor='purple',linewidth=3,label='pu to g')\n",
    "#     ax1.bar(bar_locations+8,quad_to_g[:,3],align='edge',color='green',edgecolor='pink',linewidth=3,label='pi to g')\n",
    "    \n",
    "#     ax1.set_xticks(bar_locations+4) #This places the x-axis labels in the center of each bar group.\n",
    "#     ax1.set_xticklabels(['Pre BB1','Pre BB2','NREM BB1','NREM BB2','REM BB1','REM BB2','Post BB1','Post BB2']);\n",
    "#     ax1.set_title('Connection Strengths to Blue and Green LE Groups')\n",
    "#     ax1.set_ylabel('Avg CW per Neuron')\n",
    "#     ax1.set_ylim(0,3)\n",
    "#     ax1.legend()\n",
    "    \n",
    "#     fig5.savefig(directory+'Quad to bg.pdf',format='pdf')\n",
    "#     fig5.savefig(directory+'Quad to bg.png',format='png')\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_hist(time1,time2): #plots histogram of dotp data between LE scatter points. Time1 and Time2 will usually indicate the \n",
    "    # pre and post-learning times respectively.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    \n",
    "    #Below BBs_scatter() is called to return the connection strength values from bb1 and bb2 for LE neurons. \n",
    "    bb1_vals_pre,bb2_vals_pre = BBs_scatter([time1,time1],False)\n",
    "    bb1_vals_post,bb2_vals_post = BBs_scatter([time2,time2],False)\n",
    "\n",
    "    mag_min = 3 # The minimum magnitude a vector can have if it is to be added to the large_scatter_points array.\n",
    "    scatter_points,large_scatter_points,bg_scatter_points = [],[],[] #To hold pre and post learning scatter points.\n",
    "    # pre-learning scatter points to be stored at index 0, post at index 1.\n",
    "    \n",
    "    for bb1_vals_,bb2_vals_ in [[bb1_vals_pre,bb2_vals_pre],[bb1_vals_post,bb2_vals_post]]: #Loops through first the pre-learning\n",
    "        # values and then the post-learning values.\n",
    "        # 2D list of all cw points vectors, normalized to mag 1.\n",
    "        scatter_points_temp = [np.array([bb1_val,bb2_val])/(np.sqrt(np.array([bb1_val,bb2_val]).dot(np.array([bb1_val,bb2_val])))) \\\n",
    "                          for bb1_val,bb2_val in zip(bb1_vals_,bb2_vals_)]\n",
    "        #2D list of cw points vectors, normalized to mag 1, and only including points whose magnitude was above 3 before normalization.\n",
    "        large_scatter_points_temp = [np.array([bb1_val,bb2_val])/(np.sqrt(np.array([bb1_val,bb2_val]).dot(np.array([bb1_val,bb2_val])))) \\\n",
    "                          for bb1_val,bb2_val in zip(bb1_vals_,bb2_vals_) if \\\n",
    "                                np.sqrt(np.array([bb1_val,bb2_val]).dot(np.array([bb1_val,bb2_val]))) > mag_min] \n",
    "        # 2D list of cw points of green and blue LE neurons.      \n",
    "        bg_scatter_points_temp = [np.array([bb1_val,bb2_val])/(np.sqrt(np.array([bb1_val,bb2_val]).dot(np.array([bb1_val,bb2_val])))) \\\n",
    "                          for index,(bb1_val,bb2_val) in enumerate(zip(bb1_vals_,bb2_vals_)) if \\\n",
    "                             LE_neurons[index].scatter_quad_color == 'blue' or \\\n",
    "                            LE_neurons[index].scatter_quad_color == 'green'] \n",
    "        \n",
    "        scatter_points.append(scatter_points_temp) \n",
    "        large_scatter_points.append(large_scatter_points_temp)\n",
    "        bg_scatter_points.append(bg_scatter_points_temp)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    bg_points_colors = [nrn_LE.scatter_quad_color for nrn_LE in LE_neurons if nrn_LE.scatter_quad_color == 'blue' or \\\n",
    "                        nrn_LE.scatter_quad_color == 'green'] #Grabs colors of all LE neurons to match with bg_scatter_points.\n",
    "    \n",
    "    # For the following lists, index 0 will hold pre-learning and index 1 post learning.\n",
    "    dotp_values = [] #List to hold all the dot product values between cw points.\n",
    "    large_dotp_values = [] #List to hold all the dot product values between cw points with mag above mag_min.\n",
    "    bbgg_dotp_values = [] #List to hold all the dot product values for b-b and g-g point pairs. \n",
    "    bggb_dotp_values = [] # Holds all dot product values for b-g and g-b point pairs.\n",
    "\n",
    "    \n",
    "    for i in range(2): #loops over pre and post learning scatter points.\n",
    "        \n",
    "        dotp_values_temp = []\n",
    "        \n",
    "        for index_1,cw_point_1 in enumerate(scatter_points[i]): #Loops through all the points.\n",
    "            for index_2,cw_point_2 in enumerate(scatter_points[i]): #Loops through all points again.\n",
    "\n",
    "                if index_1 != index_2: #Avoids taking the dot product between the same point.\n",
    "                    temp_dotp = np.dot(cw_point_1,cw_point_2)\n",
    "                    dotp_values_temp.append(temp_dotp)\n",
    "                    \n",
    "        dotp_values.append(dotp_values_temp)\n",
    "         \n",
    "        \n",
    "        large_dotp_values_temp = []\n",
    "\n",
    "        for index_1,cw_point_1 in enumerate(large_scatter_points[i]): #Loops through all the points.\n",
    "            for index_2,cw_point_2 in enumerate(large_scatter_points[i]): #Loops through all points again.\n",
    "\n",
    "                if index_1 != index_2: #Avoids taking the dot product between the same point.\n",
    "                    temp_dotp = np.dot(cw_point_1,cw_point_2)\n",
    "                    large_dotp_values_temp.append(temp_dotp)\n",
    "                    \n",
    "        large_dotp_values.append(large_dotp_values_temp)\n",
    "                    \n",
    "                    \n",
    "        bbgg_dotp_values_temp = []\n",
    "        bggb_dotp_values_temp = []\n",
    "        \n",
    "        for index_1,cw_point_1 in enumerate(bg_scatter_points[i]): #Loops through all the points.\n",
    "            for index_2,cw_point_2 in enumerate(bg_scatter_points[i]): #Loops through all points again.\n",
    "\n",
    "                if index_1 != index_2: #Avoids taking the dot product between the same point\n",
    "                    if bg_points_colors[index_1] == bg_points_colors[index_2]: # b-b and g-g dot products.\n",
    "                        temp_dotp = np.dot(cw_point_1,cw_point_2)\n",
    "                        bbgg_dotp_values_temp.append(temp_dotp)\n",
    "                    if bg_points_colors[index_1] != bg_points_colors[index_2]: # b-g and g-b dot products.\n",
    "                        temp_dotp = np.dot(cw_point_1,cw_point_2)\n",
    "                        bggb_dotp_values_temp.append(temp_dotp)\n",
    "        \n",
    "        bbgg_dotp_values.append(bbgg_dotp_values_temp)\n",
    "        bggb_dotp_values.append(bggb_dotp_values_temp)\n",
    "\n",
    "    \n",
    "    #Plot the histogram:\n",
    "#     fig2, (ax1,ax2) = plt.subplots(1,2,figsize=(16,8))\n",
    "    \n",
    "#     ax1.hist(dotp_values,bins=100)\n",
    "#     ax1.set_title('Dot Products Between CW Scatter Points at {0}ms'.format(time_bb1))\n",
    "#     ax1.set_ylabel('Number of Occurances')\n",
    "#     ax1.set_xlabel('Dot Product Value')\n",
    "    \n",
    "#     ax2.hist(large_dotp_values,bins=100,facecolor='orange')\n",
    "#     ax2.set_title('Dot Products Between CW Scatter Points at {0}ms, Mag > {1}'.format(time_bb1,mag_min))\n",
    "#     ax2.set_ylabel('Number of Occurances')\n",
    "#     ax2.set_xlabel('Dot Product Value')\n",
    "    \n",
    "#     fig2.savefig(directory+'CW Histograms Time={0}.pdf'.format(time_bb1),format='pdf')\n",
    "    \n",
    "    \n",
    "    fig3, (ax1,ax2) = plt.subplots(1,2,figsize=(16,8))\n",
    "    \n",
    "    ax1.hist(bbgg_dotp_values[0],bins=8,facecolor='orange',alpha=1,label='before learning')\n",
    "    ax1.hist(bbgg_dotp_values[1],bins=20,facecolor='red',alpha=0.5,label='after learning')\n",
    "    ax1.set_title('B-B, G-G CW Scatter Points at {0} and {1}ms'.format(time1,time2))\n",
    "    ax1.set_ylabel('Number of Occurances')\n",
    "    ax1.set_xlabel('Dot Product Value')\n",
    "    #ax1.set_xlim(0,1)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.hist(bggb_dotp_values[0],bins=20,facecolor='pink',alpha=1,label='before learning')\n",
    "    ax2.hist(bggb_dotp_values[1],bins=21,facecolor='purple',alpha=0.5,label='after learning')\n",
    "    ax2.set_title('B-G, G-B CW Scatter Points at {0} and {1}ms'.format(time1,time2))\n",
    "    ax2.set_ylabel('Number of Occurances')\n",
    "    ax2.set_xlabel('Dot Product Value')\n",
    "    #ax2.set_xlim(0,1)\n",
    "    ax2.legend()\n",
    "    \n",
    "    fig3.savefig(directory+'BG CW Histograms Pre&Post Learning.pdf'.format(time1,time2),format='pdf')\n",
    "    fig3.savefig(directory+'BG CW Histograms Pre&Post Learning.png'.format(time1,time2),format='png')\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "def export_LE_spikes(t_start_NREM,t_start_REM,t_start_posttest): # Separates LE spikes into each phase and writes them to \n",
    "    # txt file.\n",
    "\n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "    LE_neurons.sort(key=sort_LE_bycolor)\n",
    "\n",
    "    all_spikes = [[] for i in range(len(LE_neurons))] # List for holding all spikes accross entire simulation\n",
    "    pretest_BB1_spikes = [[] for i in range(len(LE_neurons))] # Pre-learning during BB1 activity\n",
    "    pretest_BB2_spikes = [[] for i in range(len(LE_neurons))] # Pre-learning during BB2 activity\n",
    "    NREM_spikes = [[] for i in range(len(LE_neurons))] # Holds spikes that occur in first phase of learning (usually NREM)\n",
    "    NREMtest_BB1_spikes = [[] for i in range(len(LE_neurons))] # Post-NREM during BB1 activity\n",
    "    NREMtest_BB2_spikes = [[] for i in range(len(LE_neurons))] # Post-NREM during BB1 activity\n",
    "    REM_spikes = [[] for i in range(len(LE_neurons))] # Second phase\n",
    "    posttest_BB1_spikes = [[] for i in range(len(LE_neurons))] # post-learning during BB1 activity\n",
    "    posttest_BB2_spikes = [[] for i in range(len(LE_neurons))] # post-learning during BB2 activity\n",
    "\n",
    "    \n",
    "    for i,LE_nrn in enumerate(LE_neurons):\n",
    "        \n",
    "        if len(LE_nrn.spikeTimes) > 0: # So long as the neuron actually spikes\n",
    "            \n",
    "            for spike_t in LE_nrn.spikeTimes*stepSize: # NOTE nrn.spikeTimes gives times in ms/stepSize, so we have to get back\n",
    "                # to ms. spike_t is now in ms.\n",
    "                all_spikes[i].append(spike_t)\n",
    "                \n",
    "                if spike_skip_time+20 < spike_t < BB_len_test: # For BB1 spikes in pre-learning. Skips strange synchronous burst\n",
    "                    # that appears at start of every simulation.\n",
    "                    pretest_BB1_spikes[i].append(spike_t)\n",
    "                \n",
    "                if BB_len_test < spike_t < t_start_NREM: # For BB2 spikes in pre-learning\n",
    "                    pretest_BB2_spikes[i].append(spike_t)\n",
    "                    \n",
    "                if t_start_NREM < spike_t < t_start_NREMtest: # For spikes in first phase (NREM)\n",
    "                    NREM_spikes[i].append(spike_t)\n",
    "                    \n",
    "                if t_start_NREMtest < spike_t < t_start_NREMtest+BB_len_test: # For BB1 spikes in post-NREM test\n",
    "                    NREMtest_BB1_spikes[i].append(spike_t)\n",
    "                \n",
    "                if t_start_NREMtest+BB_len_test < spike_t < t_start_REM: # For BB2 spikes in post-NREM test\n",
    "                    NREMtest_BB2_spikes[i].append(spike_t)\n",
    "            \n",
    "                if t_start_REM < spike_t < t_start_posttest: # For spikes in second phase (REM)\n",
    "                    REM_spikes[i].append(spike_t)\n",
    "                    \n",
    "                if t_start_posttest < spike_t < t_start_posttest+BB_len_test: # For BB1 spikes in post-learning\n",
    "                    posttest_BB1_spikes[i].append(spike_t)\n",
    "                \n",
    "                if t_start_posttest+BB_len_test < spike_t: # For BB2 spikes in post-learning\n",
    "                    posttest_BB2_spikes[i].append(spike_t)\n",
    "            \n",
    "\n",
    "            \n",
    "    with open(directory+\"all_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(all_spikes))\n",
    "    with open(directory+\"pretest_BB1_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(pretest_BB1_spikes))\n",
    "    with open(directory+\"pretest_BB2_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(pretest_BB2_spikes))\n",
    "    with open(directory+\"NREM_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(NREM_spikes))\n",
    "    with open(directory+\"NREMtest_BB1_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(NREMtest_BB1_spikes))\n",
    "    with open(directory+\"NREMtest_BB2_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(NREMtest_BB2_spikes))\n",
    "    with open(directory+\"REM_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(REM_spikes))\n",
    "    with open(directory+\"posttest_BB1_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(posttest_BB1_spikes))\n",
    "    with open(directory+\"posttest_BB2_spikes.txt\", \"w\") as output:\n",
    "        output.write(str(posttest_BB2_spikes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████▎   | 398460/420000 [7:55:22<25:04, 14.32it/s]"
     ]
    }
   ],
   "source": [
    "neurons,nc_Matrix = init_nrn(numnrn) #initializes neurons and creates universal list.\n",
    "strengthen_backbone()\n",
    "init_quad_colors() # Groups LE neurons based on intial connectivities to bbs.\n",
    "strengthen_LE() #Must come after init_quad_colors().\n",
    "def mainProgramLoop():\n",
    "    \n",
    "    for t_ind in tqdm(range(Ntimes)):\n",
    "        \n",
    "        #Records timing of spikes (in t/stepSize)\n",
    "        updateSpikeTime(t_ind)\n",
    "        #Updates the input synaptic current to be used in RK4\n",
    "        updateSyn(t_ind)\n",
    "        #A function to update the solutions for all neurons' D.E.s\n",
    "        RK4(t_ind)\n",
    "\n",
    "        vary_param(t_ind) #Checks t_ind to change network gks values. Also added backbone switching and plasticity.\n",
    "        \n",
    "        zeroTempVars() #Resets temporary variables like Isyn\n",
    "    \n",
    "    export_LE_spikes(t_start_NREM,t_start_REM,t_start_posttest) # Exports spike data to .txt files\n",
    "    \n",
    "    return \n",
    "\n",
    "mainProgramLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record_gaussian() #Records spike times as gussian curves.\n",
    "frequency_Theta()\n",
    "plot_raster(0,nc_Matrix) # Plots raster plot\n",
    "plot_bb_mat(bbs_toplot,True) # Plots plasticity and conn matrix\n",
    "plot_plasvstime() # Plots plasticity vs time graphs for each BB.\n",
    "\n",
    "CW_scatter(t_start_NREM,t_start_REM,t_start_posttest,1)\n",
    "CW_scatter(t_start_NREM,t_start_REM,t_start_posttest,2)\n",
    "\n",
    "COM_vectors(t_start_NREM,t_start_posttest,False)\n",
    "\n",
    "LE_connections([[t_start_NREM,t_start_NREM+BB_len_NREM],[t_start_NREM+BB_len_NREM,t_start_REM],\n",
    "                [t_start_REM,t_start_REM+BB_len_REM],[t_start_REM+BB_len_REM,t_start_posttest]])\n",
    "\n",
    "dotp_activity([[spike_skip_time+50,BB_len_test],[BB_len_test+50,t_start_NREM]])\n",
    "dotp_activity([[t_start_NREM+50,t_start_NREM+BB_len_NREM],[t_start_NREM+BB_len_NREM+50,t_start_REM]])\n",
    "dotp_activity([[t_start_REM+50,t_start_REM+BB_len_REM],[t_start_REM+BB_len_REM+50,t_start_posttest]])\n",
    "dotp_activity([[t_start_posttest+50,t_start_posttest+BB_len_test],[t_start_posttest+BB_len_test+50,simLength]])\n",
    "\n",
    "barplots()\n",
    "plot_hist(t_start_NREM,t_start_posttest)\n",
    "\n",
    "beep(makeSound) #Plays beeps as last line of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
