{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e990c803",
   "metadata": {},
   "source": [
    "Code taken from \"NREM and REM New STDP\" on 6-26-22\n",
    "\n",
    "\n",
    "Goal: Create a notebook that doesn't plot and save figures after running, but instead saves all the necessary data from the simulation needed for ploting this data in another notebook.\n",
    "\n",
    "\n",
    "\n",
    "## Changes\n",
    "\n",
    "\n",
    "\n",
    " - Deleted functions that were only for plotting or were old and unused.\n",
    "\n",
    "## Notes\n",
    "\n",
    "\n",
    " - Check this out, to do with saving objects, allowing for reimportation to other notebooks: https://stackoverflow.com/questions/4529815/saving-an-object-data-persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f0ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import random as RD\n",
    "from matplotlib import colors\n",
    "import winsound\n",
    "import csv\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84958a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.numEquations = 4\n",
    "        self.stepSize = 0.1\n",
    "        self.simLength = 12000 #42000\n",
    "        self.tarray = np.arange(0,self.simLength,self.stepSize)\n",
    "        self.Ntimes = len(self.tarray)\n",
    "        self.spikeThreshold = 5 # Sets the voltage(mV) at which a spike is recorded. \n",
    "        self.numnrn = 140 #180 # Number of neurons in the model.\n",
    "        self.numSST = 20 # Number of SST neurons to be forced into the model.\n",
    "        self.c_e = 0.1 # Percent connectivity for excitatory neurons.\n",
    "        self.c_i = 0.5 # Percent connectivity for inhibitory neurons.\n",
    "        self.p_e = 0.8 # Probabilty of an existing connection breaking and forming a new connection, excitatory.\n",
    "        self.p_i = 0 # Probabilty of an existing connection breaking and forming a new connection, inhibitory.\n",
    "        self.local_conn = True # When true, new connections can be formed with local connections. When false, only non-local new\n",
    "                        # connections are formed.\n",
    "            \n",
    "        self.gks_NREM = 1.5 # ACh level of neurons during NREM phase. Type I is gks=0, Type II gks=1.5.\n",
    "        self.gks_REM = 0 # ACh level for neurons during REM phase.\n",
    "        self.gks_test = 0.1 # ACh level for neurons during testing phases.\n",
    "        self.Idrive_min = 0.5 # Lower range for possible random Idrives. For excitory neurons.\n",
    "        self.Idrive_max = 0.5 # Upper range for possible random Idrives. For excitory neurons.\n",
    "        self.Idrive_SST = -0.1 #The Idrive for SST neurons. Should be low enough so that they do not fire without synaptic input. \n",
    "        self.Idrive_LE = -6 # Idrive to be assigned to LE neurons (or a subset of them).\n",
    "        self.Idrive_NABB = -6 # Idrive for the non-active backbone, should be low enough to prevent any firing outside of noise.\n",
    "\n",
    "        self.w_max = 5 #Maximum positive synaptic plasticity multiplier allowed in network.\n",
    "        \n",
    "        self.NABP_boo = False #True # When true, non-active backbone has plasticity. When False, it does not. \n",
    "        self.makeSound = True # Determines whether to play the three tones after simulation is finished.\n",
    "        self.plas_skip_time = 0 #200 # Time before spikes start being recorded (in ms) and plasticity begins.\n",
    "        self.NREMtest_boo = False # Currently not used anywhere. Needs code needs to be added to make the NREM testing phase optional.\n",
    "        self.RD_seed = True # When true, a seed is used to generate connections\n",
    "        self.sim_seed = 4 # The seed for generating all random elements of the simulation. NOTE: defining a seed before a\n",
    "                        # sequence of random events will not only define the outcome of the first random choice/event, but\n",
    "                        # also the following ones. So we only need one seed.\n",
    "        self.bbs_toplot = [1] #[1,2] # list of backbones to plot by ID.\n",
    "        self.directory = r'C:\\Users\\micha\\OneDrive - brandeis.edu\\Umich Stuff\\Zochowski Lab\\Results\\Figure 2\\Data\\NREM-REM single BB' # The directory for all files to be saved to.\n",
    "        \n",
    "        self.osc_period = 500 # The amount of time each BB is active in the oscillations. Note that param.osc_period under 1000*param.plas_thr will\n",
    "                        # likely cause large depotentiation problems. Also, we need param.osc_period < 1000/param.dep_thr to \n",
    "                        # prevent large depotentiation.\n",
    "        self.num_test_phases = 0 # Number of test phases in simulation. Right now we have 3: pre-learning test, \n",
    "                        # post-NREM test, and post-learning test.\n",
    "        self.BB_len_test = 0 #3000 # Length of test phase for each BB (in ms). Total pre- and post- test phase length is then 2*param.BB_len_test.\n",
    "        self.BB_len_NREM = 3000 #int((self.simLength - 2*self.num_test_phases*self.BB_len_test)/4) # The length of NREM for each BB (in ms).\n",
    "        self.BB_len_REM = 3000 #int((self.simLength - 2*self.num_test_phases*self.BB_len_test)/4) # The length of REM for each BB (in ms).\n",
    "        self.t_start_NREM = 2*self.BB_len_test # Time at which NREM begins.\n",
    "        self.t_start_NREMtest = self.t_start_NREM + 2*self.BB_len_NREM # Time at which the test phase after NREM begins.\n",
    "        self.t_start_REM = self.t_start_NREMtest + 2*self.BB_len_test # Time at which REM begins.\n",
    "        self.t_start_posttest = self.t_start_REM + 2*self.BB_len_REM # Time at which the post-learning test phase begins.\n",
    "        self.storage_freq = 50 # How often (in ms) to store connection weight data for each neuron. A value of 10 collects data every \n",
    "                        # 10 ms. At 1 ms, I was having memory issues on Michal's PC because the arrays were getting too large.\n",
    "        \n",
    "        self.w_EE = 0.15 # AMPA connection strength excitatory to excitatory.\n",
    "        self.w_EI = 0.08 # AMPA connection strength excitatory to inhibitory.\n",
    "        self.w_II = 0.15 # GABA A connection strength inhibitory to inhibitory.\n",
    "        self.w_IE = 0 # GABA A connection strength inhibitory to excitatory.\n",
    "        self.w_II_B = 0 # GABA B connection strength inhibitory to inhibitory.\n",
    "        self.w_IE_B = 0.05 # GABA B connection strength inhibitory to excitatory.\n",
    "        \n",
    "        self.LEtoBB_mult = 1 # Multiplier for connections from LE to BB neurons.\n",
    "        self.LEtoLE_mult = 1 # Multiplier for connections from LE to LE neurons.\n",
    "        self.LEtoSST_mult = 1 # Multiplier for connections from LE to SST neurons.\n",
    "        self.BBtoLE_mult = 1 # Multiplier for connections from BB to LE neurons.\n",
    "        self.SSTtoLE_mult = 3.5 # Multiplier for connections from SST to LE neurons.\n",
    "        self.SSTtoBB_mult = 0.5 # Multiplier for connections from SST to BB neurons.\n",
    "        \n",
    "        self.A_dep = 0.025 # The maximum amount a synapse can depotentiate per spike.\n",
    "        self.A_pot = 0.07 # The maximum amount a synapse can potentiate per spike.\n",
    "        self.tau_dep = 34 # Time constant for depotentiation side of STDP rule.\n",
    "        self.tau_pot = 14 # Time constant for potentiation side of STDP rule.\n",
    "        self.const_ISI = 30 # The inter-spike interval (in ms) at which to freeze the magnitude of the depotentiation portion\n",
    "        # of the STDP rule so that it stays constant for larger ISIs.\n",
    "        \n",
    "        self.LEtoLE_plas_mult = 0.3 # Multiplier to modify the plasticity rate of LE to LE connections.\n",
    "        self.LEtoBB_plas_mult = 0.3 # Multiplier to modify the plasticity rate of LE to BB connections.\n",
    "\n",
    "        self.bg_str = 0.5 # The amount to strengthen connections from BB to blue and green LE neurons.\n",
    "        self.pu_weak = 0 # The amount to weaken connections from both BBs to purple LE neurons.\n",
    "        self.pi_weak = 0 # The amount to weaken connections from both BBs to pink LE neurons.\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "def init_param(): # Function to simply initialize a parameter object. Desired changes to parameters should be made here,\n",
    "    # as opposed to being made in the parameter class function (except changes that affect definitions within the parameter\n",
    "    # class definition).\n",
    "\n",
    "    param = parameters()\n",
    "    \n",
    "    # The directory must be updated to have forward slashes, including a forward slash on the end.\n",
    "    param.directory = param.directory.replace('\\\\','/') # Replaces backslash \"\\\" with forward slash \"/\".\n",
    "    param.directory = param.directory + '/' # Adds forward slash to end of string.\n",
    "    \n",
    "#     param.BB_len_NREM = 5000\n",
    "#     param.BB_len_REM = 10000\n",
    "    \n",
    "    \n",
    "    return param\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class neuron:\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.ID = 0\n",
    "        self.position = []\n",
    "        self.connections = [] #List of (1 or 0) connection strengths to other neurons. Is 2D list like [[postsyn,conn],[postsyn,conn]...].\n",
    "        # DO NOT CHANGE self.connections from values of only 1 and 0 because many apects of the program rely on it.\n",
    "        self.connectionWeights = [] #Holds changes made from plasticity. For self as presynaptic nrn. Values are strengths of\n",
    "        # signal to other neurons from this neuron.\n",
    "        self.Input_syn = 0\n",
    "        self.Input_noise = 0\n",
    "        self.Input_external = 0\n",
    "        self.spikeTimes = [] # Set to record a spike when membrane voltage breaches variable param.spikeThreshold.\n",
    "        self.prevActivity = 0\n",
    "        self.neuronsInRange = [] #Tracks the # of neurons in range so as to minimize looping time during connection growth function\n",
    "        self.solutions = np.zeros(param.numEquations) #Why does nrn.solutions still function as a comment?\n",
    "        \n",
    "        #Things I have added in myself:\n",
    "        self.gks = param.gks_test # gks value for neuron, determines effective ACh concentration.\n",
    "        self.spike = False #Determines whether the neuron has already spiked or not. \n",
    "        self.Idrive = 0\n",
    "        self.color = '' #Color of neuron for graphing.\n",
    "        self.conn_in = [] #Connections coming in from other neurons. Sum is the in-degree of the neuron. Note, not tuple like self.connections.\n",
    "        # Format is 1D list of connection strengths, where list index is presynaptic neuron. \n",
    "        self.category = 'Excitatory' #Labels the neuron type. Default is excitatory, can be chanegd to inhibitory. \n",
    "        self.gsyn = 1 # Connection strength multiplier for I->E connections. ------- As of 6/11/22 gsyn is non-functional. It now\n",
    "        # ony is used by the function sort_gsyn() for sorting BB and LE neurons. I should change code to sort based on backbone_ID.\n",
    "        self.pair_spiketimes = np.zeros(param.numnrn) #Pair spike times for outgoing connections. Note that this only holds the most recent pair spiketime for each conn.\n",
    "        self.start_noise = 0 #Starting step time for noise when it occurs (mV/param.stepSize). \n",
    "        self.backbone_ID = 0 # backbone_ID=0 will be used to designate lower E neurons and -1 for inhibitory neurons.\n",
    "        self.spike_gaussian = [] #List of gaussian curves, each centered at the time a neuron spikes. Each index in list corresponds to a t_ind time.\n",
    "        self.plas_on = True #Boolean determining whether or not to change plasticity of connections TO and FROM this nrn. \n",
    "        self.cw_in_history = [] #Connection weight history. Holds plasticity connection weights coming IN (this nrn as postsyn).\n",
    "        # Set up as [[[weight from nrn 0, weight from nrn 1, ... ],time(ms)] ,...], one weight list for each milisecond.\n",
    "        # List set up to skip first plas_skip_time ms because we don't want plasticity due to transient behaviors. Note the default\n",
    "        # value for connections and non-existent connections is 1. \n",
    "        self.cw_out_history = [] # Same as cw_in_history, just with this nrn as the presynaptic neuron.\n",
    "        self.scatter_color = 'grey'\n",
    "        self.quad_color = 'grey' # Color assigned to LE neurons based on initial connectivity to BBs.\n",
    "\n",
    "        \n",
    "        \n",
    "def equations(solns_, eqn, Isyn, Idrive,nrn):\n",
    "    \n",
    "    \n",
    "    tempVal = 0\n",
    "    \n",
    "    category = nrn.category\n",
    "    Inoise = nrn.Input_noise # Noise from neuron. Maybe I should put Idrive, solns, etc here as well?\n",
    "    \n",
    "    if category == 'Excitatory':\n",
    "        gks = nrn.gks\n",
    "        C = 1 \n",
    "        gna = 24\n",
    "        gkdr = 3\n",
    "        gl = 0.02\n",
    "        Vna = 55\n",
    "        Vk = -90\n",
    "        Vl = -60\n",
    "        if(eqn == 0):\n",
    "            hinf = 1/(1+np.exp((solns_[3]+53)/7))\n",
    "            tauh = .37 + 2.78/(1+np.exp((solns_[3]+40.5)/6))\n",
    "            tempVal = (hinf - solns_[0])/tauh \n",
    "        elif(eqn == 1):\n",
    "            ninf = 1/(1+np.exp((-solns_[3]-30)/10))\n",
    "            taun = .37 + 1.85/(1+np.exp((solns_[3]+27)/15))\n",
    "            tempVal = (ninf - solns_[1])/taun\n",
    "        elif(eqn == 2):\n",
    "            zinf = 1/(1+np.exp((-solns_[3]-39)/5))\n",
    "            tempVal = (zinf - solns_[2])/75\n",
    "        elif(eqn == 3):\n",
    "            m = 1/(1+np.exp((-solns_[3]-30)/9.5))\n",
    "            tempVal = (-gna*(m**3)*solns_[0]*(solns_[3]-Vna) - gkdr*(solns_[1]**4)*(solns_[3]-Vk) \n",
    "                       - gks*solns_[2]*(solns_[3]-Vk) - gl*(solns_[3]-Vl) + Idrive - Isyn + Inoise)/C\n",
    "            \n",
    "    elif category == 'SST':\n",
    "        gks = nrn.gks\n",
    "        C = 1 \n",
    "        gna = 24\n",
    "        gkdr = 3\n",
    "        gl = 0.02\n",
    "        Vna = 55\n",
    "        Vk = -90\n",
    "        Vl = -60\n",
    "        if(eqn == 0):\n",
    "            hinf = 1/(1+np.exp((solns_[3]+53)/7))\n",
    "            tauh = .37 + 2.78/(1+np.exp((solns_[3]+40.5)/6))\n",
    "            tempVal = (hinf - solns_[0])/tauh \n",
    "        elif(eqn == 1):\n",
    "            ninf = 1/(1+np.exp((-solns_[3]-30)/10))\n",
    "            taun = .37 + 1.85/(1+np.exp((solns_[3]+27)/15))\n",
    "            tempVal = (ninf - solns_[1])/taun\n",
    "        elif(eqn == 2):\n",
    "            zinf = 1/(1+np.exp((-solns_[3]-39)/5))\n",
    "            tempVal = (zinf - solns_[2])/75\n",
    "        elif(eqn == 3):\n",
    "            m = 1/(1+np.exp((-solns_[3]-30)/9.5))\n",
    "            tempVal = (-gna*(m**3)*solns_[0]*(solns_[3]-Vna) - gkdr*(solns_[1]**4)*(solns_[3]-Vk) \n",
    "                       - gks*solns_[2]*(solns_[3]-Vk) - gl*(solns_[3]-Vl) + Idrive - Isyn)/C\n",
    "            \n",
    "    elif category == 'PV+':\n",
    "        gks = nrn.gks\n",
    "        C = 1 \n",
    "        gna = 35\n",
    "        gkdr = 9\n",
    "        gl = 0.1\n",
    "        Vna = 55\n",
    "        Vk = -90\n",
    "        Vl = -65    \n",
    "        if(eqn == 0):\n",
    "            a_h = 0.07*np.exp(-(solns_[3]+58)/20)\n",
    "            b_h = 1/(np.exp(-0.1*(solns_[3]+28))+1)\n",
    "            phi = 5\n",
    "            tempVal = phi*(a_h*(1-solns_[0]) - b_h*solns_[0])\n",
    "        elif(eqn == 1):\n",
    "            a_n = -0.01*(solns_[3]+34)/(np.exp(-0.1*(solns_[3]+34))-1)\n",
    "            b_n = 0.125*np.exp(-(solns_[3]+44)/80)\n",
    "            phi = 5\n",
    "            tempVal = phi*(a_n*(1-solns_[1])-b_n*solns_[1])\n",
    "        elif(eqn == 2):\n",
    "            zinf = 1/(1+np.exp((-solns_[3]-39)/5))\n",
    "            tempVal = (zinf - solns_[2])/75\n",
    "        elif(eqn == 3):\n",
    "            a_m = -0.1*(solns_[3]+35)/(np.exp(-0.1*(solns_[3]+35))-1)\n",
    "            b_m = 4*np.exp(-(solns_[3]+60)/18)\n",
    "            m = a_m/(a_m+b_m)\n",
    "            tempVal = (-gna*(m**3)*solns_[0]*(solns_[3]-Vna) - gkdr*(solns_[1]**4)*(solns_[3]-Vk) \n",
    "                       - gks*solns_[2]*(solns_[3]-Vk) - gl*(solns_[3]-Vl) + Idrive - Isyn)/C\n",
    "        \n",
    "    return tempVal\n",
    "\n",
    "\n",
    "def RK4(t_ind):\n",
    "    \n",
    "    global neuron\n",
    "    \n",
    "    for nrn in neurons:\n",
    "        \n",
    "        \n",
    "        solns = nrn.solutions\n",
    "        Isyn = nrn.Input_syn\n",
    "        Idrive = nrn.Idrive\n",
    "        k1 = np.zeros(param.numEquations)\n",
    "        k2 = np.zeros(param.numEquations)\n",
    "        k3 = np.zeros(param.numEquations)\n",
    "        k4 = np.zeros(param.numEquations)\n",
    "        \n",
    "        init_solns = solns\n",
    "        \n",
    "        #Calculates the k1 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k1[ii] = param.stepSize*equations(solns, ii,Isyn,Idrive,nrn)\n",
    "\n",
    "        #Calculates the k2 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k2[ii] = param.stepSize*equations(solns+k1/2, ii,Isyn,Idrive,nrn) #important fix done here. solns must be advanced by k\n",
    "                                                                    #for calculation of the next k variable.\n",
    "        #Calculates the k3 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k3[ii] = param.stepSize*equations(solns+k2/2, ii,Isyn,Idrive,nrn) \n",
    "\n",
    "        #Calculates the k4 variables\n",
    "        for ii in range(len(solns)):\n",
    "            k4[ii] = param.stepSize*equations(solns+k3, ii,Isyn,Idrive,nrn)\n",
    "        \n",
    "        #Updates the general solution\n",
    "        for ii in range(len(solns)):\n",
    "            solns[ii] = init_solns[ii] + (k1[ii] + 2*k2[ii] + 2*k3[ii] + k4[ii])/6 \n",
    "            nrn.solutions[ii] = solns[ii]\n",
    "            \n",
    "            \n",
    "            \n",
    "def init_nrn(): #initializes neurons and assigns ID, connections, weights, etc. \n",
    "    global neuron\n",
    "    neurons = [] #List containing neuron objects\n",
    "    nconn_Mat = [np.empty(3)] # 2D matrix for storing new connections.\n",
    "    \n",
    "    if param.RD_seed: # When true, the simulation will be reproducable entirely (all connections, neuron assignments, initial coniditions).\n",
    "        RD.seed(param.sim_seed)\n",
    "    \n",
    "    def count_SST(neurons): # A function for counting the number of SST neurons.\n",
    "        count = 0\n",
    "        for nrn in neurons:\n",
    "            if nrn.category == 'SST':\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    \n",
    "    for i in range(param.numnrn):  \n",
    "        neurons = np.append(neurons,neuron()) #Intiallizes param.numnrn number of neurons\n",
    "        \n",
    "        \n",
    "    #This for loop ensures that exactly param.numSST number of E neurons are changed to SST.\n",
    "    for i in range(param.numSST):\n",
    "        changed_to_SST = False #Keeps loop running until excitatory neuron is found to change to SST neuron.\n",
    "        while changed_to_SST == False: #Loop mentioned above.\n",
    "            nrn = RD.choice(neurons) #grabs one neuron object at random (available for editing)\n",
    "            if nrn.category == 'Excitatory': #If true, turns excitatory neuron to SST. If neuron is not Excitatory, while loop runs again.\n",
    "                nrn.category = 'SST'\n",
    "                nrn.backbone_ID = -1 #Assigns inhibitory neurons to backbone ID = -1.\n",
    "                changed_to_SST = True\n",
    "                \n",
    "    #Create list of only E neurons.\n",
    "    Eneurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.category == 'Excitatory':\n",
    "            Eneurons.append(nrn) #Note that even though this is a different list than neurons, the neuron objects within can be\n",
    "            # changed all the same like they were in neurons. \n",
    "                \n",
    "                \n",
    "    #Changes all excitatory neurons to having high inhibition (i.e. like LE neurons):\n",
    "    for nrn in Eneurons:\n",
    "        nrn.gsyn = 3\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_backbones(Eneurons):\n",
    "        #this function initializes backbones into a network assuming that all E neurons have a high gysn (high inhibition level). \n",
    "        # Takes list of excitatory neuron objects as input. WILL NEED TO FIX WITH try->except when num_per_bb > non_bb_size because\n",
    "        #then LElist will sample too many elements from templist on last run of loop. \n",
    "        global neuron \n",
    "\n",
    "        num_bb = 1 #2 #number of backbones to create from number of available E neurons\n",
    "        non_bb_size = 80 #number of non-backbone E neurons to be left in network.\n",
    "        num_bb_nrns = param.numnrn - (param.numSST + non_bb_size) #number of neurons for splitting into backbones.\n",
    "        num_per_bb = int(num_bb_nrns/num_bb) # number of E neurons per backbone.\n",
    "\n",
    "        bb_list = RD.sample(Eneurons,num_per_bb) #temp list for looping. Randomly samples num_per_bb # of neurons from Eneurons.\n",
    "\n",
    "        for bb in range(1,num_bb+1): #This makes the notation easier by shifitng indicies +1. This is because nrn.backbone_ID=0\n",
    "        # is reserved for NON-backbone neurons. bb=1 designates backbone_ID=1.\n",
    "            templist=[]\n",
    "\n",
    "            for nrn in bb_list:\n",
    "                nrn.backbone_ID = bb # Assigns first randomly chosen group of neurons to the first backbone.\n",
    "                nrn.gsyn = 0.5 #Backbones are created in the \"on\" state.\n",
    "                \n",
    "            for nrn in Eneurons: #Makes a new list with only non-backbone nrns.\n",
    "                if nrn.backbone_ID == 0:\n",
    "                    templist.append(nrn)\n",
    "            bb_list = RD.sample(templist,num_per_bb)\n",
    "\n",
    "        \n",
    "        \n",
    "    create_backbones(Eneurons)\n",
    "\n",
    "\n",
    "    ID = 0\n",
    "    bb_colors = ['cyan','blue','green','orange','purple'] # Colors for backbones, cyan reserved for non-backbone E neurons.\n",
    "    for nrn in neurons: #assigns neurons in list their IDs, init voltage, Idrive, etc.\n",
    "        nrn.ID = ID\n",
    "        ID += 1 \n",
    "        nrn.spikeTimes = []\n",
    "        nrn.solutions = [RD.random(),RD.random(),RD.random(),RD.uniform(-55,-20)] #Initial conditions of each neuron. Initial voltage randomly assigned between -55 and -20 mV.\n",
    "        nrn.connectionWeights = [1]*param.numnrn #Creates a list of all connection weights to other neurons at value 1. \n",
    "\n",
    "        if nrn.category == 'Excitatory':\n",
    "            nrn.Idrive = round(RD.uniform(param.Idrive_min, param.Idrive_max),3) #Random value between min and max rounded to 1 decimal places\n",
    "            nrn.color = bb_colors[nrn.backbone_ID] #Assigns nrn color coded for backbone.\n",
    "            \n",
    "        if nrn.category == 'SST':\n",
    "            nrn.color = 'Red' #Inhibitory given red.\n",
    "            nrn.Idrive = param.Idrive_SST #Idrive for inhibitory neurons. \n",
    "        if nrn.category == 'PV+':\n",
    "            nrn.color = 'darkorange'\n",
    "            nrn.Idrive = round(RD.uniform(Idrive_PVplus_min,Idrive_PVplus_max),3)\n",
    "    \n",
    "    conn_Matrix = np.zeros((param.numnrn,param.numnrn)) #initializes matrix of zeros with param.numnrn x param.numnrn size. Row = nrn #, Column = connected nrn #\n",
    "    # Fills matrix with connectivity based on proximity. conn_span # of neurons to right and left are given full connection. \n",
    "    for row_index, row in enumerate(conn_Matrix):\n",
    "        for column_index, conn in enumerate(row):\n",
    "            \n",
    "            if neurons[row_index].category == 'Excitatory': #Determines which connectivity percent to use based on neuron category.\n",
    "                conn_span = int(param.c_e*param.numnrn/2) #number of neurons to be connected on either side of a neuron.\n",
    "\n",
    "                #sets neurons at +- conn_span from diagonal to full connectivity.\n",
    "                if column_index >= row_index-conn_span and column_index <= row_index+conn_span:\n",
    "                    conn = 1 \n",
    "                #Full connectivity at edge case of first neurons connected to last neurons in ring.\n",
    "                elif row_index-conn_span < 0 and column_index >= param.numnrn+row_index-conn_span:\n",
    "                    conn = 1\n",
    "                #Full connectivity at edge case of last neurons connected to first neurons in ring.\n",
    "                elif row_index+conn_span > (param.numnrn-1) and column_index <= row_index-param.numnrn+conn_span:\n",
    "                    conn = 1 \n",
    "                #All other neurons have zero connectivity.\n",
    "                else:\n",
    "                    conn = 0\n",
    "                # Sets diagonal entries to zero.\n",
    "                if column_index == row_index:\n",
    "                    conn = 0\n",
    "                    \n",
    "            elif neurons[row_index].category == 'SST' or neurons[row_index].category == 'PV+': # If the presynaptic neuron is inhibitory.\n",
    "                if RD.random() <= param.c_i and column_index != row_index: # if a random between 0 and 1 is less than the connectivity percent. \n",
    "                    conn = 1\n",
    "                else:\n",
    "                    conn = 0\n",
    "                    \n",
    "            row[column_index] = conn  #Assigns the local connections.\n",
    "        conn_Matrix[row_index] = row\n",
    "\n",
    "    # Changes connections based on proability p. \n",
    "    for row_index, row in enumerate(conn_Matrix): \n",
    "        row_temp = row.copy() #used to store changes while deleting connections from new_conn_list. VERY IMPORTANT TO USE .copy()\n",
    "         # otherwise row will change when row_temp is changed. This is how assignment works. \n",
    "        if neurons[row_index].category == 'Excitatory': #Determines which connectivity percent to use based on neuron category.\n",
    "            conn_span = int(param.c_e*param.numnrn/2) #number of neurons to be connected on either side of a neuron.\n",
    "            p = param.p_e\n",
    "        elif neurons[row_index].category == 'SST' or neurons[row_index].category == 'PV+':\n",
    "            conn_span = int(param.c_i*param.numnrn/2)\n",
    "            p = param.p_i \n",
    "\n",
    "        for column_index, conn in enumerate(row):\n",
    "            \n",
    "            if conn != 0: #only for existing connections.\n",
    "                if RD.random() <= p: # RD.random() selects random float between 0 and 1.\n",
    "\n",
    "                    if param.local_conn == True: # Allows new local connections.\n",
    "                        new_conn_list = np.append(np.arange(0,row_index,1),np.arange(row_index+1,param.numnrn,1)) #Creates list of\n",
    "                        #all nrn IDs besides self.\n",
    "                    if param.local_conn == False: #No new local connections.\n",
    "                        #List of all nrns except local and self. Very gross and uses heaviside functions. May be simplifiable. \n",
    "                        new_conn_list = np.append(np.arange(param.numnrn - param.numnrn*np.heaviside(row_index-conn_span-1, 1)\n",
    "                                    +(row_index+conn_span-param.numnrn+1)*np.heaviside(row_index+conn_span-param.numnrn,1),row_index-conn_span,1),\n",
    "                                    np.arange(row_index+conn_span+1,(param.numnrn+row_index-conn_span)-\n",
    "                                    (row_index-conn_span)*np.heaviside(row_index-conn_span, 1),1))\n",
    "                     \n",
    "                    for index, val in enumerate(row_temp):#Deletes established conns from new_conn_list, preventing double connections.\n",
    "\n",
    "                        if val != 0: #Sorts out only established conns.\n",
    "                            delindex = np.where(new_conn_list == index) #Finds where est. conn lies in new_conn_list.\n",
    "                            if len(delindex[0]) > 0: #Stops error from having nothing to delete when param.local_conn = False. \n",
    "                                delindex = delindex[0][0] #grabs useful integer.\n",
    "                                new_conn_list = np.delete(new_conn_list, delindex) #deletes from possible conns. \n",
    "    \n",
    "                    nconn = RD.choice(new_conn_list) #Randomly selects one neuron to connect to. \n",
    "                    nconn_info = [[row_index, column_index, nconn]] # [neuron #, old connection, new connection]. Must be 2D.\n",
    "                    nconn_Mat = np.concatenate((nconn_Mat,nconn_info)) #Adds this info to a matrix for later use.\n",
    "                    \n",
    "                    #Updates values of the array used in determining new connections. \n",
    "                    row_temp[int(column_index)] = 0 \n",
    "                    row_temp[int(nconn)] = 1\n",
    "\n",
    "\n",
    "    nconn_Mat = np.delete(nconn_Mat,0,0) #Removes np.empty dummy row from matrix.\n",
    "    \n",
    "    #Apply new connection changes.\n",
    "    for info in nconn_Mat:\n",
    "        conn_Matrix[int(info[0]),int(info[1])] = 0 #Sets old connection to zero.\n",
    "        conn_Matrix[int(info[0]),int(info[2])] += 1 #Establishes connection or adds another connection.\n",
    "\n",
    "    nc_Matrix = np.empty((param.numnrn,param.numnrn,2)) #Empty matrix to hold final values. nc means neuron # and connection strength. \n",
    "    count = 0\n",
    "    # Creates 3D array, nc_matrix, storing (nrn #, conn strength to nrn receiving Isyn)\n",
    "    for row in conn_Matrix:\n",
    "        conn_tuple = list(enumerate(row)) #list of tuples with info (postsyn nrn #, recieving nrn conn strength)\n",
    "        nc_Matrix[count] = conn_tuple \n",
    "        count += 1\n",
    "\n",
    "    \n",
    "    #Assigns neuron objects the list of tuple connections. \n",
    "    for nrn in neurons:\n",
    "        nrn.connections = nc_Matrix[nrn.ID] #Outgoing connections for nrn.\n",
    "        nrn.conn_in = nc_Matrix[:,nrn.ID][:,1]# Incoming connections for nrn. [0,0,1,1] would mean this neuron recieves no\n",
    "        # signal from neurons 0 and 1, and full signal from neurons 2 and 3. \n",
    "        \n",
    "        \n",
    "    def del_crossbb_conns():\n",
    "        # This function deletes E-E connections between neurons in different backbones. This prevents the activity of one backbone\n",
    "        # form exciting the other.\n",
    "        global neuron\n",
    "\n",
    "        for nrn1 in neurons:\n",
    "            for nrn2 in neurons:\n",
    "                #The following checks that nrns are not inhibitory (bb=-1) or lower excitatory (bb=0) and are in different backbones with a connection.\n",
    "                if nrn1.backbone_ID not in [-1,0] and nrn2.backbone_ID not in [-1,0] and nrn1.backbone_ID != nrn2.backbone_ID and nrn1.connections[int(nrn2.ID)][1] == 1:\n",
    "                    nrn1.connections[int(nrn2.ID)][1] = 0 #Eliminates connection between neurons.\n",
    "                \n",
    "    del_crossbb_conns()\n",
    "    \n",
    "    def del_LEtobb_conns():\n",
    "        # This function deletes LE to BB connections. NOTE that the conn mat/ plas mat are not changed, so they still show these connections as existing.\n",
    "        global neuron\n",
    "\n",
    "        for nrn in neurons:\n",
    "            for postsyn, conn in nrn.connections:\n",
    "                if nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID in param.bbs_toplot:\n",
    "                    nrn.connections[int(postsyn)][1] = 0 #Eliminates connection between neurons.\n",
    "\n",
    "    #del_LEtobb_conns()\n",
    "    \n",
    "    \n",
    "    return neurons,nc_Matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def init_quad_colors(): # Function for initializing the color groups of LE neurons based on their initial connections to bbs.\n",
    "    # This function should be run after connections are established (after init_neurons()) but before the t_ind loop for the \n",
    "    # simulation begins.\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "            \n",
    "    quad_colors = ['blue', 'green', 'purple', 'pink']\n",
    "    quad_counts = [0,0,0,0] # counts the number of LE assigned to each color. [blue, green, purple, pink].\n",
    "    \n",
    "    LE_sum_cw_bb1,LE_sum_cw_bb2 = np.zeros(len(LE_neurons)),np.zeros(len(LE_neurons)) #Arrays of cw sums for plotting on scatter plot.\n",
    "\n",
    "    # Need to fill LE_sum_cw_bbx with number of connections (effectively the cw) from bbx. This will be used to sort for quadrant colors.\n",
    "    # LE_sum_cw_bbx is analogous to bbx_REM_vals from BBs_scatter().\n",
    "    for LE_nrn in LE_neurons:\n",
    "        for index,conn in enumerate(LE_nrn.conn_in):\n",
    "            if neurons[index].backbone_ID == 1 and conn == 1: # If presyn is bb1 and connection exists.\n",
    "                LE_sum_cw_bb1[LE_neurons.index(LE_nrn)] += 1 # Adds 1 so that at after the loop, index represents total # of\n",
    "                                                             # connections from bb1 to this LE nrn.   \n",
    "            if neurons[index].backbone_ID == 2 and conn == 1:\n",
    "                LE_sum_cw_bb2[LE_neurons.index(LE_nrn)] += 1\n",
    "            \n",
    "    # Zip all this data together with the neuron objects.\n",
    "    nrns_and_cws = zip(LE_neurons, LE_sum_cw_bb1, LE_sum_cw_bb2)\n",
    "    \n",
    "    # First sort the list based on one of the backbones, say bb1. Strongest first in the list.\n",
    "    sorted_bb1 = [(nrn,cw_bb1,cw_bb2) for nrn,cw_bb1,cw_bb2 in sorted(nrns_and_cws, reverse=True, key=sort_tuple_1)]\n",
    "    \n",
    "    # Then separate the sorted list into two halves, one half for the blue/purple neurons, the other for the green/pink.\n",
    "    strong_bb1, weak_bb1 = [],[] \n",
    "    for index,val in enumerate(sorted_bb1):\n",
    "        if index < len(LE_neurons)/2: \n",
    "            strong_bb1.append(val) # Sorts strongest bb1 connections into strong_bb1.\n",
    "        else:\n",
    "            weak_bb1.append(val) # Sorts weaker bb1 connections into weak_bb1.\n",
    "    \n",
    "    # Now I need to sort these two lists by strength of connections from the other backbone, bb2. Strongest first in the list.\n",
    "    sorted_strong_bb1 = [(nrn,cw_bb1,cw_bb2) for nrn,cw_bb1,cw_bb2 in sorted(strong_bb1, reverse=True, key=sort_tuple_2)]\n",
    "    sorted_weak_bb1 = [(nrn,cw_bb1,cw_bb2) for nrn,cw_bb1,cw_bb2 in sorted(weak_bb1, reverse=True, key=sort_tuple_2)]\n",
    "    \n",
    "    # Now everything should be fully sorted into four equal size groups based on connection strength to both backbones.\n",
    "    # Remember that for each time the lists were sorted, the strongest connections were sorted to the beginning of the list.\n",
    "    for index, (nrn,cw_bb1,cw_bb2) in enumerate(sorted_strong_bb1):\n",
    "        \n",
    "        if index < len(LE_neurons)/4: # Strongest to both bbs: purple LE neurons.\n",
    "            nrn.quad_color = quad_colors[2]\n",
    "            quad_counts[2] += 1\n",
    "        else: # Strong to bb1 but weak to bb2: blue LE neurons.\n",
    "            nrn.quad_color = quad_colors[0] \n",
    "            quad_counts[0] += 1    \n",
    "            \n",
    "    for index, (nrn,cw_bb1,cw_bb2) in enumerate(sorted_weak_bb1):\n",
    "        \n",
    "        if index < len(LE_neurons)/4: # Weak to bb1 but strong to bb2: green LE neurons.\n",
    "            nrn.quad_color = quad_colors[1]\n",
    "            quad_counts[1] += 1\n",
    "        else: # Weak to both bbs: pink LE neurons.\n",
    "            nrn.quad_color = quad_colors[3] \n",
    "            quad_counts[3] += 1   \n",
    "    \n",
    "#    print('Number LE Neurons. [blue, green, purple, pink]: ', quad_counts)\n",
    "    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            \n",
    "    \n",
    "            \n",
    "def updateSyn(t_ind): #Gives synaptic input to all neurons on connection list\n",
    "    #Includes changes in synaptic strengths. t_start is the time at which the presynaptic neuron's voltage breaches -20 mV.\n",
    "    # Has been changed to normalize strength of inputs to a neuron by number of inputs. I.e sum of all inputs comes to param.w_max. \n",
    "    t_temp = 0 \n",
    "    global neuron\n",
    "    \n",
    "    tau = 0.5 # Time constant for fast-acting receptors.\n",
    "    tau_B = 50 # Time constant for GABA B receptors, slow-acting.\n",
    "    \n",
    "    \n",
    "    for nrn in neurons:# presynaptic neurons.         \n",
    "        if len(nrn.spikeTimes) > 0: # To prevent errors of calling [-1] from an array without any entries. Can change to be l > 2, 3 ...\n",
    "            t_temp = nrn.spikeTimes[-1] #grabs time this neuron spikes at.\n",
    "\n",
    "            for conn in nrn.connections: #Gives all postsynaptic neurons Isyn corrspondping to their voltage.\n",
    "                if conn[1] != 0: #Prevents synaptic current from being calculated to non-connected neurons.\n",
    "                    \n",
    "                    V = neurons[int(conn[0])].solutions[3] #Voltage of postsynaptic neuron. Note conn[1] is the connection strength and conn[0] is the ID.\n",
    "                    Isyn = 0 \n",
    "\n",
    "                    if nrn.category == 'SST' or nrn.category == 'PV+': # Handles GABA A and B receptors in postsyn  neurons.\n",
    "                        \n",
    "                        E_syn = -75 # Chloride reversal potential. \n",
    "                        \n",
    "                        if neurons[int(conn[0])].category == 'SST' or neurons[int(conn[0])].category == 'PV+': # For I-I connections.\n",
    "                            for w,t in (param.w_II,tau),(param.w_II_B,tau_B): #Sends two signals, one with w_II/tau and one with param.w_II_B/tau_B. \n",
    "                                Isyn += conn[1]*(w)*np.exp(-param.stepSize*(t_ind-t_temp)/t)*(V - E_syn) # t is tau here. \n",
    "                                \n",
    "                        if neurons[int(conn[0])].category == 'Excitatory': # For I->E connections.\n",
    "                            \n",
    "                            for w,t in (param.w_IE,tau),(param.w_IE_B,tau_B):\n",
    "                                if neurons[int(conn[0])].backbone_ID == 0: # For I->LE connections.\n",
    "                                    Isyn += param.SSTtoLE_mult*conn[1]*(w)*np.exp(-param.stepSize*(t_ind-t_temp)/t)*(V - E_syn)\n",
    "                                else: # For other connections, i.e. I->BB\n",
    "                                    Isyn += param.SSTtoBB_mult*conn[1]*(w)*np.exp(-param.stepSize*(t_ind-t_temp)/t)*(V - E_syn)\n",
    "                                    \n",
    "                    if nrn.category == 'Excitatory':\n",
    "                        \n",
    "                        E_syn = 0 # Sodium reversal potential. E_syn = 0 for excitory synapse and E_syn = -75 mV for inhibitory synapse\n",
    "                        \n",
    "                        if nrn.backbone_ID == 0: # If presynaptic neuron in an LE neuron.\n",
    "                            if neurons[int(conn[0])].category == 'SST' or neurons[int(conn[0])].category == 'PV+': # For LE->I connections.\n",
    "                                Isyn =param.LEtoSST_mult*conn[1]*(param.w_EI)*np.exp(-param.stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                            if neurons[int(conn[0])].category == 'Excitatory': # For LE-E connections.\n",
    "                                if neurons[int(conn[0])].backbone_ID == 0: # If postsynaptic neuron is LE as well. \n",
    "                                    Isyn = param.LEtoLE_mult*nrn.connectionWeights[int(conn[0])]*conn[1]*(param.w_EE)*np.exp(-param.stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                                elif neurons[int(conn[0])].backbone_ID in param.bbs_toplot: # For LE->BB connections\n",
    "                                    Isyn =param.LEtoBB_mult*nrn.connectionWeights[int(conn[0])]*conn[1]*(param.w_EE)*np.exp(-param.stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                        \n",
    "                        else: # For non-LE presynaptic E neurons, i.e. BB neurons.\n",
    "                            if neurons[int(conn[0])].category == 'SST' or neurons[int(conn[0])].category == 'PV+': # For BB->I connections.\n",
    "                                Isyn = conn[1]*(param.w_EI)*np.exp(-param.stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                            if neurons[int(conn[0])].category == 'Excitatory': # For E-E connections.\n",
    "                                if neurons[int(conn[0])].backbone_ID in param.bbs_toplot: # For BB->BB connections.\n",
    "                                    Isyn = nrn.connectionWeights[int(conn[0])]*conn[1]*(param.w_EE)*np.exp(-param.stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                                if neurons[int(conn[0])].backbone_ID == 0: # For BB -> LE connections.\n",
    "                                    Isyn = param.BBtoLE_mult*nrn.connectionWeights[int(conn[0])]*conn[1]*(param.w_EE)*np.exp(-param.stepSize*(t_ind-t_temp)/tau)*(V - E_syn)\n",
    "                                    \n",
    "                                    \n",
    "                    neurons[int(conn[0])].Input_syn += Isyn #Isyn going to Postsynaptic neuron.\n",
    "      \n",
    "        #Additional portion of updateSyn() for calculating noise probabilities. INDENTATION IS IMPORTANT! MUST BE IN nrn LOOP.\n",
    "        noise_mag = 80 #Magnitude of noise input. \n",
    "        probability = 2*10**(-4) #Probability in every integration step that a noise spike will occur for each neuron.\n",
    "        t_noise = nrn.start_noise \n",
    "        global neuron\n",
    "\n",
    "        if RD.random() <= probability: #Handles the start of a noise spike.\n",
    "            #print('Noise Spike at Time ',t_ind*param.stepSize)\n",
    "            Inoise = noise_mag\n",
    "            nrn.start_noise = t_ind #Time at which noise begins \n",
    "        elif nrn.Input_noise != 0 and (t_ind - t_noise)*param.stepSize <= 1: #extends noise input for 1 ms.\n",
    "            Inoise = noise_mag\n",
    "        else:\n",
    "            Inoise = 0 #When there is no noise. \n",
    "\n",
    "        nrn.Input_noise = Inoise # Applies noise to neuron. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "def updateSpikeTime(t_ind):\n",
    "    global neuron\n",
    "    # Variables for old, symmetric, frequency dependent synaptic plasticity rule:\n",
    "#     A = 0.6/10 # The maximum amount a synapse can change in strength per spike.\n",
    "#     tau = 10 # Time constant for exponential function in ms.\n",
    "\n",
    "    # For new, unsymmetric plasticity rule. Depotentiation happens more weakly but over a wider time span, while potentiation \n",
    "    # happens stronly but only when the spikes are close together. This rule is also spike timing dependent, so pre->post is\n",
    "    # always potentiated and post->pre always depotentiated. This plasticity rule also does not have a frequency dependent\n",
    "    # component. For more details see \"80 LE Network 5.ipynb\". \n",
    "\n",
    "\n",
    "    for nrn in neurons:\n",
    "        \n",
    "        # Recording the incoming connection plasticity weights for each neuron:\n",
    "        if t_ind % (param.storage_freq/param.stepSize) == 0 and t_ind*param.stepSize >= param.plas_skip_time: #Only runs code every ms (t_ind with only zero in decimal place). Also skips first 500 ms of no plasticity.\n",
    "            \n",
    "            presyn_weight_list = np.ones(int(param.numnrn)) #List for storing weight connections from each presyn neuron.\n",
    "            postsyn_weight_list = np.ones(int(param.numnrn))\n",
    "            \n",
    "            for nrn_ID in range(param.numnrn): #Loops through presynaptic connections to nrn.\n",
    "                presyn_weight_list[int(nrn_ID)] = neurons[int(nrn_ID)].connectionWeights[int(nrn.ID)] #Records value \n",
    "                # of connection weight from presynaptic neuron.\n",
    "                postsyn_weight_list[int(nrn_ID)] = nrn.connectionWeights[int(nrn_ID)]\n",
    "            \n",
    "            nrn.cw_in_history.append([presyn_weight_list, t_ind*param.stepSize]) #Appends conn weights in to this nrn to history. \n",
    "            nrn.cw_out_history.append([postsyn_weight_list, t_ind*param.stepSize]) # Appends conn weights out of this nrn to history.\n",
    "\n",
    "        # Recording spike times:\n",
    "        if nrn.solutions[3] >= param.spikeThreshold and nrn.spike == False and (t_ind*param.stepSize) > param.plas_skip_time: #Selects spikes, skips anything before the first \"param.plas_skip_time\" ms. \n",
    "            \n",
    "            nrn.spikeTimes = np.append(nrn.spikeTimes, t_ind) #Records (time/param.stepSize) of a spike.\n",
    "            nrn.spike = True\n",
    "                        \n",
    "            if nrn.plas_on == True: #If nrn's plas_on is True, plasticity(to and from) nrn is allowed to change. If False, it is frozen.\n",
    "\n",
    "                \n",
    "                #Changes synaptic weights. Note, nrn.connections is a tuple [postsyn, conn] while nrn.conn_in is simply a list of conns where the index is the presyn.\n",
    "                # This works using only spikes that have already occured, so in-conns will always be strengthened and out-conns always weakened.\n",
    "                for postsyn,conn in nrn.connections: # The outgoing connections. This weakens synapses. \n",
    "\n",
    "                    if conn == 1 and nrn.category == 'Excitatory' and neurons[int(postsyn)].category == 'Excitatory' \\\n",
    "                    and len(neurons[int(postsyn)].spikeTimes) > 0 and neurons[int(postsyn)].plas_on == True: # Existing E-E conns for neurons that have spiked and have plas_on.\n",
    "                        \n",
    "                        # Excludes inter-BB conns and (commented out) LE to BB conns from plasticity. Also excludes b-g LE.\n",
    "                        if (nrn.backbone_ID == neurons[int(postsyn)].backbone_ID and nrn.backbone_ID in param.bbs_toplot):\n",
    "#                         or (nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID == 0 and nrn.quad_color in\\\n",
    "#                            ['blue','green'] and neurons[int(postsyn)].quad_color in ['blue','green'] and\\\n",
    "#                            nrn.quad_color != neurons[int(postsyn)].quad_color): \n",
    "                            pass # Does nothing if the above is true.\n",
    "\n",
    "                        else:\n",
    "                            ISI = param.stepSize*abs(neurons[int(postsyn)].spikeTimes[-1] - nrn.spikeTimes[-1]) # The inter-spike interval in ms.\n",
    "                            if ISI <= param.const_ISI: # Portion for the normal exponential STDP rule shape.\n",
    "                                \n",
    "                                if nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID == 0: # For LE-LE connections.\n",
    "                                    nrn.connectionWeights[int(postsyn)] += param.LEtoLE_plas_mult*-param.A_dep*np.exp(-ISI/param.tau_dep) # Weaken LE-LE synapse.\n",
    "                                \n",
    "                                elif nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID in param.bbs_toplot: # LE to BB connections. \n",
    "                                    nrn.connectionWeights[int(postsyn)] += param.LEtoBB_plas_mult*-param.A_dep*np.exp(-ISI/param.tau_dep) # Weaken LE-BB synapse.\n",
    "                                    \n",
    "                                else: # For all other E-E connections.\n",
    "                                    nrn.connectionWeights[int(postsyn)] += -param.A_dep*np.exp(-ISI/param.tau_dep) # Weaken synapse.\n",
    "                            \n",
    "                            elif ISI > param.const_ISI: # Portion for the flat line STDP rule shape. Value set to be the \n",
    "                                # value of the STDP rule when the ISI equals const_ISI. \n",
    "                                if nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID == 0: # For LE-LE connections.\n",
    "                                    nrn.connectionWeights[int(postsyn)] += param.LEtoLE_plas_mult*-param.A_dep*np.exp(-param.const_ISI/param.tau_dep) # Weaken LE-LE synapse.\n",
    "                                \n",
    "                                elif nrn.backbone_ID == 0 and neurons[int(postsyn)].backbone_ID in param.bbs_toplot:\n",
    "                                    nrn.connectionWeights[int(postsyn)] += param.LEtoBB_plas_mult*-param.A_dep*np.exp(-param.const_ISI/param.tau_dep)\n",
    "                                \n",
    "                                else: # For all other E-E connections.\n",
    "                                    nrn.connectionWeights[int(postsyn)] += -param.A_dep*np.exp(-param.const_ISI/param.tau_dep) # Weaken synapse.\n",
    "                                \n",
    "                            if nrn.connectionWeights[int(postsyn)] < 0:\n",
    "                                nrn.connectionWeights[int(postsyn)] = 0 #This prevents synaptic weakening below zero, which would simulate inhibition.\n",
    "                  \n",
    "                \n",
    "                for presyn,conn in enumerate(nrn.conn_in): # Incoming connections. This strengthens synapses.\n",
    "\n",
    "                    if conn == 1 and nrn.category == 'Excitatory' and neurons[int(presyn)].category == 'Excitatory' \\\n",
    "                    and len(neurons[int(presyn)].spikeTimes) > 0 and neurons[int(presyn)].plas_on == True:\n",
    "\n",
    "                        if (nrn.backbone_ID == neurons[int(presyn)].backbone_ID and nrn.backbone_ID in param.bbs_toplot):\n",
    "#                         or (nrn.backbone_ID == 0 and neurons[int(presyn)].backbone_ID == 0 and nrn.quad_color in\\\n",
    "#                            ['blue','green'] and neurons[int(presyn)].quad_color in ['blue','green'] and\\\n",
    "#                            nrn.quad_color != neurons[int(presyn)].quad_color):\n",
    "                            pass \n",
    "\n",
    "                        else:\n",
    "                            \n",
    "                            if nrn.backbone_ID == 0 and neurons[int(presyn)].backbone_ID == 0: # LE-LE connections.\n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] += param.LEtoLE_plas_mult*param.A_pot*np.exp((-param.stepSize*abs(neurons[int(presyn)].spikeTimes[-1] \n",
    "                                                                                            - nrn.spikeTimes[-1]))/param.tau_pot)# Weaken synapse.\n",
    "                            \n",
    "                            elif (nrn.backbone_ID in param.bbs_toplot and neurons[int(presyn)].backbone_ID == 0):\n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] += param.LEtoBB_plas_mult*param.A_pot*np.exp((-param.stepSize*abs(neurons[int(presyn)].spikeTimes[-1] \n",
    "                                                                                            - nrn.spikeTimes[-1]))/param.tau_pot)\n",
    "                            else: # All other E-E connections.\n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] += param.A_pot*np.exp((-param.stepSize*abs(neurons[int(presyn)].spikeTimes[-1] \n",
    "                                                                                            - nrn.spikeTimes[-1]))/param.tau_pot)# Weaken synapse.\n",
    "                            if neurons[int(presyn)].connectionWeights[int(nrn.ID)] > param.w_max:\n",
    "                                neurons[int(presyn)].connectionWeights[int(nrn.ID)] = param.w_max # Caps strength at param.w_max.\n",
    "                                        \n",
    "        \n",
    "        \n",
    "        if nrn.solutions[3] <= -30 and nrn.spike == True: #Resets the spiking status, allows for next spike to be recorded. \n",
    "            nrn.spike = False\n",
    "                                    \n",
    "                                    \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "'---------------------------------------------------------------------------'      \n",
    "def param_funcs():\n",
    "    # Function for creating and returning lists needed in vary_param that don't need to be redone every timestep. \n",
    "    # NOTE: Before I actually implement this function, I need to test whether using it increases or decreases simulation runtime.\n",
    "    dummy_var = 0\n",
    "\n",
    "\n",
    "            \n",
    "def vary_param(t_ind): #Changes gks of network as well as vary other parameters. I am also added in a component to weaken all synapses after NREM.\n",
    "\n",
    "    global neuron\n",
    "    bbt_list = [] # Will hold BB activity for learning times.\n",
    "    \n",
    "    #Vary gks:\n",
    "    t = t_ind*param.stepSize #changes t_ind to ms.\n",
    "    \n",
    "    #List containing gks values and the time to impliment them. [[gks val,time(ms)],[...]].\n",
    "#     gt_list = [[param.gks_test, 0]]\n",
    "#     gt_list = [[param.gks_test, 0], [param.gks_NREM, param.t_start_NREM], \\\n",
    "#                [param.gks_test, param.t_start_NREMtest], [param.gks_REM, param.t_start_REM],\\\n",
    "#                [param.gks_test, param.t_start_posttest]] \n",
    "    gt_list = [ [param.gks_NREM, param.t_start_NREM], \\\n",
    "                [param.gks_REM, param.t_start_REM]] \n",
    "    \n",
    "    times = [i[1] for i in gt_list] # creates list of times from the gt_list.\n",
    "    if t in times:\n",
    "        gks_val = gt_list[times.index(t)][0] # assigns gks_val the corresponding gks value.\n",
    "        \n",
    "        for nrn in neurons:\n",
    "            nrn.gks = gks_val # Changes the gks value to gks_val for all neurons.\n",
    "        \n",
    "        \n",
    "        \n",
    "#     # Vary backbone activity:\n",
    "#     # List indicating times and implimentations. [ [ ['on',[bbs to turn on],'off',[bbs to turn off] ], time(ms)] , [...] ]\n",
    "#     tot_learning_time = param.simLength - 2*param.num_test_phases*param.BB_len_test #Total learning time, i.e. time not spent in either test phase.\n",
    "    \n",
    "#     # ---------------------------------------------\n",
    "#     # NOTE: The number of test phases was changed from 2 to 3 when adding post-NREM test to simulation, so tot_learning_time\n",
    "#     # was changed appropriately.\n",
    "#     # ---------------------------------------------\n",
    "    \n",
    "#     num_osc = np.floor(tot_learning_time/param.osc_period) # Number of oscillations between BBs during learning.\n",
    "    \n",
    "#     NREM_osc_times = list(range(param.t_start_NREM,param.t_start_NREMtest,param.osc_period)) #List of times for switching BBs in NREM.\n",
    "#     REM_osc_times = list(range(param.t_start_REM,param.t_start_posttest,param.osc_period)) #List of times for switching BBs in REM.\n",
    "#     osc_times = NREM_osc_times + REM_osc_times # Concatenates lists to create one list with all oscillation switch times.\n",
    "    \n",
    "#     # Now that I have the times to switch the oscillations at, I need to put them into the form of \n",
    "#     # [ [ ['on',[bbs to turn on],'off',[bbs to turn off] ], time(ms)] , [...] ].\n",
    "    \n",
    "#     BB_onoff = [ ['on',[1],'off',[2]] , ['on',[2],'off',[1]] ] # Holds the 2 options for turning BBs on and off. \n",
    "#     onoff_index = 0 #Used to assign index from BB_onoff. If initialized at 0, starts with blue BB. If at 1, starts with green.\n",
    "\n",
    "    \n",
    "#     for osc_t in osc_times: # Loops through times at which to switch BBs.\n",
    "#         bbt_list.append([BB_onoff[onoff_index], osc_t ])\n",
    "        \n",
    "#         if onoff_index == 0: #This keeps switching between BB_onoff indices.\n",
    "#             onoff_index = 1\n",
    "#         else:\n",
    "#             onoff_index = 0\n",
    "        \n",
    "\n",
    "#     insert_values = [[['on',[1],'off',[2]],0], [['on',[2],'off',[1]],param.BB_len_test], [['on',[1],'off',[2]],param.t_start_NREMtest],\n",
    "#                      [['on',[2],'off',[1]],param.t_start_NREMtest+param.BB_len_test], [['on',[1],'off',[2]],param.t_start_posttest],\n",
    "#                      [['on',[2],'off',[1]],param.t_start_posttest+param.BB_len_test]] #Values (for test phases) to be inserted.\n",
    "    \n",
    "#     # Adding the testing phases to the list.\n",
    "#     bbt_list.insert(0,insert_values[0]) # Inserting BB activity rules for pre-learning test.\n",
    "#     bbt_list.insert(1,insert_values[1])\n",
    "    \n",
    "    \n",
    "#     # It is more difficult to insert the post-NREM test phase because I have to know between exactly which oscillations\n",
    "#     # to place it. To use np.where() I need to use arrays.\n",
    "#     np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) # This eliminates the depreciation warning \n",
    "#     # that arises from converting a \"ragged\" list into an array. I don't think this actually does anything harmful, so I will\n",
    "#     # supress the warning like this.\n",
    "    \n",
    "#     bbt_array = np.array(bbt_list) # convert to array.\n",
    "    \n",
    "#     post_NREMtest_results = np.where(bbt_array[:,1] > param.t_start_NREMtest) # Object containing first-axis indices of elements in bbt_array where\n",
    "#     # the time is greater than the start time of NREM test phase, but this object is not the indices themselves.\n",
    "#     post_NREMtest_indices = post_NREMtest_results[0] # List containing the desired indices.\n",
    "#     smallest_index = post_NREMtest_indices[0] # Grabs first index in list. This should be the index of the smallest time in\n",
    "#     # bbt_list that comes after param.t_start_NREMtest.\n",
    "    \n",
    "#     bbt_list.insert(smallest_index,insert_values[2]) # Inserts BB activity rules for post-NREM test.\n",
    "#     bbt_list.insert(smallest_index+1,insert_values[3])\n",
    "    \n",
    "    \n",
    "#     bbt_list.append(insert_values[-2]) # BB activity rules for post-learning test.\n",
    "#     bbt_list.append(insert_values[-1])\n",
    "    \n",
    "                \n",
    "#     times_bb = [i[1] for i in bbt_list]\n",
    "\n",
    "#     if t in times_bb:\n",
    "#         #print('onoff triggered at',t)\n",
    "#         #'On' Operations:\n",
    "#         on_off = bbt_list[times_bb.index(t)][0][0] #This grabs the 'on' string\n",
    "#         bb_toswitch = bbt_list[times_bb.index(t)][0][1] #Grabs bb IDs to be turned on.\n",
    "#         bb_onoff(on_off,bb_toswitch)\n",
    "#         #'Off' Operations:\n",
    "#         on_off = bbt_list[times_bb.index(t)][0][2] #This grabs the 'off' string\n",
    "#         bb_toswitch = bbt_list[times_bb.index(t)][0][3] #Grabs bb IDs to be turned off.\n",
    "#         bb_onoff(on_off,bb_toswitch)\n",
    "                \n",
    "        \n",
    "        \n",
    "    #Vary plasticity activity:\n",
    "    #List for turning off plasticity to and from specific bbs or LE neurons. [[LE,bb1,bb2],time] , ...\n",
    "#     plas_onoff_list = [[[False,False,False],0], [[False,False,False],param.t_start_NREMtest], [[False,False,False],param.t_start_posttest]]\n",
    "    plas_onoff_list = [[[True, True, True],0]]\n",
    "    \n",
    "    if param.NABP_boo == True: #For NABP on.\n",
    "        plas_onoff_list.insert(1,[[True,True,True],param.t_start_NREM + 2*param.osc_period])\n",
    "        plas_onoff_list.insert(3,[[True,True,True],param.t_start_REM + 2*param.osc_period]) # Turns plasticity back on after post-NREM test phase\n",
    "    \n",
    "    # Loop through bbt_list used for BB activity and use it to create the plasticity activity list.\n",
    "    if param.NABP_boo == False: #Only adds these elements if NABP is supposed to be off. \n",
    "        for item in bbt_list:\n",
    "            if item[1] >= param.t_start_NREM and item[1] < param.t_start_NREMtest or item[1] >= param.t_start_REM and \\\n",
    "            item[1] < param.t_start_posttest: #If the time related to the command is in learning:\n",
    "                \n",
    "                if item[0][1] == [1] and item[0][3] == [2]:\n",
    "                    plas_onoff_list.insert(-1, [[True,True,False],item[1]] ) # Adds element for turning on BB1.\n",
    "                if item[0][1] == [2] and item[0][3] == [1]:\n",
    "                    plas_onoff_list.insert(-1, [[True,False,True],item[1]] ) # Adds element for turning on BB2.\n",
    "            \n",
    "    times_plas = [i[1] for i in plas_onoff_list]\n",
    "    if t in times_plas: #If the simulation reaches one of desired times:\n",
    "        plas_boo_list = plas_onoff_list[times_plas.index(t)][0] #Assigns plas_on the boolean associated with time t. \n",
    "        \n",
    "        for nrn in neurons: #Changes plas_on attribute for all neurons to match plas_boo_list vals. Uses index. \n",
    "            nrn.plas_on = plas_boo_list[int(nrn.backbone_ID)]\n",
    "        \n",
    "        \n",
    "'-------------------------------------------------------------------------'     \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "def zeroTempVars(): #Zeros all variables to prevent accidental accumulation of unwanted terms. Just a safety measure, good habit.\n",
    "        #Note: Do not zero solutions, because they are used in calculating next solutions. \n",
    "        global neuron\n",
    "        for nrn in neurons:\n",
    "            nrn.Input_syn = 0 #Zeroed because ISyn must be added to account for input from multiple neurons. If Isyn was\n",
    "            # simply assigned, the Isyn would not accumulate. But now it must be zeroed. \n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "def sort_gsyn(item): #Function for returning the gsyn of a neuron\n",
    "    # Built to handle nrn simply as an object, and also as a list [nrn_object,index_val].\n",
    "    if isinstance(item,tuple): #if item is a tuple.\n",
    "        val = item[0].gsyn    \n",
    "    elif isinstance(item,neurons[0].__class__): #If this item is object type of a neuron.\n",
    "        val = item.gsyn\n",
    "    elif isinstance(item, list): #If item is a list.\n",
    "        val = item[0].gsyn\n",
    "    else:\n",
    "        print(\"Exception: val=0 in sort_gsyn.\")\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "\n",
    "def sort_Idrive(nrn):\n",
    "    return nrn.Idrive\n",
    "\n",
    "\n",
    "def sort_bb(nrn):\n",
    "    val = nrn.backbone_ID\n",
    "    return val\n",
    "\n",
    "def sort_bb_tuple(list1):\n",
    "    val = list1[0].backbone_ID\n",
    "    return val\n",
    "                    \n",
    "def sort_tuple(tup): #Sorts tuple by first element (index 0).\n",
    "    val = tup[0]\n",
    "    return val\n",
    "\n",
    "def sort_tuple_1(tup): # Sorts tuple by value at index 1.\n",
    "    val = tup[1]\n",
    "    return val\n",
    "\n",
    "def sort_tuple_2(tup): # Sorts tuple by value at index 2.\n",
    "    val = tup[2]\n",
    "    return val\n",
    "\n",
    "def sort_LE_bycolor(LE_nrn): # Function used to sort LE neurons by color. Green first, then blue, then pink, then purple.\n",
    "    val = 0\n",
    "    if LE_nrn.quad_color == 'green':\n",
    "        val = 1\n",
    "    if LE_nrn.quad_color == 'blue':\n",
    "        val = 2\n",
    "    if LE_nrn.quad_color == 'pink':\n",
    "        val = 3\n",
    "    if LE_nrn.quad_color == 'purple':\n",
    "        val = 4\n",
    "    \n",
    "    return val\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def beep(): #Makes a series of beeps. Meant to signal end of code-running. \n",
    "    if param.makeSound: #When True, plays beeps.\n",
    "        winsound.Beep(349,500)\n",
    "        winsound.Beep(440,500)\n",
    "        winsound.Beep(523,500)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def strengthen_backbone(): # Increases strength of all connections between backbone neurons.\n",
    "    global neuron\n",
    "    for nrn1 in neurons: # Loops over all possible pairs of neurons.\n",
    "        for nrn2 in neurons:\n",
    "            if nrn1.backbone_ID == nrn2.backbone_ID and nrn1.backbone_ID not in [-1,0] and nrn1.connections[int(nrn2.ID)][1] == 1: #if both neurons are to be part of the same backbone and are actually connected.\n",
    "                nrn1.connectionWeights[int(nrn2.ID)] = 2.5 # Strengthens connections between neurons in the same BB.\n",
    "                \n",
    "                \n",
    "                \n",
    "def strengthen_LE(): # Gives the LE neurons with largest number of connections from each backbone an increased connection weight\n",
    "    # for all those connections, as well as a smaller connection weight for the least connected LE neurons. NOTE that this is \n",
    "    # based off of quad colors, which takes into account the number of connections from both bbs. So, in reality, the LE\n",
    "    # neurons with most connections to one bb and also least connections to the other bb have their plasticity weights changed\n",
    "    # for those connections. These are the blue and green quad color labeled LE neurons.\n",
    "    # This function should be run after init_quad_colors() but before the t_ind loop for the simulation begins.\n",
    "    global neuron\n",
    "    \n",
    "    LE_neurons = []\n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0:\n",
    "            LE_neurons.append(nrn)\n",
    "            \n",
    "    for nrn_LE in LE_neurons: # Changes plasticity weight based on quad color.\n",
    "        for nrn in neurons:\n",
    "            if nrn.connections[int(nrn_LE.ID)][1] == 1: # If connection from nrn to LE nrn exists.\n",
    "                \n",
    "                if nrn.backbone_ID == 1: # For connections from a bb1 neuron to LE neuron. \n",
    "                    if nrn_LE.quad_color == 'blue':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += param.bg_str # Strenghthens connections to LE neurons that have many\n",
    "                        # synapses from bb1 and few synapses from bb2.\n",
    "                    if nrn_LE.quad_color == 'green':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += 0 # Weakens connections to LE neurons that have many \n",
    "                        # synapses from bb2 and few synapses from bb1.\n",
    "                    if nrn_LE.quad_color == 'purple': #Weakens connections to LE neurons strongly connected to both BBs.\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += -param.pu_weak\n",
    "                    if nrn_LE.quad_color == 'pink': #Weakens connections to LE neurons weakly connected to both BBs.\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += -param.pi_weak\n",
    "                        \n",
    "                if nrn.backbone_ID == 2: # For connections from a bb2 neuron to LE neuron. \n",
    "                    if nrn_LE.quad_color == 'blue':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += 0 # Strenghthens connections to LE neurons that have many\n",
    "                        # synapses from bb1 and few synapses from bb2.\n",
    "                    if nrn_LE.quad_color == 'green':\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += param.bg_str # Weakens connections to LE neurons that have many \n",
    "                        # synapses from bb2 and few synapses from bb1.\n",
    "                    if nrn_LE.quad_color == 'purple': #Weakens connections to LE neurons strongly connected to both BBs.\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += -param.pu_weak\n",
    "                    if nrn_LE.quad_color == 'pink': #Weakens connections to LE neurons weakly connected to both BBs.\n",
    "                        nrn.connectionWeights[int(nrn_LE.ID)] += -param.pi_weak\n",
    "                        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def bb_onoff(onoff,bb_listtoswitch):\n",
    "    # Function for turning backbones on or off through changes in Idrive. onoff can be string value \n",
    "    # 'on' or 'off', determining the action to be taken and bb_listtoswitch are the IDs of the backbones to apply this action to.\n",
    "    global neurons\n",
    "    \n",
    "    if onoff == 'on': #Turns on backbone through higher Idrive.\n",
    "        #print('bb',bb_listtoswitch, 'turned on')\n",
    "        for nrn in neurons:\n",
    "            if nrn.backbone_ID in bb_listtoswitch: #if the nrn belongs to a backbone in the list.\n",
    "                nrn.Idrive = param.Idrive_min #This is the high Idrive value. Could use param.Idrive_max also because there is no distribution of E idrive.\n",
    "                \n",
    "    if onoff == 'off': #Turns off backbone through lower Idrive.\n",
    "        #print('bb',bb_listtoswitch,'turned off')\n",
    "        for nrn in neurons:\n",
    "            if nrn.backbone_ID in bb_listtoswitch:\n",
    "                nrn.Idrive = param.Idrive_NABB #Low enough to prevent backbone from theta spiking when it is \"off.\"\n",
    "                \n",
    "\n",
    "                \n",
    "def record_gaussian(): # Gives neuron objects their gaussian spike data. Must be run before any dot product functions can work.\n",
    "    global neuron \n",
    "    \n",
    "    for nrn in neurons: #This loop is to add the spike gaussians to the neurons.\n",
    "        spike_gauss_sum = np.zeros(len(param.tarray)) #List to hold all the guassians together from one neuron.\n",
    "\n",
    "        for spike_time in nrn.spikeTimes: #Note spikeTimes are still in ms/param.stepSize\n",
    "            temp_gauss = stats.norm.pdf(param.tarray,loc=int(param.stepSize*spike_time),scale=2) #Temp list to hold 1 spike gaussian. Scale = 2 gives\n",
    "            # Gaussian curve of total width about 10 ms. \n",
    "            spike_gauss_sum += temp_gauss #Adds to total sum.\n",
    "\n",
    "        nrn.spike_gaussian = spike_gauss_sum #updates neuron object to the gaussian curves at each spike time.\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def return_inhib_conns(nrn):\n",
    "    # Function that returns the number of inhibitory connections to \"nrn\".\n",
    "    count = 0\n",
    "    for presyn,conn in enumerate(nrn.conn_in):\n",
    "        if neurons[int(presyn)].backbone_ID == -1:\n",
    "            count += conn # conn_in values are all 0 or 1, so summing gives the total in-degree from inhibitory neurons.\n",
    "            \n",
    "    return count #Returns number of inhibitory conns to this nrn. \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def assign_LE_Idrive(quad_colors): # Assigns new Idrives to LE neurons. quad_colors contains str of all\n",
    "    # colors to change the Idrive for.\n",
    "    global neuron\n",
    "    \n",
    "    for nrn in neurons:\n",
    "        if nrn.backbone_ID == 0 and nrn.quad_color in quad_colors:\n",
    "            nrn.Idrive = param.Idrive_LE # Assigns new Idrive.  \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def save_simdata(): # Function to save all useful information of the simulation data for the later creation of plots and \n",
    "    # measures.\n",
    "    \n",
    "    \n",
    "    def export_LE_spikes(): # Separates LE spikes into each phase and writes them to \n",
    "        # txt file.\n",
    "\n",
    "        LE_neurons = []\n",
    "        for nrn in neurons:\n",
    "            if nrn.backbone_ID == 0:\n",
    "                LE_neurons.append(nrn)\n",
    "        LE_neurons.sort(key=sort_LE_bycolor)\n",
    "\n",
    "        all_spikes = [[] for i in range(len(LE_neurons))] # List for holding all spikes accross entire simulation\n",
    "        pretest_BB1_spikes = [[] for i in range(len(LE_neurons))] # Pre-learning during BB1 activity\n",
    "        pretest_BB2_spikes = [[] for i in range(len(LE_neurons))] # Pre-learning during BB2 activity\n",
    "        NREM_spikes = [[] for i in range(len(LE_neurons))] # Holds spikes that occur in first phase of learning (usually NREM)\n",
    "        NREMtest_BB1_spikes = [[] for i in range(len(LE_neurons))] # Post-NREM during BB1 activity\n",
    "        NREMtest_BB2_spikes = [[] for i in range(len(LE_neurons))] # Post-NREM during BB1 activity\n",
    "        REM_spikes = [[] for i in range(len(LE_neurons))] # Second phase\n",
    "        posttest_BB1_spikes = [[] for i in range(len(LE_neurons))] # post-learning during BB1 activity\n",
    "        posttest_BB2_spikes = [[] for i in range(len(LE_neurons))] # post-learning during BB2 activity\n",
    "\n",
    "\n",
    "        for i,LE_nrn in enumerate(LE_neurons):\n",
    "\n",
    "            if len(LE_nrn.spikeTimes) > 0: # So long as the neuron actually spikes\n",
    "\n",
    "                for spike_t in LE_nrn.spikeTimes*param.stepSize: # NOTE nrn.spikeTimes gives times in ms/param.stepSize, so we have to get back\n",
    "                    # to ms. spike_t is now in ms.\n",
    "                    all_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.plas_skip_time+20 < spike_t < param.BB_len_test: # For BB1 spikes in pre-learning. Skips strange synchronous burst\n",
    "                        # that appears at start of every simulation.\n",
    "                        pretest_BB1_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.BB_len_test < spike_t < param.t_start_NREM: # For BB2 spikes in pre-learning\n",
    "                        pretest_BB2_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.t_start_NREM < spike_t < param.t_start_NREMtest: # For spikes in first phase (NREM)\n",
    "                        NREM_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.t_start_NREMtest < spike_t < param.t_start_NREMtest+param.BB_len_test: # For BB1 spikes in post-NREM test\n",
    "                        NREMtest_BB1_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.t_start_NREMtest+param.BB_len_test < spike_t < param.t_start_REM: # For BB2 spikes in post-NREM test\n",
    "                        NREMtest_BB2_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.t_start_REM < spike_t < param.t_start_posttest: # For spikes in second phase (REM)\n",
    "                        REM_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.t_start_posttest < spike_t < param.t_start_posttest+param.BB_len_test: # For BB1 spikes in post-learning\n",
    "                        posttest_BB1_spikes[i].append(spike_t)\n",
    "\n",
    "                    if param.t_start_posttest+param.BB_len_test < spike_t: # For BB2 spikes in post-learning\n",
    "                        posttest_BB2_spikes[i].append(spike_t)\n",
    "\n",
    "\n",
    "        # NOTE that opening a file in the write mode (using \"w\") automatically clears the file when it is opened, so I am always \n",
    "        # writing onto an empty file.\n",
    "        with open(param.directory+\"all_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(all_spikes))\n",
    "        with open(param.directory+\"pretest_BB1_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(pretest_BB1_spikes))\n",
    "        with open(param.directory+\"pretest_BB2_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(pretest_BB2_spikes))\n",
    "        with open(param.directory+\"NREM_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(NREM_spikes))\n",
    "        with open(param.directory+\"NREMtest_BB1_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(NREMtest_BB1_spikes))\n",
    "        with open(param.directory+\"NREMtest_BB2_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(NREMtest_BB2_spikes))\n",
    "        with open(param.directory+\"REM_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(REM_spikes))\n",
    "        with open(param.directory+\"posttest_BB1_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(posttest_BB1_spikes))\n",
    "        with open(param.directory+\"posttest_BB2_LE_spikes.txt\", \"w\") as output:\n",
    "            output.write(str(posttest_BB2_spikes))\n",
    "            \n",
    "    \n",
    "    export_LE_spikes() # Runs the function so that LE spike files are saved.\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def save_object(obj, filename): # For saving objects in .pkl files.\n",
    "        with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "            pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "    save_object(neurons, param.directory+\"neuron_objects.pkl\") # Saves all neuron objects to a pickle file, which can be reimported to a \n",
    "    # notebook later! \n",
    "    \n",
    "    save_object(param, param.directory+\"param_object.pkl\") # Saves param object for reimportation to another notebook.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87221ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120000/120000 [54:18<00:00, 36.83it/s]\n"
     ]
    }
   ],
   "source": [
    "param = init_param() # Initializes parameters\n",
    "neurons,nc_Matrix = init_nrn() #initializes neurons and creates universal list.\n",
    "strengthen_backbone()\n",
    "init_quad_colors() # Groups LE neurons based on intial connectivities to bbs.\n",
    "assign_LE_Idrive(['purple','pink'])\n",
    "strengthen_LE() #Must come after init_quad_colors().\n",
    "\n",
    "def mainProgramLoop():\n",
    "    \n",
    "    for t_ind in tqdm(range(param.Ntimes)):\n",
    "        \n",
    "        #Records timing of spikes (in t/stepSize)\n",
    "        updateSpikeTime(t_ind)\n",
    "        #Updates the input synaptic current to be used in RK4\n",
    "        updateSyn(t_ind)\n",
    "        #A function to update the solutions for all neurons' D.E.s\n",
    "        RK4(t_ind)\n",
    "\n",
    "        vary_param(t_ind) #Checks t_ind to change network gks values. Also added backbone switching and plasticity.\n",
    "        \n",
    "        zeroTempVars() #Resets temporary variables like Isyn\n",
    "        \n",
    "    \n",
    "    return \n",
    "\n",
    "mainProgramLoop()\n",
    "\n",
    "record_gaussian()\n",
    "\n",
    "save_simdata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
